---
title: "Análise Descritiva"
subtitle: "Introdução à Estatística"
author:
- Alexandre Nicolella
date: '2024'
format: html
---

## Porque Estudar Estatística?

Podemos dizer que a existência da estatística e de outras ciências está conectada a existência de problemas. Não somente a ciência mas o nosso trabalho está conectado a superação de problemas cotidianos. Tomar decisão é o dia a dia do gestor.

Segundo Popper "we study not disciplines, but problems. Often, problems transcend the boundaries of a particular discipline"

A questão central é: Como solucionamos os problemas? Utilizamos a melhor estratégia? A solução foi boa?

```{mermaid}
flowchart LR
  A[PROBLEMA] --> B[Estratégia de Decisão]
  B --> C{Solução é BOA?}
```

### Os dois sistemas cognitivos

Os livros abaixo são boas referências sobre a tomada de decisão.

::: {layout="[30,-40,30]"}
![Rápido e Devagar: Duas Formas de Pensar](figuras\kahneman.jpg){width="10%"}

![Processo Decisório](figuras\bazerman.jpg){width="10%"}
:::

Existem dois sistemas que utilizamos para tomar decisão. O chamado **Sistema 1** e o chamado **Sistema 2**. Segue uma breve descrição de cada um:

**Sistema 1**:

-   Intuitivo, rápido, automático, sem esforço, implícito e emocional
    -   Pressa,
    -   Falta de tempo,
    -   Problemas menos importante
    -   Mais Falhas/Erros

**Sistema 2**

-   Raciocíonio lento, consciente, esforçado, explícito, lógico
    -   Requer tempo,
    -   Mais recursos
    -   Problemas mais importante
    -   Menos Falhas

Para o Sistema 1 usamos a nossa intuição que chamamos de Heurística. Vejamos um pouco mais sobre esse sistema.

**Heurística**

São rotinas inconscientes ou atalhos que o nosso cérebro utiliza para lidar com a complexidade.

-   Modelo/Regras Intuitivas.
-   Próprio do Sistema 1.
-   Apesar de processo sofisticado, são passíveis de falhas. Intuição falha

[**Um Exemplo**]{.underline}

Veja a figura abaixo retirada do livro do Bazerman.Responda rápido.

**Qual delas tem o tampo mais quadrado?**

![Bazerman: Exemplo das mesas](figuras\mesa.jpg){width="80%"}

Se você achou que é a segunda mesa, você está alinhado com a grande maioria. Nesse caso você usou o seu sistema 1

Vamos repitir a pergunta:

**Qual delas tem o tampo mais quadrado?**

Agora use uma régua para medir as mesas. Usamos aqui o sistema 2. Mais tempo e recursos são utlizados. Qual mesa agora você considera mais quadrada? Mudou sua opinião?

Com a régua vemos que as mesas são iguais. Isso mostra que a nossa intuição **FALHA**.

**Tipos de Heurísticas**

-   **Heurística da disponibilidade**: Usamos o que está mais próximo na memória para calcular a probabilidade.

-   **Heurística da representatividade**: Buscamos aquilo que reforça o padrão.

-   **Heurística da hipótese positiva**: Assumimos que uma determinada hipótese é verdadeira e não olhamos o contrafactual.

-   **Heurística do afeto**: Decisão considera o emocional. Seu humor afetam as decisões.

Para contornar os problemas da intuição e seus viéses na tomada de decisão o primeiro passo é compreender que eles existem e estarmos alerta. E para problemas maiores o uso do sistema 2 torna-se relevante.

Uma das principais ferramentas do sistema 2 é a Estatística. Com os avanços computacionais essa ciência tem se destacado como um dos elementos centrais do *data science*. Abaixo a figura resume as diversas áreas de desenvolvimento da análise de dados, obviamente não exaustiva:

![Bazerman: mesas](figuras\analisedados.jpg){width="80%"}

Nosso objetivo é explorar nessa seção a análise descritiva. Chamado hoje no *Business Intelligence*, que e uma das áreas do *Data Science*.

## Conceitos Básicos de Estatística

Novamente começamos com um problema e esse definirá a nossa análise. Vejamos alguns problemas que poderiam nos interessar...

::: callout-note
## Problema 1

O prefeito de Ribeirão Preto vai lançar uma política que fornece vouchers de alimentação para mulheres que estão em situação de pobreza.

**Problema**: [Qual o valor que devo reservar ao programa? Quantas mulheres serão atendidas?]{.underline}
:::

::: callout-note
## Problema 2

O TJSP vai lançar um programa para reduzir o tempo médio em processos de feminicídio.

**Problema**: [Qual o tempo médio de um processo de feminicídio?]{.underline}
:::

::: callout-note
## Problema 3

O O governo federal vai lançar um programa para capacitar mulheres que estão fora do mercado de trabalho.

**Problema**: [Quantas mulheres serão alvos dessa política?]{.underline}
:::

### A Variável Aleatória

O problema nos define a população que estou interessado. Vamos seguir, a princípio, com o nosso probelma 1 para definirmos alguns conceitos importantes.

**No problema 1**: me interessa compreender a renda das mulheres que moram em Ribeirão Preto em dado ano. Para ficar simples vamos abreviar o que nos interessa

$$X=\text{Renda das mulheres que moram em Ribeirão Preto em determinado ano}$$ Agora posso utilizar o X no lugar do nome. Olhando para a população e pensando que cada nível de renda pode ser representada por uma cor, teremos a seguinte imagem pouco de como a renda se distribui nessa população:

![Renda pc das mulheres de Ribeirão Preto.](figuras\lego.jpg){width="50%"}

A questão é: quais cores existem e quantas peças de cada cor temos? Para isso usamos um experimento

**Experimento Aleatório**

O experimento em ciências sociais aplicadas em geral está associada a observação sistemática de pessoas, cidades, empresas ou processos. A ideia é:

-   Sortear pessoas e observar a sua caracteristica de forma indefinida e sempre na mesma condição.\
-   Não consigo dizer o que vai sair no próximo sorteio, apenas consigo descrever os resultados possíveis
-   Se repetir o experimento um número grande de vezes uma regularidade aparece.

Se eu conseguir sortear de forma indefinida e na mesma condição as mulheres que moram em Ribeirão Preto e perguntar sobre a sua renda. Eu consigo reorganizar a figura acima da seguinte forma:

![Renda pc das mulheres de Ribeirão Preto.](figuras\lego_org.jpg){width="50%"}

**Espaço Amostral**

Agora conseguimos organizar os nossos resultados em um lugar chamado espaço amostral. Nele teremos todas as cores (azul, branca, amarela...) que podem acontecer e o número de peças de cada cor (a chance). Em outras palavras teremos todos os possíveis valores de $X$ e suas probabilidades.

**Variável Aleatória**

Quanto representamos esse espaço amostral em formato de números é o que chamamos de Variável Aleatória (V.A.). A V.A. é a combinação de tudo que pode acontecer, ou seja, todas as rendas que existem associadas a probabilidade de cada uma das rendas acontecerem.

Existem dois tipos principais de variáveis aleatórias: discretas e contínuas.

**Variáveis Aleatórias Discretas**

É um tipo de variável que conseguimos colocar em lista, seja finita ou infinita $x_1; x_2;...; x_n;...$ e associa-se a cada um dessses valores uma probabilidade $p(x_1); p(x_2);...; p(x_n);...$

Podemos pensar aqui se a pessoa é casada, solteira, divorciada, viúva ou outra condição. Se no processo classificamos como homicídio ou feminicídio, se mora na área urbana ou rural...

Na figura abaixo iremos coletar de 20 processos de homicídio e gostariamos de saber quando é classificado como feminicídio e quanto é classificado como homicídio (p=0,3).

```{r echo = TRUE, fig.cap= "Distribuição Normal",fig.height = 3.5, fig.width = 5}
feminicidio <- 0:20

plot(feminicidio,dbinom(feminicidio,size=20,prob=.3),
     type='h',
     main='Distribuição Binomial (n=20, p=0.3)',
     ylab='Probabilidade',
     xlab ='Feminicídio',
     lwd=3)
```

**Variáveis Aleatórias Contínuas**

Por outro lado, uma variável aleatória contínua pode assumir infinito valores dentro de um intervalo específico. Agora temos infinitas possibilidades de resultados para $X$ e agora associamos uma função $f(x)$ que irá descrever o comportamento da probabilidade.

Por exemplo, a altura de uma pessoa, a sua renda, a sua idade, o tempo que demora um processo.

Abaixo temos uma representação de uma distriuição continua da renda das mulheres em Ribeirão Preto, chamada distribuição normal:

```{r echo = TRUE, fig.cap= "Distribuição Normal",fig.height = 3.5, fig.width = 5}
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
x<-seq(700,1300,1)
fdnorm<-dnorm(x = x, mean = 1000, sd=100)  
fdanorm<-pnorm(q = x, mean = 1000, sd=100)
curve(dnorm(x,1000,100),xlim=c(700,1300),main='',xaxt="n",xlab="Renda pc Mulheres", ylab="f(x)",col="darkblue",cex.axis=0.65, cex.lab=0.8) 
axis(1,at=c(900, 1000, 1100),labels =
       c("-DP(X)","E(x)","DP(x)"),cex.axis=0.65, cex.lab=0.8) 
lines(x=c(1000,1000),y=c(0,fdnorm[x==1000]),lty=2, col="black") 
lines(x=c(1100,1100),y=c(0,fdnorm[x==1100]),lty=2, col="black")
lines(x=c(900,900),y=c(0,fdnorm[x==900]),lty=2, col="black")

```

#### Esperança e Variância

O fomato das distribuições vistas dependem principalmente de dois parâmetros: A esperança que é uma medida de centralidade e a variância que é uma medida de dispersão.

**Esperança -** $E(X)$

É uma medida de centralidade da variável aleatória. É definida como a média ponderada de todos os possíveis resultados de $X$, onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança de $X$, $E(X)$, é calculada como:

$$E(X) = \sum_{x} x \cdot P(X = x)$$

para variáveis discretas.

$$E(X) = \int_{-\infty}^{\infty} x \cdot f(x)$$,

para variáveis contínuas

**Variância Populacional -** $Var(X)$

A variância é uma medida que captura como os dados populacionais se dispersão em relação a sua média (ou esperança).

$$Var(X) =\frac{1}{N} \sum_{1}^{N} (X_i-E(X))^2$$ Ou podemos assim representar: $$\text{Var}(X) = E(X^2) - [E(X)]^2$$.

**Desvio Padrão Populacional -** $DP(X)$

A variãncia é uma medida ao quadrado. Se estamos falando da renda seria uma medida da dispersão ao quadrado, ou seja, em $R\$^{2}$. Para retornar a unidade original usamos o desvio padrão que é:

$$DP(X)=\sqrt{Var(X)}$$

Vejamos o que acontece quando mudamos a esperança e o desvio padrão. No gráfico em azul temos a esperança igual a 10 e devio padrão de 2,5. No gráfico em vermelho temos esperança de 20 e desvio padrão de 10. E no grafico em verde temos esperança de 10 e desvio padrão de 1. Nota-se que quanto menor o desvio padrão mais concentrados são os valores que podem acontecer.

```{r echo = TRUE, fig.cap= "Médias e desvios distintos entre distribuições",fig.height = 3.5, fig.width = 6}
curve(dnorm(x,mean=10,sd=sqrt(2.5)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs="i",yaxs="i",ylab="", col="darkblue") 
par(new=T)
curve(dnorm(x,mean=20,sd=sqrt(10)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs="i",yaxs="i",ylab="", col="darkred") 
par(new=T)
curve(dnorm(x,mean=20,sd=sqrt(1)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs="i",yaxs="i",ylab="", col="darkgreen") 

```

### Variáveis Aleatórias Bidimensionais

Muito provavelmente nos interessa observar mais de uma característica de um experimento. Por exemplo, não somente a renda das mulheres em Ribeirão Preto nos interessa, mas o seu consumo alimentar também julgamos importante para o projeto.

Portanto, queremos observar duas características de forma simultânea das mulheres: sua renda e seu consumo alimentar. Ou seja, duas características simultaneamente do mesmo experimento $\epsilon$ que foi observar as mulheres no município.

Apesar de termos coletados duas informações, temos na realidade três informações. A informação da renda, a informação do consumo alimentar e a informação de como renda e consumo alimentar interagem.

**Visualização gráfica**

Vejamos agora um exemplo de variável aleaória bidimensional:

**Normal Bivariada**:

Abaixo tem-se uma variável aleatória $(X,Y)$ com distribuição normal bivariada com a esperança de $X$ igual a 1, de $Y$ igual a 0, o desvio-padrões iguais a 3 e 2 respectivamente. Aqui consideremaos a correlação de 1 (veremos mais a frente esse conceito)

```{r echo = TRUE, fig.cap= "Normal Bivariada",fig.height = 3.5, fig.width = 6}
library(mnormt)

#Para tornar reproduzível
set.seed(0)

#cCriando a normal bivariada
x     <- seq(-3, 3, 0.1) 
y     <- seq(-3, 3, 0.1)
mu    <- c(1, 0)
sigma <- matrix(c(3, 1, 1, 2), nrow=2)
f     <- function(x, y) dmnorm(cbind(x, y), mu, sigma)
z     <- outer(x, y, f)

#Criando um gráfico de superfície
persp(x, y, z, theta=-30, phi=25, expand=0.6, ticktype='detailed')
```

Surge aqui um conceito importante que tenta medir como as características da população se relacionam - uma medida do relacionamento. Assim:

[O que acontece com o consumo de alimentos quando a renda das mulheres sobem?]{.underline}

#### Covariância e Correlação

Duas medidas que tentam mensurar o "grau de associação" linear entre X e Y são:

**Covariância**

$$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]$$

Ela mede a variabilidade conjunta de uma variável aleátoria multidimensional. Como no caso da variância, ela sofre do efeito das escalas de medidas. Para corrigir dividimos pelos desvios padrões. Surge dessa maneira a medida de correlação.

**Correlação**

$$\rho_{X,Y}=\frac{E[(X-E(X))(Y-E(Y))]}{\sqrt{Var(X)Var(Y)}}$$ 

::: callout-warnig

## Correlação

A correlação mede o **GRAU DE ASSOCIAÇÃO LINEAR**. Associações não lineares não são capturadas pela correlação.

:::


::: callout-note

## Lendo a Correlação

A correlação $\rho_{X,Y}$ varia de -1 até 1. Sendo que:

$\rho$ próximo a 1 e -1 indicam alto grau de linearidade e $\rho$ próximo a 0 indica ausência de relação linear - mas não diz nada sobre relações não-lineares.
:::


**Visualização gráfica**

Veja no gráfico abaixo que a variável 4 e 5 possuem correlação perfeita, igual a -1. E as variáveis 3 e 1 não possuem grau de associação linear, correlação próxima a 0.

```{r echo = FALSE, fig.cap= "Gráfico de correlação para variáveis simuladas v1 a v5",fig.height = 5, fig.width = 5, fig.align = "center"}
library(psych)
data <- data.frame( var1 = 1:100 + rnorm(100,sd=20), v2 = 1:100 + rnorm(100,sd=27), v3 = rep(1, 100) + rnorm(100, sd = 1)) 
data$v4 = data$var1 ** 2 
data$v5 = -(data$var1 ** 2) 
pairs.panels(data)
```




## Conceitos Básicos Inferência Estatística

### População, Amostra, Parâmetros e Estimadores


## Estatisticas Descritivas: Medidas Numéricas a partir da amostra

Existem outros métodos númericos que se constituem como alternativas adcionais para sintetizar os dados. Podemos dividir as medidas numericas em duas, temos as medidas de posíção e as de variabilidade.

**Medidas de posição:** Média, Mediana, Moda Percentis e Quartis.

**Medidas de Variabilidade:** Amplitude, Amplitude interquartil, Variância, Desvio Padrão e Coeficiente de Variação.

**Medidas de associação entre duas variáveis:** Covariancia e o Coeficiente de Correlção.

Vamos apresentar as formulas de algumas dessas principais medidas.

**Media Amostral:**

$$\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i$$



**Mediana:**

Organize os dados em ordem crescente.
a) Para um numero impar de observações a mediana é o valor que ocupa a posição central.

b) para um número par de observações, a mediana é a média dos dois valores centrais.

**Moda:**
Moda é o valor que ocorre com mais frequência.


**Percentil:**
O p-esimo percentil é um valor tal que ao menos p por cento das observações são menores ou iguais à ele e pelo menos (100-p) por cento das observações são maiores ou iguais a esse valor.

Etapas: para calcular o p-ésimo percentil

Etapa 1. Organize os dados em ordem crescente.
Etapa 2: Calcule um indice, $i$ tal que
$$i = \frac{p}{100} \times n$$
onde $p$ é o percentil procurado

Etapa 3: a) Se $i$ não for um número inteiro, arredondeo-o para cima. O próximo número inteiro maior que $i$  denota a posição do p-esimo percentil. b) Se $i$ for um número inteiro o p-esimo percentil será a média dos valores que o ocupam as posições $i$ e $i + 1$.

**Quartis**
Os quartis são medidas estatísticas que dividem um conjunto de dados ordenados em quatro partes iguais.

Existem três quartis principais:

Primeiro Quartil (Q1): Representa o valor abaixo do qual está situada a primeira quarta parte (ou 25%) dos dados quando eles estão ordenados em ordem crescente. Matematicamente, o primeiro quartil é o valor que divide os dados em 25% (ou 0.25) abaixo e 75% (ou 0.75) acima desse ponto.


Segundo Quartil (Q2): Corresponde à mediana dos dados, dividindo o conjunto em duas metades iguais. É o valor que separa os 50% inferiores dos 50% superiores dos dados. O segundo quartil é frequentemente representado pela mediana.

Terceiro Quartil (Q3): Indica o valor abaixo do qual está situada a terceira quarta parte (ou 75%) dos dados quando eles estão ordenados. Assim como o primeiro quartil, o terceiro quartil divide os dados em 75% (ou 0.75) abaixo e 25% (ou 0.25) acima desse ponto

![quartis](quartis.png)


**Amplitude:**

$$\text{Amplitude} = \text{Maior Valor} - \text{Menor Valor}$$

**Amplitude interquartil:**

A amplitude interquartil é dada pela diferenca entre o terceiro ($Q_3$) e o primeiro quartil ($Q_1$).

$$IQR = Q_3 - Q_1$$


**Medidas de Variabilidade**

A variância amostral é uma medida estatística que indica o quão dispersos estão os dados em relação à média amostral. Em outras palavras, ela quantifica a extensão das diferenças individuais entre os valores observados e a média da amostra.


A variância populacional é semelhante à variância amostral, mas é calculada utilizando todos os dados de uma população em vez de uma amostra. Ela descreve a dispersão dos dados em relação à média populacional.

**Variancia Amostral**:

$$s^2 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})^2}{n-1}$$
onde $\bar{x}$ é a média amostral.


O **desvio padrão** é derivado da variância. Podemos qualcular essa estatistica da seguinte maneira:


Desvio padrão amostral:

$$s = \sqrt{s^2} = \sqrt{\frac{\sum_{i=1}^{n} (x_i - \bar{x})^2}{n-1}}$$

**Coeficiente de Varição**:

O coeficiente de variação (CV) é uma medida de dispersão relativa que expressa a variabilidade dos dados como uma porcentagem da média.

$$\text{CV} = \left( \frac{\text{Desvio padrão}}{\text{Média}} \right) \times 100\%$$

O r calcula essas estatisticas de maneira muito eficiente com apenas uma linha de comando.A função `summary()` em R fornece um resumo estatístico básico das variáveis numéricas presentes em um data frame. Ao aplicar `summary()` a um data frame, as seguintes estatísticas são calculadas para cada coluna numérica:

Mínimo (Min): O menor valor observado na variável.
1º Quartil (Q1): O valor que separa os 25% inferiores dos dados.
Mediana (50º Percentil): O valor que separa os 50% inferiores dos 50% superiores dos dados.
Média (Mean): A média aritmética dos valores.
3º Quartil (Q3): O valor que separa os 75% inferiores dos dados.
Máximo (Max): O maior valor observado na variável.


Vamos calcular outras estatísticas

```{r}

load("dados.RData")


```


Medida de Associação entre duas variáveis:

Covariância entre duas variáveis: A covariância entre duas variáveis X e  Y é uma medida estatística que descreve como essas variáveis variam juntas. Em outras palavras, a covariância indica a tendência de X e Y de se moverem na mesma direção (covariância positiva) ou em direções opostas (covariância negativa).

$$\text{Cov}(X, Y) = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})(Y_i - \bar{Y})$$

Coeficiente de Correlação: O coeficiente de correlação entre duas variáveis X e Y é uma medida estatística que descreve a força e a direção da relação linear entre essas variáveis. O coeficiente de correlação é frequentemente representado pelo coeficiente de correlação de Pearson, $r_{XY}$.

$$r_{XY} = \frac{\text{Cov}(X, Y)}{s_X s_Y}$$
O coeficiente de correlação de Pearson é uma medida amplamente utilizada para avaliar a relação linear entre variáveis, pois fornece uma interpretação padronizada da força e direção da relação, independentemente das unidades das variáveis.








