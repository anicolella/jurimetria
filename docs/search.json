[
  {
    "objectID": "estatistica.html",
    "href": "estatistica.html",
    "title": "11  Uma Introdução à Estatística",
    "section": "",
    "text": "11.1 Porque Estudar Estatística?\nPodemos dizer que a existência da estatística e de outras ciências está conectada a existência de problemas. Não somente a ciência mas o nosso trabalho está conectado a superação de problemas cotidianos. Tomar decisão é o dia a dia do gestor.\nSegundo Popper “we study not disciplines, but problems. Often, problems transcend the boundaries of a particular discipline”\nA questão central é: Como solucionamos os problemas? Utilizamos a melhor estratégia? A solução foi boa?\nflowchart LR\n  A[PROBLEMA] --&gt; B[Estratégia de Decisão]\n  B --&gt; C{Solução é BOA?}",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Uma Introdução à Estatística</span>"
    ]
  },
  {
    "objectID": "estatistica.html#porque-estudar-estatística",
    "href": "estatistica.html#porque-estudar-estatística",
    "title": "11  Uma Introdução à Estatística",
    "section": "",
    "text": "11.1.1 Os dois sistemas cognitivos\nOs livros abaixo são boas referências sobre a tomada de decisão.\n\n\n\n\n\n\nKahneman: Rápido e Devagar- Duas Formas de Pensar\n\n\n\n\n \n\n\n\n\n\nBazerman e Moore: Processo Decisório\n\n\n\n\n\nExistem dois sistemas que utilizamos para tomar decisão. O chamado Sistema 1 e o chamado Sistema 2. Segue uma breve descrição de cada um:\nSistema 1:\n\nIntuitivo, rápido, automático, sem esforço, implícito e emocional\n\nPressa,\nFalta de tempo,\nProblemas menos importante\nMais Falhas/Erros\n\n\nSistema 2\n\nRaciocíonio lento, consciente, esforçado, explícito, lógico\n\nRequer tempo,\nMais recursos\nProblemas mais importante\nMenos Falhas\n\n\nPara o Sistema 1 usamos a nossa intuição que chamamos de Heurística. Vejamos um pouco mais sobre esse sistema.\nHEURÍSTICA\nSão rotinas inconscientes ou atalhos que o nosso cérebro utiliza para lidar com a complexidade.\n\nModelo/Regras Intuitivas.\nPróprio do Sistema 1.\nApesar de processo sofisticado, são passíveis de falhas. Intuição falha\n\nUm Exemplo\nVeja a figura abaixo retirada do livro do Bazerman.Responda rápido.\nQual delas tem o tampo mais quadrado?\n\n\n\nBazerman: Exemplo das mesas\n\n\nSe você achou que é a segunda mesa, você está alinhado com a grande maioria. Nesse caso você usou o seu sistema 1\nVamos repitir a pergunta:\nQual delas tem o tampo mais quadrado?\nAgora use uma régua para medir as mesas. Usamos aqui o sistema 2. Mais tempo e recursos são utlizados. Qual mesa agora você considera mais quadrada? Mudou sua opinião?\nCom a régua vemos que as mesas são iguais. Isso mostra que a nossa intuição FALHA.\nTipos de Heurísticas\n\nHeurística da disponibilidade: Usamos o que está mais próximo na memória para calcular a probabilidade.\nHeurística da representatividade: Buscamos aquilo que reforça o padrão.\nHeurística da hipótese positiva: Assumimos que uma determinada hipótese é verdadeira e não olhamos o contrafactual.\nHeurística do afeto: Decisão considera o emocional. Seu humor afetam as decisões.\n\nPara contornar os problemas da intuição e seus viéses na tomada de decisão o primeiro passo é compreender que eles existem e estarmos alerta. E para problemas maiores o uso do sistema 2 torna-se relevante.\nUma das principais ferramentas do sistema 2 é a Estatística. Com os avanços computacionais essa ciência tem se destacado como um dos elementos centrais do data science. Abaixo a figura resume as diversas áreas de desenvolvimento da análise de dados, obviamente não exaustiva:\n\n\n\nFluxograma da Análise de Dados\n\n\nNosso objetivo é explorar nessa seção a análise descritiva. Chamado hoje no Business Intelligence, que e uma das áreas do Data Science.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Uma Introdução à Estatística</span>"
    ]
  },
  {
    "objectID": "estatistica.html#conceitos-básicos-de-estatística",
    "href": "estatistica.html#conceitos-básicos-de-estatística",
    "title": "11  Uma Introdução à Estatística",
    "section": "11.2 Conceitos Básicos de Estatística",
    "text": "11.2 Conceitos Básicos de Estatística\nNovamente começamos com um problema e esse definirá a nossa análise. Vejamos alguns problemas que poderiam nos interessar…\n\n\n\n\n\n\nProblema 1\n\n\n\nO prefeito de Ribeirão Preto vai lançar uma política que fornece vouchers de alimentação para mulheres que estão em situação de pobreza.\nProblema: Qual o valor que devo reservar ao programa? Quantas mulheres serão atendidas?\n\n\n\n\n\n\n\n\nProblema 2\n\n\n\nO TJSP vai lançar um programa para reduzir o tempo médio em processos de feminicídio.\nProblema: Qual o tempo médio de um processo de feminicídio?\n\n\n\n\n\n\n\n\nProblema 3\n\n\n\nO O governo federal vai lançar um programa para capacitar mulheres que estão fora do mercado de trabalho.\nProblema: Quantas mulheres serão alvos dessa política?\n\n\n\n11.2.1 A População e suas Características\nO problema nos define a população que estou interessado. Vamos seguir, a princípio, com o nosso probelma 1 para definirmos alguns conceitos importantes.\nNo problema 1: me interessa compreender a renda das mulheres que moram em Ribeirão Preto em dado ano. Para ficar simples vamos abreviar o que nos interessa\n\\[X=\\text{Renda das mulheres que moram em Ribeirão Preto em determinado ano}\\] Agora posso utilizar o X no lugar do nome. Olhando para a população e pensando que cada nível de renda pode ser representada por uma cor, teremos a seguinte imagem pouco de como a renda se distribui nessa população:\n\n\n\nRenda pc das mulheres de Ribeirão Preto.\n\n\nA questão é: quais cores existem e quantas peças de cada cor temos? Para isso usamos um experimento\nEXPERIMENTO ALEATÓRIO\nO experimento em ciências sociais aplicadas em geral está associada a observação sistemática de pessoas, cidades, empresas ou processos. A ideia é:\n\nSortear pessoas e observar a sua caracteristica de forma indefinida e sempre na mesma condição.\n\nNão consigo dizer o que vai sair no próximo sorteio, apenas consigo descrever os resultados possíveis\nSe repetir o experimento um número grande de vezes uma regularidade aparece.\n\nSe eu conseguir sortear de forma indefinida e na mesma condição as mulheres que moram em Ribeirão Preto e perguntar sobre a sua renda. Eu consigo reorganizar a figura acima da seguinte forma:\n\n\n\nRenda pc das mulheres de Ribeirão Preto.\n\n\nESPAÇO AMOSTRAL\nAgora conseguimos organizar os nossos resultados em um lugar chamado espaço amostral. Nele teremos todas as cores (azul, branca, amarela…) que podem acontecer e o número de peças de cada cor (a chance). Em outras palavras teremos todos os possíveis valores de \\(X\\) e suas probabilidades.\nVARIÁVEL ALEATÓRIA\nQuanto representamos esse espaço amostral em formato de números é o que chamamos de Variável Aleatória (V.A.). A V.A. é a combinação de tudo que pode acontecer, ou seja, todas as rendas que existem associadas a probabilidade de cada uma das rendas acontecerem.\nExistem dois tipos principais de variáveis aleatórias: discretas e contínuas.\nVARIÁVEIS ALEATÓRIAS DISCRETAS\nÉ um tipo de variável que conseguimos colocar em lista, seja finita ou infinita \\(x_1; x_2;...; x_n;...\\) e associa-se a cada um dessses valores uma probabilidade \\(p(x_1); p(x_2);...; p(x_n);...\\)\nPodemos pensar aqui se a pessoa é casada, solteira, divorciada, viúva ou outra condição. Se no processo classificamos como homicídio ou feminicídio, se é procedente ou improcedente, se mora na área urbana ou rural…\nNa figura abaixo iremos coletar de 20 processos de homicídio e gostariamos de saber quando é classificado como feminicídio e quanto é classificado como homicídio (p=0,3).\n\nfeminicidio &lt;- 0:20\n\nplot(feminicidio,dbinom(feminicidio,size=20,prob=.3),\n     type='h',\n     main='Distribuição Binomial (n=20, p=0.3)',\n     ylab='Probabilidade',\n     xlab ='Feminicídio',\n     lwd=3)\n\n\n\n\nDistribuição Normal\n\n\n\n\nVARIÁVEIS ALEATÓRIAS CONTÍNUAS\nPor outro lado, uma variável aleatória contínua pode assumir infinito valores dentro de um intervalo específico. Agora temos infinitas possibilidades de resultados para \\(X\\) e agora associamos uma função \\(f(x)\\) que irá descrever o comportamento da probabilidade.\nPor exemplo, a altura de uma pessoa, a sua renda, a sua idade, o tempo que demora um processo.\nAbaixo temos uma representação de uma distriuição continua da renda das mulheres em Ribeirão Preto, chamada distribuição normal:\n\nrm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.\nx&lt;-seq(700,1300,1)\nfdnorm&lt;-dnorm(x = x, mean = 1000, sd=100)  \nfdanorm&lt;-pnorm(q = x, mean = 1000, sd=100)\ncurve(dnorm(x,1000,100),xlim=c(700,1300),main='',xaxt=\"n\",xlab=\"Renda pc Mulheres\", ylab=\"f(x)\",col=\"darkblue\",cex.axis=0.65, cex.lab=0.8) \naxis(1,at=c(900, 1000, 1100),labels =\n       c(\"-DP(X)\",\"E(x)\",\"DP(x)\"),cex.axis=0.65, cex.lab=0.8) \nlines(x=c(1000,1000),y=c(0,fdnorm[x==1000]),lty=2, col=\"black\") \nlines(x=c(1100,1100),y=c(0,fdnorm[x==1100]),lty=2, col=\"black\")\nlines(x=c(900,900),y=c(0,fdnorm[x==900]),lty=2, col=\"black\")\n\n\n\n\nDistribuição Normal\n\n\n\n\n\n11.2.1.1 Esperança e Variância\nO formato das distribuições vistas dependem principalmente de dois parâmetros: A esperança (média ponderada) que é uma medida de centralidade e a variância que é uma medida de dispersão.\nESPERANÇA - \\(E(X)\\)\nA esperança de uma variável aleatória ou média populacional representa o valor médio que se espera observar se o fenômeno fosse repetido muitas vezes sob as mesmas condições. Em outras palavras, é uma medida de tendência central que indica para onde os resultados tendem a convergir (a média). É definida como a média ponderada de todos os possíveis resultados de \\(X\\), onde os pesos são dados pelas probabilidades desses resultados ocorrerem.\n\nQual o tempo médio de um processo de homicídio até a sentença?\nQual a a média de procedência de processos relacionados à violência contra a mulher?\n\n\n\n\n\n\n\nDefinição Formal\n\n\n\n\n\nA esperança de \\(X\\), \\(E(X)\\), é calculada como:\n\\[E(X) = \\sum_{x} x \\cdot P(X = x)\\]\npara variáveis discretas.\n\\[E(X) = \\int_{-\\infty}^{\\infty} x \\cdot f(x)\\]\npara variáveis contínuas\n\n\n\nVARIÂNCIA POPULACIONAL - \\(Var(X)\\)\nA variância é uma medida que captura como os dados populacionais se dispersão em relação a sua média (ou esperança). Suponha que conhecemos o tempo de tramitação de processos judiciais. A Variância é uma medida que nos ajuda a entender o quão espalhados estão os tempos de cada processo em relação ao tempo médio. Como não importa se durou mais ou menos que a média, usamos a medida do desvio ao quadrado!\n\n\n\n\n\n\nDefinição Formal\n\n\n\n\n\nA Variância é uma medida de desvio em relação a média, ao quadrado, definida como:\n\\[Var(X) =\\frac{1}{N} \\sum_{1}^{N} (X_i-E(X))^2\\]\nOu podemos assim representar:\n\\[\\text{Var}(X) = E(X^2) - [E(X)]^2\\]\n\n\n\nDESVIO PADRÃO POPULACIONAL - \\(DP(X)\\)\nA variância é uma medida ao quadrado. Se estamos falando da renda seria uma medida da dispersão ao quadrado, ou seja, em \\(R\\$^{2}\\), se for o tempo, \\(T^{2}\\). Para retornar a unidade original usamos a raiz quadrada da variância, que chamamos de desvio padrão.\n\n\n\n\n\n\nDefinição Formal\n\n\n\n\n\nO desvio padrão é a raiz quadrada da variância:\n\\[DP(X)=\\sqrt{Var(X)}\\]\n\n\n\nEXEMPLO\nVejamos o que acontece quando mudamos a esperança e o desvio padrão.\n\nNo gráfico em azul temos a esperança igual a 10 e devio padrão de 2,5.\nNo gráfico em vermelho temos esperança de 20 e desvio padrão de 10.\nE no grafico em verde temos esperança de 10 e desvio padrão de 1.\n\nNota-se que quanto menor o desvio padrão mais concentrados são os valores que podem acontecer.\n\ncurve(dnorm(x,mean=10,sd=sqrt(2.5)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs=\"i\",yaxs=\"i\",ylab=\"\", col=\"darkblue\") \npar(new=T)\ncurve(dnorm(x,mean=20,sd=sqrt(10)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs=\"i\",yaxs=\"i\",ylab=\"\", col=\"darkred\") \npar(new=T)\ncurve(dnorm(x,mean=20,sd=sqrt(1)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs=\"i\",yaxs=\"i\",ylab=\"\", col=\"darkgreen\") \n\n\n\n\nMédias e desvios distintos entre distribuições\n\n\n\n\n\n\n\n11.2.2 Variáveis Aleatórias Bidimensionais\nMuito provavelmente nos interessa observar mais de uma característica de um experimento. Por exemplo, não somente a renda das mulheres em Ribeirão Preto nos interessa, mas o seu consumo alimentar também julgamos importante para o projeto.\nPortanto, queremos observar duas características de forma simultânea das mulheres: sua renda e seu consumo alimentar. Ou seja, duas características simultaneamente do mesmo experimento \\(\\epsilon\\) que foi observar as mulheres no município.\nApesar de termos coletados duas informações, temos na realidade três informações. A informação da renda, a informação do consumo alimentar e a informação de como renda e consumo alimentar interagem.\nVISUALIZAÇÃO GRÁFICA\nVejamos agora um exemplo de variável aleaória bidimensional:\nNormal Bivariada:\nAbaixo tem-se uma variável aleatória \\((X,Y)\\) com distribuição normal bivariada com a esperança de \\(X\\) igual a 1, de \\(Y\\) igual a 0, o desvio-padrões iguais a 3 e 2 respectivamente. Aqui consideremaos a correlação de 1 (veremos mais a frente esse conceito)\n\nlibrary(mnormt)\n\n#Para tornar reproduzível\nset.seed(0)\n\n#cCriando a normal bivariada\nx     &lt;- seq(-3, 3, 0.1) \ny     &lt;- seq(-3, 3, 0.1)\nmu    &lt;- c(1, 0)\nsigma &lt;- matrix(c(3, 1, 1, 2), nrow=2)\nf     &lt;- function(x, y) dmnorm(cbind(x, y), mu, sigma)\nz     &lt;- outer(x, y, f)\n\n#Criando um gráfico de superfície\npersp(x, y, z, theta=-30, phi=25, expand=0.6, ticktype='detailed')\n\n\n\n\nNormal Bivariada\n\n\n\n\nSurge aqui um conceito importante que tenta medir como as características da população se relacionam - uma medida do relacionamento. Assim:\nO que acontece com o consumo de alimentos quando a renda das mulheres sobem?\n\n11.2.2.1 Covariância e Correlação\nDuas medidas que tentam mensurar o “grau de associação” linear entre X e Y são:\nCOVARIÂNCIA\nA covariância mede como duas variáveis se movem conjuntamente. Quando uma aumenta e a outra tende a aumentar também, a covariância é positiva. Quando uma cresce e a outra tende a diminuir, a covariância é negativa. Em outras palavras, ela indica o sentido da associação entre as variáveis, se caminham na mesma direção ou em direções opostas.\nPor exemplo, podemos observar a covariância entre renda e consumo: quando a renda aumenta, o consumo normalmente também aumenta, indicando uma covariância positiva.\nEntretanto, a covariância é expressa nas unidades originais das variáveis (por exemplo, em reais e porcentagem), o que dificulta a comparação entre diferentes pares de variáveis.\n\n\n\n\n\n\nDefinição Formal\n\n\n\n\n\nA covariância pode ser assim medida:\n\\[Cov(X,Y)=E[(X-E(X))(Y-E(Y))]= E(X.Y)-E(X).E(Y)\\]\n\n\n\nCORRELAÇÃO\nPara contornar o problema das diferentes unidades de medida, utilizamos a correlação, que é uma versão padronizada da covariância. Isto é, a covariância é dividida pelo desvios padrões das variáveis envolvidas. Ela mede a força e direção da relação linear entre duas variáveis, mas varia sempre entre –1 e 1, sem unidade de medida. Assim, uma correlação próxima de 1 indica associação positiva perfeita, –1 associação negativa perfeita, e 0 ausência de relação linear.\n\n\n\n\n\n\nDefinição Formal\n\n\n\n\n\nA correlação pode ser assim medida:\n\\[\\rho_{X,Y}=\\frac{E[(X-E(X))(Y-E(Y))]}{\\sqrt{Var(X)Var(Y)}}=\\frac{Cov(X,Y)}{DP(X).DP(Y)}\\]\n\n\n\nAtenção\n\n\n\n\n\n\nCorrelação\n\n\n\nA correlação mede o GRAU DE ASSOCIAÇÃO LINEAR. Associações não lineares não são capturadas pela correlação.\n\n\n\n\n\n\n\n\nInterpretando a Correlação\n\n\n\nA correlação \\(\\rho_{X,Y}\\) varia de -1 até 1. Sendo que:\n\\(\\rho\\) próximo a 1 e -1 indicam alto grau de linearidade e \\(\\rho\\) próximo a 0 indica ausência de relação linear - mas não diz nada sobre relações não-lineares.\n\n\nVISUALIZAÇÃO GRÁFICA\nVeja no gráfico abaixo que a variável 4 e 5 possuem correlação perfeita, igual a -1. E as variáveis 3 e 1 não possuem grau de associação linear, correlação próxima a 0.\n\n\nWarning: package 'psych' was built under R version 4.4.1\n\n\n\n\n\nGráfico de correlação para variáveis simuladas v1 a v5",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Uma Introdução à Estatística</span>"
    ]
  },
  {
    "objectID": "estatistica.html#conceitos-básicos-inferência-estatística",
    "href": "estatistica.html#conceitos-básicos-inferência-estatística",
    "title": "11  Uma Introdução à Estatística",
    "section": "11.3 Conceitos Básicos Inferência Estatística",
    "text": "11.3 Conceitos Básicos Inferência Estatística\nDado a nossa pergunta ou problema, gostariamos de saber as carcateística de uma população.\nEntretantom um processo de levantamento de informações é em geral caro e em muitas situações é destrutivo. Em ciências sociais estamos interessados em características de pessoas, empresas, municípios, estados, países etc. Não é destrutivo mas é uma coleta cara. Por exemplo, o Censo demográfico de 2010 custou R$ 1,3 bilhões, ou aproximadamente R$ 2,2 bi em reais de 2020. O valor é de aproximadamente R$ 35,00 por domicílio.\nDessa forma nosso objetivo aqui é:\n\n\n\n\n\n\nObjetivo\n\n\n\nA partir de uma amostra da população realizar inferência sobre toda a população\n\n\n\n11.3.1 Exemplos do príncipio no dia a dia\nPense nessas situações:\n\nGlicose: Para medir a glicose muitos pacientes usam uma gota de sangue e um pequeno aparelho. A partir dele sabem quanto tem no corpo todo, basta uma gota para termos boa certeza de quanto é taxa de glicose!\nSal: Para saber se a quantidade de sal está adequada em uma grande panela de arroz, basta uma pequena colher de chá para termos uma boa certeza!\nDoçura: Abacaxis às vezes são vendidos em caminhões na rua. Quando paramos provamos e são doces. Compramos 4 por 10. Qual a certeza que esses que vc está levando estejam também doces? É diferente das situações anteriores?\n\nCom certeza vc deve ter pensado que essas situações tem grau de certeza variáveis. A diferença está em quão homogênea é a característica na população, o sal no arroz e a glicose no sangue devem ser muito bem distribuidas, ou seja, bem homogêneas. Já a doçura no abacaxi deve ter distribuição maior e provar apenas um abacaxi não nos dá uma ideia do todo.\nEsse é um erro muito comum, a partir de uma ou poucas observações dizer que o todo se comporta da mesma maneira , esse erro se agrava quando maior é a heterogeneidade!!!\n\n\n11.3.2 População, Amostra, Parâmetros e Estimadores\n\n\n11.3.3 População e amostra\n\n\n\n\n\nflowchart LR\n  A[POPULAÇÃO] --&gt; B[Totalidade das observações sob Investigação]\n  A --&gt; C[AMOSTRA]\n  C --&gt; D[Subconjunto da População]\n\n\n\n\n\n\nA definição da população depende da pergunta de pesquisa ou análise. Se queremos saber qual o salário médio dos empregados do setor industrial no estado de São Paulo para determinado ano, nossa população são todos os funcionários das indústrias instaladas no estado de São Paulo para esse ano. Se queremos os determinantes do desempenho escolar dos alunos do ensino fundamental no Brasil em 2019, nossa população será esse grupo de alunos nesse ano. Se quisermos avaliar o gasto municipal no ano anterior as eleições no Brasil, temos nossa população formada pelos municípios para o ano de análise.\n\n\n\n\n\n\nPopulação\n\n\n\nQuem define a população é o objetivo do seu trabalho!! Ou seja, seu problema de pesquisa\n\n\n\n\n11.3.4 Amostragem Aleatória Simples\nExistem várias maneiras de fazer uma análise aleatória, uma delas é a simples. Vejamos primeiro um processo de amostragem não aleatório e que possui tendenciosidade. A figura abaixo mostra esse processo de amostragem errado:\n\n\n\nUm processo de amostragem viesádo. Fonte:Data Basecamp\n\n\nObserva-se que existe uma supervalorização do vermelho e uma subvalorização do azul. Chegariamos a conclusão, caso isso fosse uma pesquisa eleitoral, que o candidato vermelho, segunda amostra teria mais chance de ganhar e o azul quase nenhuma chance. O que não condiz com a população. Dizemos que temos uma amostra viesada ou tendenciosa.\nUm processo de amostragem aleatório requer que as características presentes na população estejam presentes na amostras e estejam balanceadas, ou seja, que a sua leitura represente bem o todo.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Uma Introdução à Estatística</span>"
    ]
  },
  {
    "objectID": "estatistica.html#estatística-e-parâmetro",
    "href": "estatistica.html#estatística-e-parâmetro",
    "title": "11  Uma Introdução à Estatística",
    "section": "11.4 Estatística e Parâmetro",
    "text": "11.4 Estatística e Parâmetro\nPARÂMETROS\n\n\n\n\n\nflowchart LR\n  A[PARÂMETRO] --&gt; B[Medida que descreve uma característica da população]\n\n\n\n\n\n\nOs parâmetros definem as características de uma população. Qual a renda média da população, qual o desemprego médio da população, qual o desempenho médio educacional, qual a expectativa de vida média na população, qual o tempo médio de processos de homicídios etc. São características que em geral não observamos.\nUma pergunta, qual o tempo médio de um processo de feminicídio até a sentença? Perceba que mesmo características da população que conhecemos muitas vezes são não observadas. Temos que nos valer de uma parte e tentar estimar o que seriam os valores dessas características.\nESTATÍSTICAS\n\n\n\n\n\nflowchart LR\n  A[ESTATÍSTICA] --&gt; B[Medida que descreve uma característica da amostra]\n\n\n\n\n\n\nVamos supor que coletamos mil processos judiciais para analisar o tempo de tramitação até a sentença. Cada processo representa uma realização de da variável aleatória, neste caso, o tempo necessário para que o processo tenha sentença. Esses processos pertencem a uma população maior de todos os processos existentes, e o que observamos é apenas uma amostra dessa população.\nA partir dessas observações amostrais, calculamos estatísticas, que são resumos numéricos dos dados amostrais, como médias, proporções, desvios, mínimos ou máximos. Essas estatísticas descrevem a amostra que temos em mãos. São estimativas dos parâmetros populacionais, que são os valores verdadeiros (e geralmente desconhecidos) da população como um todo.\nÉ importante notar, porém, que se repetíssemos o mesmo procedimento de coleta com outros mil processos, provavelmente obteríamos valores diferentes de médias e desvios. Isso ocorre porque as estatísticas variam de amostra para amostra.\n\n\n\n\n\n\nDefinição Formal\n\n\n\n\n\nSejam \\(x_1, x_2,..., x_{n}\\) os valores medidos a cada para cada medição de \\(X\\). Podemos definir uma estatística como:\n\\[ t= H (x_1, x_2, ..., x_{n})\\]\nAlguns exemplos de T:\n\\[ \\text{Média}: \\ \\overline{x}=\\frac{\\sum_{i=1}^{n} x_i}{n}\\]\n\\[ \\text{Variância:} \\ s^{2}= \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\overline{x})^{2} \\]\n\\[ x_{(1)}: Min\\{x_1, ..., x_n\\}\\]\n\n\n\nVejamos a tabela abaixo que já faz uma primeira associação entre estatística e parâmetro:\n\n\n\n\n\n\n\n\n\nParâmetro\n\nEstatística\n\n\n\n\n\nEsperança\n\\(E(X)=\\mu\\)\n\\(\\bar{X}\\)\nMédia\n\n\nVariância Pop.\n\\(Var(X)=\\sigma^2\\)\n\\(S^2;\\sigma^2\\)\nVariância Amostral\n\n\nMediana Pop.\nMd\nmd\nMediana Amostral\n\n\nProporção Pop.\np\n\\(\\hat{p}\\)\nProporção Amostral\n\n\n\nTabela 1 - Parâmetros populacionais e as Estatísticas associadas\nComo regra geral, os parâmetros são representados por letras gregas e as estatística com letras do nosso alfabeto (latino) ou letra grega com com chapéu para indicar que é uma estatística.\nESTIMADORES\nUm estimador é uma estatística calculada a partir da amostra que é usada para estimar um parâmetro desconhecido da população. Nos permitem fazer inferências sobre os parâmetros com base nos dados amostrais. Por exemplo, a média amostral é um estimador da média populacional, e a proporção amostral é um estimador da proporção populacional.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Uma Introdução à Estatística</span>"
    ]
  },
  {
    "objectID": "estatistica.html#teste-de-hipotese-parâmetros.",
    "href": "estatistica.html#teste-de-hipotese-parâmetros.",
    "title": "11  Uma Introdução à Estatística",
    "section": "11.5 Teste de Hipotese (Parâmetros).",
    "text": "11.5 Teste de Hipotese (Parâmetros).\nAlgumas vezes gostariamos de testar se uma teoria é verossímil com a realidade ou mesmo testar teorias diferentes e verificar qual seria a mais plausível com base na realidade.\nDessa forma, gostariamos de testar se uma sobre a população é mais plausível, ou seja, se os dados amostrais trazem evidências que apoiam ou não essa hipótese. Por exemplo:\n\nVerificar se um determinado medicamento não tem efeito sobre a mortalidade causada por um determinado virus ou se possui efeito.\nVerificar se a quantidade de gordura anunciado pelo fabricante de um produto realmente está correta ou é maior.\nSe a afirmativa de um canditado de que possui a maioria dos votos é verdadeira ou é menor.\nVerificar se as rendas entre duas comunidades são as mesmas para podermos lançar uma política de apoio\nVerifcar se uma política do aumento do recurso as empresas não afeta falência ou se tem efeito.\nse o tempo médio de encaminhamento e deferimento de medida protetiva de urgência é menor do que 48 horas em casos de violência doméstica e familiar contra a mulher.\n\nAqui faremos algo muito parecido a presunção de inocência, assumimos que a pessoa ou empresa é “inocente”.\n\nO medicamento não tem efeito,\nO teor de gordura está certo,\nO candidato tem maioria,\nAs comunidades possuem a mesma renda,\nO recurso financeiro não afeta o número de falências\nO deferimento ocorre em até 48h.\n\n\n\n\n\n\n\nA Intuição\n\n\n\nPartimos da premissa de que a hipótese inicial é a correta e tentamos verificar com os fatos (dados amostrais) se essa hipótese colocada é verossímil.\n\n\n\n11.5.1 Construíndo a Hipótese Nula\nImaginemos o seguinte caso. Um estudo sobre a eficiência do Judiciário sugere que a duração média de um determinado tipo de processo na Justiça Federal é de 600 dias. No entanto, advogados e operadores do direito argumentam que, na prática, esse tempo pode ser maior devido a atrasos processuais e recursos frequentes. A questão é: a estimativa oficial está correta ou os operadores do direito têm razão?\nDessa forma, temos duas hipóteses distintas:\n\nA primeira afirma que o tempo médio de duração do processo, \\(\\mu\\), é de 600 dias,\nA segunda sugere que a duração real é superior a 600 dias.\n\nVamos assumir que a estimativa oficial está correta até que se prove o contrário, e chamaremos essa afirmativa de hipótese nula (\\(H_0\\)):\n\\[H_0: \\quad \\mu = 600 \\text{ dias}\\]\nJá a hipótese alternativa (\\(H_1\\)), que representa a teoria concorrente dos operadores do direito, sugere que a média real de duração do processo é maior:\n\\[ H_1: \\quad \\mu &gt; 600 \\text{ dias}\\]\nNosso problema, então, é decidir se devemos aceitar ou rejeitar a hipótese nula \\(H_0\\) — de que o tempo médio é de 600 dias — em favor da hipótese alternativa \\(H_1\\), que afirma que os processos, na realidade, levam mais tempo para serem concluídos.\nJuntas:\n\\[H_0: \\quad \\mu = 600\\] \\[H_1: \\quad \\mu &gt; 600\\]\nEsse modelo pode ser aplicado utilizando dados reais de processos judiciais para verificar se a alegação dos operadores do direito se sustenta estatisticamente.\n\n\n11.5.2 O Teste Estatístico\nQual dessas duas hipóteses é mais plausível?\nPara isso devemos nos valer de um processo de amostragem, onde faremos \\(n\\) medições do tempo médio dos processos (que chamaremos de X), \\(X_1, X_2, ..., X_n\\), e obteremos os valores em dias do tempo médio de cada processo amostrado \\(x_1, x_2,...x_n\\).\nCom base na amostra devemos realizar algum tipo de cálculo que nos permite inferir se rejeitamos ou não \\(H_0\\), se é plausível ou não a hipótese colocada. Isso é o que chamamos de teste estatístico:\n\\[T = h(X_1,X_2, . . .,X_n)\\]\nDecidindo qual o \\(T\\) utilizar - a função \\(h\\) que será aplicado aos valores da amostra - devemos compreender qual é a distribuição dessa estatística sob a condição de que a hipótese \\(H_0\\) for a verdadeira.\n\n\n\n\n\n\nA Intuição\n\n\n\nQueremos aqui saber se a amostra tivesse sido extraída de contratos com esperança do tempo de duração , \\(\\mathbb{E(X)}\\), de 600 dias, quais seriam os valores típicos para a distribuição do estimador T? Dessa forma, podemos comparar esses valores típicos com o que obtivemos no processo de amostragem.\n\n\nVejamos no nosso exemplo, gostariamos de verificar a hipótese de que a esperança do tempo médio, \\(\\mu\\) é de 600 dias. Como já vimos uma boa alternativa de teste estatístico poderia ser a média, \\(\\bar{X}\\). Assim o teste estatístico seria:\n\\[\\bar{X} = \\frac{\\sum_i^n(X_i)}{n}\\]\nCom base na amostra observada \\(x_1, x_2, ..., x_3\\) poderiamos obter a estimativa do tempo médio, ou seja, \\(\\bar{x}\\). Como saber se essa média calculada nos traz mais evidência a favor de \\(H_0\\) ou \\(H_1\\)? Veja a Figura abaixo para pensarmos no problema.\nA figura considera o estimador \\(\\bar{X}\\). A esquerda temos os valores do estimador que atestam que a hipótese \\(H_0\\) é a mais plausível, quando mais próxima a estimativa de 600 maior evidência que \\(H_0\\) é verdadeira. Ao caminhar para a direita, os valores do estimador se distanciam de 600, e mais evidência de que \\(H_0\\) não é plausível.\nDessa forma, precisamos de um ponto no qual (interrogação na figura) onde valores menores do estimador são favoráveis a hipótese nula e valores maiores são mais favoráveis a hipótese alternativa. Por exemplo, se no nosso processo de amostragem obtivemos a estimativa de \\(\\bar{x}=700\\), isso é mais favorável a \\(H_0\\) ou \\(H_1\\)?\n\n\n\n\nTeste de Hipótese - intuição \n\n\n\nPara saber qual seriam os valores típicos do estimador \\(\\bar{X}\\) sob \\(H_0\\) imagine que a população \\(X\\) seja \\(N(600,100^2)\\), ou seja, tem esperança 600 e desvio padrão populacional de 100. Essa é a afirmação da Justiça Federal, ou seja, nosso \\(H_0\\).\nJá sabemos que um processo de amostragem cada uma das \\(n\\) medições \\(X_1, X_2, ...,X_n\\) possuem a mesma distribuição de \\(X\\). E também sabemos por definição que o estimador \\(\\bar{X}\\) terá uma distribuição:\n\\[N(600,\\frac{100^2}{n})\\].\nSupondo que retiramos uma amostra de 25 processos, logo os valores típicos do estimador sob \\(H_0\\) são \\(N(600,\\frac{100^2}{25})\\). Vejamos abaixo a simulação do estimador \\(\\bar{X}\\), os valores típicos para esse caso, e onde se encontra o valor de 700.\n\nx&lt;-seq(500,700,0.1) \nfdnorm&lt;-dnorm(x = x, mean = 600, sd=20)   \nregiao=seq(560,640,0.01)\ncord.x &lt;- c(min(regiao),regiao,max(regiao))\ncord.y &lt;- c(0,dnorm(regiao,mean=600, sd=20),0) \ncurve(dnorm(x,600,20),xlim=c(500,700),xlab=expression(bar(x)),type=\"l\",\n      col=\"steelblue4\",lwd=2, ylab=expression(paste(\"f(\", bar(x),\n      \")\")),xaxt=\"n\",cex.axis=0.65, cex.lab=0.8 ) \naxis(1,at=c(500,540,560,580, 600, 620, 640,660, 700),labels =\n       c(500,540,560,580, 600, 620, 640,660, 700),cex.axis=0.7, cex.lab=0.8) \npolygon(cord.x,cord.y,col='lightgray')\nabline(v=600, col=\"steelblue4\", lty=2, lwd=2)\ntext(602, 0.001, expression(mu))\n\n\n\n\nValores típicos da distribuiçao da média sob H0\n\n\n\n\nNo centro temos a \\(E(\\bar{X})=\\mu=600\\). Observamos que para o tamanho amostral que retiramos e sob \\(H_0\\) os valores típicos oscilam mais ou menos entre 560 e 640 - dois desvios padrão para cima e para baixo (lembrem-se que nesse intervalo temos mais de 95% das observaçoes).\nQuanto retiramos a amostra e calculamos o valor da média obtivemos \\(\\bar{x}=700\\). Observe no gráfico acima onde está o valor de 700, muita a frente e notamos claramente que a probabilidade de obtermos esse valor de média com uma amostra retirada da população \\(N(600,100^2)\\), é praticamente 0.\nPortanto, existem evidências de que essa amostra não veio de uma população conforme descrita pela Justiça Federal e sim de processos com tempo médio (esperança) maior do que 600. Portanto, dizemos que rejeitamos \\(H_0\\).\n\n\n11.5.3 Erro Tipo I (EI) e Erro Tipo II (EII)\nAqui precisamos distinguir duas ideias, a primeiro é a existência da verdadeira população e a segunda é o que achamos ser a verdadeira população com base na análise que fizemos. Aqui surge o que chamamos de erro estatístico. Não temos como fugir dele, somente controlá-lo. Vejamos a tabela abaixo que resume as possibilidades:\n\n\nTipos de Erros em Estatística, EI e EII.\n\n\nA Decisão\n(\\(H_0\\)) é verdadeiro\n(\\(H_1\\)) é verdadeiro\n\n\n\n\nRejeitar (\\(H_0\\))\nErro Tipo I (EI)\nCorreto\n\n\nNão Rejeitar (\\(H_0\\))\nCorreto\nErro Tipo II (EII)\n\n\n\n\nObserve que a nossa decisão pode incorrer em dois erros diversos.\n\n\n\n\n\n\nErro Tipo I e Erro Tipo II\n\n\n\nErro Tipo I e Erro Tipo II\nErro Tipo I (EI): ocorre quando “indevidamente” rejeitamemos \\(H_0\\). Nesse caso \\(H_0\\) era verdadeira e rejeitamos.\\\nErro Tipo II (EII): ocorre quando “indevidamente” não rejeitamos \\(H_0\\). Nesse caso não rejeitamos \\(H_0\\) e na verdade \\(H_1\\) é verdadeira.\n\n\nO primeiro erro é o chamado na literatura médica de falso negativo, ou seja, classifica a pessoa não portadora da doença (negativa) e na verdade ela possui.\nO segundo tipo é o falso positivo, onde classifica-se a pessoa com a doença quando na realidade ela não possui.\nNosso desafio agora é estabelecer um critério de decisão, o ponto a partir do qual dizemos que \\(H_0\\) não parece mais provável (Figura Teste de Hipótese - Intuição). Essa chamaremos de região crítica ou de rejeição.\n\nEI \\((\\alpha)\\)- Dizer que o tempo médio é maior que 600, quando na realizadade ela é de 600.\nEII \\((\\beta)\\)- Dizer que tempo médio é de 600 quando na realidade ela é maior do que 600.\n\nVamos retomar o nosso exemplo. Foi retirada uma amostra de \\(n=25\\) processos e por definição a distribuição de \\(\\bar{X}\\) sob \\(H_0\\) será \\(N(600,\\frac{100^2}{25})\\). A hipótese a ser testada será:\n\\[H_0: \\qquad \\mu=600\\] \\[H_1: \\qquad \\mu&gt;600\\]\nUma maneira de acharmos o valor a partir do qual teremos a região crítica ou de rejeição, seria controlar o Erro Tipo I \\((\\alpha)\\). Podemos dizer que gostariamos de cometer o Erro Tipo I em apenas 5% dos casos.\n\n\n\n\n\n\nErro Estatístico\n\n\n\nA chance de retirarmos um amostra e o valor da estimativa ser maior que o valor de decisão é de 5% dos casos, os outros 95% sempre cairão na área de aceitação.\n\n\n\\[P(Z_{\\bar{X}} \\geq z_c|H_0)=0.05= \\alpha\\] Olhando a tabela temos:\n\\[P(Z_{\\bar{X}} \\geq 1.65|H_0)=0.05= \\alpha\\] \\[z_c =\\frac{\\bar{X}+600}{100/5}\\] \\[1.65 = \\frac{\\bar{X}+600}{20}\\] \\[\\bar{X}=600+1.65*20=633\\]\nPortanto,\n\\[P(\\bar{X}\\geq 633|H_0)=0.05= \\alpha\\]\n\n\n\n\n\n\nTabela Normal\n\n\n\n\n\n\n\n\n\nTabela da Norma Padrão \n\n\n\n\n\n\nLogo, temos agora uma regra de decisão que tenta controlar o Erro Tipo I. A nossa regra de decisão agora é rejeitar \\(H_0\\) toda vez que o valor calculado da estimativa de \\(\\bar{X}\\) for maior do que 633 e aceitar quando for menor. Assim nossa região crítica será:\n\\[RC =\\{\\bar{x} \\in \\mathbb{R} | \\bar{x} \\geq 633\\}\\]\nIsso implica que a probabilidade de rejeitarmos \\(H_0\\) (de que o tempomédio não é de 600), e na verdade ela ser de 600 é de 5%.\nVejamos o gráfico:\n\nx&lt;-seq(500,700,0.1) \nfdnorm&lt;-dnorm(x = x, mean = 600, sd=20)  \nfdnorm1&lt;-dnorm(x = x, mean = 660, sd=20)\nregiao=seq(633,700,0.01)\ncord.x &lt;- c(min(regiao),regiao,max(regiao))\ncord.y &lt;- c(0,dnorm(regiao,mean=600, sd=20),0) \ncurve(dnorm(x,600,20),xlim=c(500,700),xlab=expression(bar(x)),type=\"l\",\n      col=\"steelblue4\",lwd=2, ylab=expression(paste(\"f(\", bar(x),\n      \")\")),xaxt=\"n\",cex.axis=0.65, cex.lab=0.8 ) \naxis(1,at=c(500,540,560,580, 600, 620, 633,660, 700),labels =\n       c(500,540,560,580, 600, 620, 633,660, 700),cex.axis=0.7, cex.lab=0.8) \npolygon(cord.x,cord.y,col='wheat4')\nabline(v=633, col=\"steelblue4\", lty=2, lwd=2)\ntext(600, 0.001, expression(mu))\ntext(660, 0.005, expression(paste(\"EI=\", alpha, \"=0.05\")))\n\n\n\n\nErro Tipo I e a Região Crítica\n\n\n\n\nEm cinza tem-se a região crítica descrita acima. Logo todos os valores calculados de \\(\\bar{X}\\) que cairem acima de 633, dizemos que rejeitamos \\(H_0\\). Entretanto, percebam que poderiam fazer parte desta distribuição, apesar da chance ser pequena, 5%.\nComo não sabemos a distribuição sob \\(H_1\\) não conseguimos calcular a probabilidade de não rejeitar \\(H_0\\) e na verdade ela pertencer a distribuição de \\(H_1\\).\n\n\n11.5.4 Procedimento Geral do Teste de Hipótese\n\n11.5.4.1 Teste para um parâmetro populacional\nTemos interesse em uma característica da população. Como vimos por exemplo, o tempo médio de um processo \\(X\\), ou mais especificamente na sua esperança \\(E(X)=\\mu\\). Contruímos o teste sobre o parâmetro, podendo ser unicaudal ou bicaudal.\nHipótese Bicaudal:\nO teste bilateral ou bicaudal podemos observar valores maiores ou menores em relação a hipótese nula. Assim não temos nenhum conhecimento que nos permita dizer que podemos ter valores somente maiores ou somente menores. Temos a seguinte formulação geral:\n\\[H_0: \\qquad \\theta=\\theta_0\\]\n\\[H_1: \\qquad \\theta \\neq \\theta_0\\]\nNível de significância\nRetomando o nosso exemplo, ao rejeitarmos \\(H_0\\) podemos cometer o erro de dizer que o tempo médio é maior que 600 dias, mas na realidade o tempo era efetivamente 600 dias.\nTentamos controlar esse tipo de erro que é o nosso Erro Tipo I (EI). Temos que definir qual seria o tamanho desse erro, 10%, 5%, 1% etc. Esse percentual é o que chamamos de nível de significância. Quem define esse tamanho é o pesquisador e em geral, em ciência sociais, utilizamos os níveis acima.\n\n\n\n\n\n\nNível de Signficãncia\n\n\n\nNível de Significância:É a probabilidade máxima aceitável de cometer o erro tipo I e chamamos de \\(\\alpha\\), sendo um valor entre \\(0&lt;\\alpha&lt;1\\)\n\n\nDessa forma, faremos o teste de hipótese para o parâmetro \\(\\theta\\) ao nível de significância de \\(\\alpha\\). No nosso caso dizemos que iremos testar se o tempo médio dos processos é de 600, \\(H_0: \\mu=600\\), ao nível de 5% de significância.\nValor Crítico e Região Crítica\nCom base no nível de significância conseguiremos estabelecer qual é o valor crítico e qual seria a região de rejeição. Para o nosso caso encontramos o valor crítico de 633 e a nossa região foi estabelecida como \\(RC =\\{\\bar{x} \\in R | \\bar{x} \\geq 633\\}\\). Conforme calculamos anteiormente.\nAssim, de forma geral tem-se:\n\\[RC =\\{T \\in C| H_0\\}\\] \\[P(T \\in C|H_0)\\leq\\alpha\\]\n\n\n\n\n\n\nTeste Unilateral e Bilateral\n\n\n\nA região critica depende do teste estatístico escolhido e se a hipótese é unilateral, ou seja, apenas de um lado da distribuição ou bilateral, os dois lados da distribuição. No caso unilateral utilizamos o nível de siginifcância, \\(\\alpha\\), todo de um lado apenas. Se for o teste bilateral dividimos o nível de significância, ou seja, utilizamos\\(\\alpha /2\\), metade para cada lado.\n\n\nO Teste de Hipótese\nFazemos nosso processo de amostragem e obtemos o valor do teste estatístico. Se o valor do teste ficar fora da região crítica dizemos que não rejeitamos \\(H_0\\). Para o nosso caso, que não existe evidências de que o tempo médio dos processos é maior do 600 dias.\nCaso o teste estatítico produza uma estimativa na região crítica, rejeitamos \\(H_0\\), há evidências de que o tempo médio é maior do que aquela postulada pela Justiça Federal.\n\n\n\n11.5.5 Os Cinco passos para a contrução do teste de hipótese\n\nEstabeleça as hipótese nula \\(H_0\\) e a hipótese alternativa \\(H_1\\)\nDefina qual estimador do parâmetro populacional \\(\\theta\\) que será usado para testar \\(H_0\\): média, desvio padrão amostral, proporção amostral etc\nDefina o nível de significância - \\(\\alpha\\) e estabeleça qual o valor e a região crítica.\nCalcule a estimativa do teste estatístico.\nSe não pertencer a Região Crítica não rejeitamos \\(H_0\\), caso contrário rejeitamos a hipótese nula \\(H_0\\).\n\n\n\n11.5.6 Introdução ao Teste de Hipótese de Duas Populações (de Médias)\nO teste de hipótese é uma técnica estatística fundamental usada para tomar decisões baseadas em evidências amostrais. O teste de hipótese de duas populações é aplicado quando queremos comparar as médias de duas populações distintas e determinar se existe uma diferença estatisticamente significativa entre elas. Vamos explorar os principais conceitos deste teste:\nFormulação das Hipóteses\nNo teste de hipótese de duas populações, formulamos duas hipóteses:\n\nHipótese Nula (\\(H_0\\)): Esta é a hipótese inicial que assume que não há diferença entre as médias das duas populações. Geralmente, é representada como\n\n\\[H_0: \\mu_1 = \\mu_2\\],\nonde \\(\\mu_1\\) e \\(\\mu_2\\) são as médias das duas populações.\n\nHipótese Alternativa (\\(H_a\\) ou \\(H_1\\)): Esta é a hipótese que queremos testar, indicando que há uma diferença significativa entre as médias das duas populações. Pode ser definida como: \\[H_a: \\mu_1 &gt; \\mu_2\\] ou \\[H_a: \\mu_1 &lt; \\mu_2\\] ou\n\n\\[H_a: \\mu_1 \\neq \\mu_2\\].\nEstatística do Teste\nO teste de hipótese de duas populações geralmente envolve o cálculo de uma estatística de teste específica para comparar as médias das amostras das duas populações. Uma das estatísticas comuns é o teste t de Student, especialmente quando as variâncias populacionais são desconhecidas e podem ser diferentes entre as populações.\nDecisão do Teste\nApós calcular a estatística de teste, comparamos o valor observado da estatística com um valor crítico ou calculamos um valor p associado. O valor p é a probabilidade de obter uma estatística de teste tão extrema quanto a observada, assumindo que a hipótese nula seja verdadeira. Com base no valor p (geralmente comparado com um nível de significância pré-definido, como 0,05), tomamos uma decisão de rejeitar ou não rejeitar a hipótese nula.\nConclusão do Teste\nA conclusão do teste de hipótese de duas populações nos permite determinar se há evidências estatísticas suficientes para rejeitar a hipótese nula em favor da hipótese alternativa. Essa decisão tem implicações importantes em áreas como pesquisa científica, análise de dados e tomada de decisões em negócios e saúde.\n\n\n11.5.7 Aplicação Prática sobre Teste de Hipótese\nEssa seção tem o objetivo de aplicar o Teste de Hipótese utilizando o R. Vamos utilizar nosso banco de dados sobre feminicídio. E vamos criar uma variável que identifica se pertence as regiões norte, nordeste e centro oeste ou as regiões sul e sudeste.\n\n#carregando o pacote para ler arquivos em excel\nload(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/final_fem_22.Rdata\")\n\n# Criando a Binária que indica a região N, NE e CO\nlibrary(dplyr)\n\nfinal_fem_22 &lt;- final_fem_22 %&gt;%\n  mutate(N_NE_CO = case_when(\n    regiao %in% c(\"N\", \"NE\", \"CO\") ~ 1,  # Regiões N, NE e CO recebem 1\n    TRUE ~ 0                             # Demais regiões recebem 0\n  ))\n\nVamos olhar as médias entra as regiões norte, nordeste e centro oeste e as regiões sul e sudeste.\n\nlibrary(kableExtra)\n\nmean_1&lt;- aggregate(final_fem_22[4:15], list(final_fem_22$N_NE_CO), mean,  na.rm=T)\n\nt(mean_1) %&gt;% \n  kbl(digits = 2) %&gt;%\n     kable_styling()\n\n\n\n\nGroup.1\n0.00\n1.00\n\n\nhomic_abs\n249.71\n108.80\n\n\nhomic_tx\n3.60\n5.18\n\n\nfeminic_abs\n107.57\n34.20\n\n\nfeminic_tx\n1.47\n1.72\n\n\npart_feminic\n42.84\n35.98\n\n\nrendapc\n1903.14\n1287.55\n\n\nmais_50\n0.29\n0.25\n\n\nt_homic_abs\n453.57\n224.25\n\n\nt_homic_tx\n8.91\n15.50\n\n\nt_feminic_abs\n177.67\n78.79\n\n\nt_feminic_tx\n3.25\n4.42\n\n\npart_t_feminic\n26.24\n27.09\n\n\n\n\n\nPode-se observar que existem em todas as variáveis existem diferenças entre as duas regiões. A questão é: Essas diferenças são estatisticamente significativas?\nAproveitando um gráfico anterior que fizemos, vamos olhar a distribuição das taxas de feminicídio entre as regiões.\n\nlibrary(ggplot2)\nggplot(final_fem_22, aes(x = factor(N_NE_CO, labels = c(\"Sul e Sudeste\", \"Norte, Nord. e C.Oeste\")),  # Transformando em fatores\n                         y = feminic_tx, fill = factor(N_NE_CO))) +                                   # Taxa de Feminicídio por Fator\n  geom_violin(trim = FALSE, color = \"white\") +                                                        # Cria o gráfico de violino\n  scale_fill_manual(values = c(\"lightblue\", \"steelblue\")) +                                           # Cor das violas\n  stat_summary(fun=\"median\", geom = \"point\", shape=19, size=3, color=\"darkorange\"  ) +                # Vamos colocar o ponto mediana\n  labs(\n    title = \"Distribuição da taxa de feminicídio por região do Brasil\",\n    x = \"Região\",\n    y = \"Taxa de Feminicídio (por 100 mil)\",\n    fill = \"Região\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),              # Centraliza o título\n    axis.text.x = element_text(size = 12),                                         # Ajusta o tamanho dos rótulos no eixo X\n    axis.text.y = element_text(size = 10),                                         # Ajusta o tamanho dos rótulos no eixo Y\n    legend.position = \"none\"  )\n\n\n\n\n\n\n\n\nObserva-se diferença entre as duas regiões, mas será que as médias são estatisticamente diferentes? Para isso temos que utilizar o Teste de Hipótese.\nRelembrando os Passos\nO teste de hipótese segue um processo estruturado de cinco etapas:\n\nDefinir as Hipóteses – Comece formulando a hipótese nula (\\(H_0\\)) e a hipótese alternativa (\\(H_1\\)). Em geral, a hipótese nula representa a ausência de efeito ou diferença, enquanto a hipótese alternativa sugere a existência de um efeito ou diferença.\nDefina o Estimador - Defina qual estimador vai utilizar para inferir sobre o parâmetro populacional \\(\\theta\\), o qual será usado para testar \\(H_0\\): média, desvio padrão amostral, proporção amostral etc\nEstabelecer os Critérios de Decisão – Defina o nível de significância (\\(\\alpha\\)), que representa a probabilidade de rejeitar a hipótese nula quando ela é verdadeira (Erro Tipo I). Valores comuns de (\\(\\alpha\\)) são 0,05 (5%) e 0,01 (1%).\nAnalisar os Dados da Amostra – Calcule o teste estatístico com base nos dados amostrais. Esse teste estatístico vai ser utilizado para a comparação com os valores típicos que poderiam acontecer se a amostra tivesse vindo de \\(H_0\\).\nTomar uma Decisão e Interpretar os Resultados – Compare o valor calculado no teste com o valor crítico ou utilize o p-valor. Se o p-valor for menor que o nível de significância \\(\\alpha\\), rejeita-se a hipótese nula em favor da hipótese alternativa. Caso contrário, não há evidências suficientes para rejeitar a hipótese nula, indicando que o efeito não é estatisticamente significativo.\n\nTeste de Hipótese no R\nA função t.test() no R possui vários argumentos importantes para a realização do teste t.\n\nt.test(x, y = NULL,\n       alternative = c(\"two.sided\", \"less\", \"greater\"),\n       mu = 0, paired = FALSE, var.equal = FALSE,\n       conf.level = 0.95, …)\n\nAbaixo estão os principais:\n\nx, y: As duas amostras de dados a serem comparadas.\n\nalternative: Define a hipótese alternativa do teste (exemplo: \"two.sided\", \"greater\", \"less\").\n\nmu: Especifica um valor de referência para a média populacional no teste.\n\npaired: Indica se o teste t deve ser pareado (TRUE) ou não pareado (FALSE).\n\nvar.equal: Especifica se as variâncias das amostras devem ser assumidas como iguais (TRUE) ou não (FALSE).\n\nconf.level: Define o nível de confiança do intervalo (padrão de 95%).\n\nEsses parâmetros permitem personalizar o teste conforme a necessidade da análise estatística.\nTeste sobre o Parâmetro\nUma reportagem em um portal de notícias indicou que a média da taxa de feminicídio nos estados brasileiros é igual a 2 assassinatos por 100 mil mulheres. Com base nos dados que coletamos gostaríamos de saber se eles carregam evidências favoráveis ou contra ao artigo.\n\nDefinir as Hipóteses\n\n\\[H_0: \\mu = 2\\] \\[H_1:\\mu \\neq 2 \\]\n\nDefina o Estimador\n\nVamos utilizar a Média Amostral, \\(\\bar{X}\\), para testar a hipótese nula \\(H_0\\).\n\nEstabelecer os Critérios de Decisão\n\nVamos adotar \\(\\alpha= 0,05\\) (5%).\n\nAnalisar os Dados da Amostra\n\n\nt.test(x=final_fem_22$feminic_tx, y = NULL,\n       alternative = c(\"two.sided\"),\n       mu = 2, \n       paired = FALSE, \n       var.equal = TRUE,\n       conf.level = 0.95)\n\n\n    One Sample t-test\n\ndata:  final_fem_22$feminic_tx\nt = -2.9276, df = 26, p-value = 0.007011\nalternative hypothesis: true mean is not equal to 2\n95 percent confidence interval:\n 1.407411 1.896292\nsample estimates:\nmean of x \n 1.651852 \n\n\n\nTomar uma Decisão e Interpretar os Resultados\n\nEntendendo o resultado do teste:\nOne Sample t-test: Teste de uma amostra -&gt; taxa de feminicídio\ndata:  final_fem_22$feminic_tx: Indica a variável que utilizou\nt = -2.9276, df = 26, p-value = 0.007011: O valor do teste t, o grau de liberdade e o p-valor\nalternative hypothesis: true mean is not equal to 2: A hipótese alternativa é que a média não é igual a 2\n95 percent confidence interval: 1.407411 1.896292 : O intervalo de confiança de 95% para a média, indicando que a verdadeira média populacional está nesse intervalo.\nsample estimates: mean of x  = 1.651852: A média amostral é de 1.65, a qual é a estimativa da verdadeira média populacional.\nComo o p-valor foi menor que o nível de significância \\(\\alpha\\), rejeita-se a hipótese nula em favor da hipótese alternativa. Há evidências de que a média nacional é menor do que 2.\nTeste Unicaudal\nPodemos testar também a seguinte hipótese com nível de significância de 1%:\n\\[H_0: \\mu = 2\\] \\[H_1:\\mu &lt; 2 \\] No R:\n\nt.test(x=final_fem_22$feminic_tx, y = NULL,\n       alternative = c(\"less\"),\n       mu = 2, \n       paired = FALSE, \n       var.equal = TRUE,\n       conf.level = 0.99)\n\n\n    One Sample t-test\n\ndata:  final_fem_22$feminic_tx\nt = -2.9276, df = 26, p-value = 0.003505\nalternative hypothesis: true mean is less than 2\n99 percent confidence interval:\n     -Inf 1.946607\nsample estimates:\nmean of x \n 1.651852 \n\n\nNovamente como o p-valor foi menor que o nível de significância \\(\\alpha\\), rejeita-se a hipótese nula em favor da hipótese alternativa. Há evidências de que a média nacional é menor do que 2.\nTeste para Diferença de Médias\n\nTaxa de Feminicídio\n\nVamos testar a hipótese de que as taxas de feminicídio são iguais entre as regiões norte, nordeste e centro oeste e as regiões sul e sudeste. Vamos permitir que as variâncias sejam diferentes entre as duas regiões\n\\[H_0: \\mu_{N-NE-CO} = \\mu_{S-SD}\\] \\[H_1: \\mu_{N-NE-CO} \\neq \\mu_{S-SD}\\]\n\nt.test(feminic_tx~N_NE_CO, data=final_fem_22,\n       alternative = c(\"two.sided\"),\n       var.equal = FALSE,\n       conf.level = 0.95)\n\n\n    Welch Two Sample t-test\n\ndata:  feminic_tx by N_NE_CO\nt = -1.2049, df = 20.949, p-value = 0.2417\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.6640345  0.1768916\nsample estimates:\nmean in group 0 mean in group 1 \n       1.471429        1.715000 \n\n\nComo o p-valor foi maior que o nível de significância \\(\\alpha\\), não rejeita-se a hipótese nula. Não há evidências de que as regiões possuem taxas diferentes de feminicídio.\n\nRenda pc\n\nVejamos agora a renda per capita a 1% de significância :\n\nt.test(rendapc~N_NE_CO, data=final_fem_22,\n       alternative = c(\"two.sided\"),\n       var.equal = FALSE,\n       conf.level = 0.99) \n\n\n    Welch Two Sample t-test\n\ndata:  rendapc by N_NE_CO\nt = 4.6401, df = 22.301, p-value = 0.0001225\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n99 percent confidence interval:\n 242.1018 989.0840\nsample estimates:\nmean in group 0 mean in group 1 \n       1903.143        1287.550 \n\n\nObserva-se que rejeita-se a hipótese nula, e há evidências de que a média da renda per capita entre as duas regiões são diferentes.\nAmostras Pareada\nVamos testar a diferença de média entre amostra pareadas. A amostra pareada é quando temos o mesmo indivíduo observado duas vezes. Vamos testar se existe diferença entre a participação do feminicídio sobre os homicídios e a participação da tentativa de feminicídio sobre as tentativas de feminicídio feminino.\n\\[H_0: \\mu_{part-feminic} = \\mu_{part-t-feminic}\\] \\[H_1: \\mu_{part-feminic} \\neq \\mu_{part-t-feminic}\\]\nUtilizando a média amostral para testar a hipótese nula \\(H_0\\) e considerando um nível de significância de 95%. No R temos:\n\nt.test(x=final_fem_22$part_feminic, y=final_fem_22$part_t_feminic,\n       alternative = c(\"two.sided\"),\n       paired = TRUE, \n       var.equal = FALSE,\n       conf.level = 0.95)\n\n\n    Paired t-test\n\ndata:  final_fem_22$part_feminic and final_fem_22$part_t_feminic\nt = 3.457, df = 24, p-value = 0.002049\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n  4.105405 16.269795\nsample estimates:\nmean difference \n        10.1876 \n\n\nComo o p-valor foi menor que o nível de significância \\(\\alpha\\), rejeita-se a hipótese nula em favor da hipótese alternativa. Há evidências de que a média da participação do feminicídio é maior do que a média da participação da tentativa de feminicídio. A estimativa dessa diferença é de 10 pontos percentuais a mais para participação do feminicídio.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Uma Introdução à Estatística</span>"
    ]
  }
]