[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jurimetria",
    "section": "",
    "text": "1 Prefácio"
  },
  {
    "objectID": "index.html#nossa-motivação",
    "href": "index.html#nossa-motivação",
    "title": "Jurimetria",
    "section": "1.1 Nossa Motivação:",
    "text": "1.1 Nossa Motivação:\nEsse curso foi criado pensando em profissionais com formação em direito, estatística, tecnologia da informação e demais profissionais que atuam tanto no judiciário quanto em tribunais administrativos. A ideia é colocar juntas diversas visões sobre um mesmo problema para buscarmos soluções mais criativas e eficicientes para as desigualdades nacionais."
  },
  {
    "objectID": "index.html#nosso-objetivo",
    "href": "index.html#nosso-objetivo",
    "title": "Jurimetria",
    "section": "1.2 Nosso Objetivo:",
    "text": "1.2 Nosso Objetivo:\nÉ oferecer aos participantes uma abordagem probabilística do direito aplicado, tendo como foco os casos práticos e discutindo questões relativas ao direito e desigualdades. Especificamente, objetiva-se ensinar um conjunto de métodos quantitativos e oferecer ferramentas para coleta, transformação e análise de dados jurídicos disponibilizados nas páginas dos tribunais de justiça."
  },
  {
    "objectID": "index.html#nosso-problema",
    "href": "index.html#nosso-problema",
    "title": "Jurimetria",
    "section": "1.3 Nosso Problema:",
    "text": "1.3 Nosso Problema:\nTeremos como tema de fundo nesse curso os processos de homicídio feminino. Especificamente queremos compreender qual o perfil e os determinantes do feminicidio no Estado de São Paulo."
  },
  {
    "objectID": "summary.html#resumo",
    "href": "summary.html#resumo",
    "title": "2  Sumário do Curso",
    "section": "2.1 Resumo:",
    "text": "2.1 Resumo:\nA pesquisa no direito e a ciência de dados: introdução, relevância e experiências; Coleta, transformação e estruturação de dados processuais com R; Estatística descritiva; Aprendizado estatístico (regressão linear, regressão logística); Aprendizado estatístico (machine learning); Interpretação dos resultados e elaboração de relatório."
  },
  {
    "objectID": "summary.html#plano-detalhado-das-aulas",
    "href": "summary.html#plano-detalhado-das-aulas",
    "title": "2  Sumário do Curso",
    "section": "2.2 Plano detalhado das aulas:",
    "text": "2.2 Plano detalhado das aulas:\n\nA pesquisa no direito e a ciência de dados: introdução, relevância e experiências - 25/04\nColeta, transformação e estruturação de dados processuais com R - 02/05\nColeta, transformação e estruturação de dados processuais com R - 09/05\nAnálise descritiva e visualização de dados processuais - 16/05\nModelos lineares aplicados a pesquisa em direito – regressão linear - 23/05\nModelos para diferentes tipos de estrutura de dados e variáveis. - 06/06\nAprendizado estatístico (machine learning) - 13/06\nAprendizado estatístico (machine learning) - 20/06\nInterpretação dos resultados e elaboração do relatório - 27/06"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introdução ao Feminicídio",
    "section": "",
    "text": "Nessa seção pensei em falarmos um pouco no no caso referências etc…."
  },
  {
    "objectID": "lineares.html",
    "href": "lineares.html",
    "title": "6  Modelos Lineares",
    "section": "",
    "text": "7 Teste de Hipóteses no RLM"
  },
  {
    "objectID": "lineares.html#introdução",
    "href": "lineares.html#introdução",
    "title": "7  Modelos Lineares",
    "section": "7.1 Introdução",
    "text": "7.1 Introdução\nComeçamos com o modelo mais geral da população:\n\\[y = \\beta_0 + \\beta_1x + u \\]\nNesta equação, \\(y\\) é a variavel dependente ou também denominada de variável explicada; \\(x\\) é a variável explicativa e \\(u\\) é o termo de erro. Essa equação é uma equação de regressão linear simples.\nVejamos um exemplo\nGostariamos de explicar a taxa de crimes nos bairros de uma cidade e consideramos que os níveis de desemprego nas localidades são importantes. Nosso modelo de regressão poderia ser específicado da seguinte maneira:\n\\[Crime_i = \\beta_0 + \\beta_1Desemprego_i + u\\]\nO subscrito \\(i\\) se refere a um bairro hipotético da cidade. Note que nesse caso, \\(i\\) é o subscrito que relaciona nossas unidades de observação (bairros). Nossas unidades de observação podem variar a depender do contexto em estudo: países, cidades, bairros, estados, pessoas, processos, varas, tribunais….\nNote que, novamente o termo de erro, \\(u\\), está presente na equação. O termo de erro, não observado, capta tudo aquilo que afeta \\(Crime\\), mas que não estamos controlando, ou seja, que não é explicado pelo \\(Desemprego\\).\nVoltemos a equação básica:\n\\[y = \\beta_0 + \\beta_1x + u \\]\nNa análise de RLS estamos interessados nos parâmetros \\(\\beta_0\\) e sobretudo \\(\\beta_1\\). A razão primordial para isso é que, tudo o mais constante, a relação acima aponta que\n\\[\\Delta y = \\beta_1 \\Delta x \\] , se \\[\\Delta u = 0\\]\nIsto é, se tudo o mais que afeta \\(y\\) permanecer inalterado, uma variáção em \\(x\\), \\(\\Delta x\\), terá um impacto de \\(\\beta_1 \\Delta x\\) em \\(y\\). No exemplo da criminalidade, teremos que:\n\\[\\Delta crime = \\beta_1 \\Delta desemprego \\]\nAssim, o aumento de 1 ponto no desemprego irá ter o efeito de \\(\\beta_1\\) unidades de crimes em média. Por isso, quando conseguimos estimar os parêmetros \\(\\beta\\) estamos mais próximos de entender as relações entre \\(x\\) e \\(y\\) em nossas aplicações.\nCabe destacar algo bastante importante.As relações acima não encerram a questão da causalidade. Como podemos inferir um impacto causal do desemprego na criminalidade se estamos ignorando todos os demais fatores que ficaram de fora do modelo - fatores que são captados em \\(u\\) não observados.\n\n7.1.1 Alguns Exemplos de Regressão Aplicados ao Contexto Jurídico:\nConsidere os seguintes exemplos de RLS aplicadas ao contexto do Direito\nPrevisão de Sentenças com Base na Gravidade do Crime:\n\nVariável dependente \\((Y)\\): Tamanho da pena,\nVariável independente\\((X)\\): Gravidade do Crime,\nObjetivo: Identificar se a gravidade do crime tem influência sobre tamanho da pena.\n\nNesse exemplo \\(\\beta_0\\) é o intercepto da regressão e \\(\\beta_1\\) o coeficiente de regressão que representa como a gravidade do crime influência o tamanho da pena, \\(u\\) é o termo de erro.\n\\[Dpena = \\beta_0 + \\beta_1{\\text{Gravidade}} + u\\]\nAnálise de Fatores que Influenciam o Tempo de Julgamento:\n\nVariável Dependente (\\(Y\\)): Tempo de Duração do Processo\nVariável Independente (\\(x\\)), Tipo de Processo (por exemplo, criminal, civil, administrativo).\nObjetivo: Identificar se o tipo de processo tem impacto no tempo que um caso leva para ser concluído.\n\n\\[Tempo = \\beta_0 + \\beta_1  Processo  + u\\]\nPrevisão de Probabilidade de Recurso com Base em Decisões Anteriores:\n\nVariável Dependente (\\(Y\\)): Probabilidade de Entrada com Recurso\nVariável Independente (\\(X\\)): Resultado da Decisão Anterior (por exemplo, deferimento ou negação do recurso).\nObjetivo: Determinar a probabilidade de um recurso ser apresentado com base no resultado de decisões passadas.\n\n\\[Resultado = \\beta_0 + \\beta_1 Resultado_{-1} + u \\]\nAnálise de Relação entre Número de Testemunhas e Veredito:\n\nVariável Dependente (\\(Y\\)): Veredito (por exemplo, culpado ou inocente)\nVariável Independente (\\(X\\)): Número de Testemunhas.\nObjetivo: Investigar se o número de testemunhas influencia o veredito\n\n\\[ Veredito = \\beta_0 + \\beta_1 Testemunhas + u \\]"
  },
  {
    "objectID": "lineares.html#hipóteses-sobre-o-comportamento-do-termo-de-erro",
    "href": "lineares.html#hipóteses-sobre-o-comportamento-do-termo-de-erro",
    "title": "7  Modelos Lineares",
    "section": "7.2 Hipóteses sobre o comportamento do Termo de Erro",
    "text": "7.2 Hipóteses sobre o comportamento do Termo de Erro\nSe especificamos o modelo com \\(\\beta_0\\), podemos assumir que \\(u\\), tem média igual a zero. Em notação de esperança matemática essa hipótese equivale a:\n\\[E(u) = 0\\]\nPodemos definir uma segunda hipotese sobre \\(u\\). Uma hipótese forte, é a de que \\(u\\) e \\(x\\) são independentes. Tal hípótese é a hipótese crucial do modelo de RLS:\n\\[E(u|x) = 0\\]\nJustas as hipóteses de \\(E(u) = 0\\) e \\(E(u|x) = 0\\) são denominadas de hipotese de média condicional zero.\nDessa forma, no nosso modelo inicial:\n\\[y = \\beta_0 + \\beta_1x + u\\]\nAplicando o operador \\(E( \\cdot |x )\\), obtemos\n\\[ E( y |x ) = \\beta_0 + \\beta_1x \\]\nAssim, na equação acima, temos um aumento de uma unidade em \\(x\\), implica em um aumento no valor esperado (ou em média) de \\(y\\) na magnitude de \\(\\beta_1\\).\nA equação acima, é caracterizada como função de regressão populacional. Essa função nos fornece a relação entre os diferentes níveis de \\(x\\) é o nível médio de \\(y\\), isto é \\(E( y |x )\\).\n\n\n\nFunção de Regressão Populacional, fonte: Anderson David R., Sweeney Dennis J., Williams Thomas A. (2019), Statistics for Business & Economics, Cengage Learning; 14th edition\n\n\nAgora, podemos voltar a nossa equação base e verificarmos o progresso feito no entendimento do modelo:\n\\[y = \\beta_0 + \\beta_1x + u \\]\n\\[y = E( y |x ) + u \\]\nNa equação acima, \\(E( y |x )\\) é chamada de parte sistemática de \\(y\\). Isto é, a parte sistematicamente explicada por \\(x\\). Já o termo de erro não observado, \\(u\\) é a parte não sistemática de \\(y\\), não explicada por \\(x\\)."
  },
  {
    "objectID": "lineares.html#estimação-dos-parâmetros-da-rls",
    "href": "lineares.html#estimação-dos-parâmetros-da-rls",
    "title": "7  Modelos Lineares",
    "section": "7.3 Estimação dos Parâmetros da RLS",
    "text": "7.3 Estimação dos Parâmetros da RLS\nNão conhecemos \\(\\beta_0\\) e \\(\\beta_1\\) queremos estimadores desses parametros: \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\).\nSuponha que tenhamos uma amostra aleatória da população: \\(\\{(x_i, y_i): i = 1, ..., n\\}\\). Poderia ser uma amostra de crimes e taxa de desemprego por bairros.\nEm nosso modelo base:\n\\[y_i = \\beta_0 + \\beta_1x_i + u_i \\]\nonde \\(u_i\\) é o erro aleatório da \\(i\\)-ésima observação.\nComo estimamos \\(\\beta_0\\) e \\(\\beta_1\\)?\nApós algum esforço algébrico, tem-se:\n\\[\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\\]\ne\n\\[\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\\]\nOnde, \\(\\bar{x}\\) e \\(\\bar{y}\\) são as médias amostrais de \\(X_i\\) e \\(Y_i\\), respectivamente.\nOs estimadores \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) são chamados de estimadores de Mínimos Quadrados Ordinários (MQO).\nA ideia é que os parâmetros que estimamos, \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\), são os parâmetros que minimizam a soma dos quadrados das diferenças entre nossos \\(y_i\\) observados e seus valores preditos definidos como\n\\[y_i- \\hat{y}_i =y_i -  \\hat{\\beta}_0 + \\hat{\\beta}_1x_i=u_i\\]\nQueremos minimizar o quadrado dessa diferença. Vejamos graficamente:\n\n\n\nValores Ajustados e Resíduos de MQO\n\n\nAntes de passarmos para o proxímo tópico de RLS, cabe mencionar uma nota sobre terminologia: quando estimamos equações de RLS do tipo \\(y = \\beta_0 + \\beta_1 x + u\\), dizemos que “rodamos a regressão de \\(y\\) sobre \\(x\\) !”\n\n7.3.1 Teste de Hipótese sob um Único Parametro\nAgora precisamos testar se nossa estimativa é estatisticamente igual a zero ou se ela é diferente de zero.\nHá evidências que a nossa variável \\(X\\) afeta a nossa variável \\(Y\\) na população?\nNa maior parte do tempo testamos hipóteses do tipo\n\\[H_0: {\\beta_j}=0\\] Na hipótese principal testamos a situação que \\(X\\) não afeta \\(Y\\) na população sob análise. Na hipótese alternativa:\n\\[H_1: \\beta_j \\neq 0\\]\nTestamos a hipótese que \\(X\\) afeta \\(Y\\) nessa população. Graficamente temos a figura abaixo onde a média populacional é igual a 0:\n\n\n\nTeste de hipótese, Fonte:CUEMATH\n\n\nEstatística de Teste:\nEste é um valor calculado a partir dos dados da amostra que é usado para avaliar a probabilidade de observar tal valor se a hipótese nula fosse verdadeira (\\(H_0: {\\beta_j}=0\\)). Ele que vai dizer se estamos na área amarela ou azul da figura acima.\n\n7.3.1.1 Valor-p:\nO valor-p é a probabilidade de observar uma estatística de teste tão extrema quanto, ou mais extrema do que, aquela calculada a partir dos dados da amostra, sob a suposição de que a hipótese nula seja verdadeira. Em outras palavras, mede quão provável é obter os resultados observados se a hipótese nula for correta.\nInterpretação: Um valor-p pequeno (tipicamente menor que um nível de significância predefinido, comumente 0,05) sugere que os dados observados são improváveis de ter ocorrido se a hipótese nula fosse verdadeira. Portanto, fornece evidências contra a hipótese nula, e os pesquisadores podem rejeitar a hipótese nula em favor da hipótese alternativa. Por outro lado, um valor-p grande indica que os dados observados são consistentes com a hipótese nula, e as evidências evidências são insuficientes para rejeitá-la.\n\n\n\n7.3.2 Aplicação - Estimando uma Regressão Linear Simples\nVamos utilizar aqui o nosso banco de dados anterior sobre feminicídio. É um banco com poucas obserações e possui fim didátco, apesar de serem dados reais.\nUma questão incial é entender quem será \\(Y\\) e quem será \\(X\\). Estamos querendo entender a taxa de feminicídio. A questão é, quais são seus determinantes? Aqui precisamos de alguma teoria…mas por hora, vamos ter como hipótese inicial que quanto maior a taxa de homícídio (ou maior a violência no estado) espera-se que em média a taxa de feminicídio aumente:\n\\[Feminc_{tx} = \\beta_0 + \\beta_1 Homici_{tx} + u\\]\nApesar de parecer “muito complicado” na teoria, na prática o R estima uma RLS em segundos. A função para estimar é alm, ou linear model.\n\n### Aplicação da RLS - Método dos Mínimos Quadrados Ordinários\n\n#carregando o pacote para ler arquivos em excel\nload(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/final_fem_22.Rdata\")\n\n#Vamos chamar a partir de agora nosso banco de dados\ndados&lt;- final_fem_22 \n\n##Função para rodar a regressão\nmodelo &lt;- lm(data = dados, feminic_tx ~ homic_tx)\n\n\n#Essa função resume a regressão, ja testar a hipótese sobre o coeficiente e da outras estatisticas que abordaremos a seguir.\nsummary(modelo)\n\n\nCall:\nlm(formula = feminic_tx ~ homic_tx, data = dados)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.28942 -0.30169  0.03482  0.30070  1.18192 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.14673    0.28607   4.009 0.000485 ***\nhomic_tx     0.10580    0.05503   1.923 0.065990 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5882 on 25 degrees of freedom\nMultiple R-squared:  0.1288,    Adjusted R-squared:  0.09397 \nF-statistic: 3.697 on 1 and 25 DF,  p-value: 0.06599\n\n\n\n7.3.2.1 Entendendo os Resultados\n1. Resíduos (Residuals): apresenta a distribuição dos resíduos, observa-se que amediana dos resíduos está próxima a zero.\n2.Coeficientes Em seguida, abaixo tem-se Coefficients com 5 colunas.\nColuna 1: Nome da variável\nColuna 2: Coeficiente estimado \\(\\hat{\\beta_0}\\) o intercepto e \\(\\hat{\\beta_1}\\) do termo da variável homicídio\nColuna 3: É o desvio padrão da estimativas de \\(\\beta\\)\nColuna 4: É a estatistica t utilizada para fazer o teste de hipótese e neste caso, tem-se: \\[H_0:\\beta_0=0\\] e \\[H_0:\\beta_1=0\\]\nColuna 5: É o p-valor, a probabilidade de encontrarmos valores mais extremos da estatística t. Os asteriscos indicam *** signicante a 0,1%; ** a 1%; * a 5%; e \\(.\\) a 10%.\nInterpretando o Coeficiente\nO coeficiente do intercepto nos diz que quando a taxa de homicídio for 0, ainda existira uma taxa de feminicídio de 1,4 pontos (\\(\\beta_0\\)), sendo significante a 0,1%. E cada 1 ponto de aumento na taxa de homicídio, aumenta em 0,106 (\\(\\beta_1\\)) pontos a taxa de feminicídio, significante a 10%.\n3. \\(R^2\\): Em seguida temos o \\(R^2\\) e \\(R^2\\) ajustado. Essas estatísticas calculam quanto da variância da taxa de feminicídio pode ser explicada pela variância da taxa de homicídio. Quando estão próximos a 1 explicam muito, quanto estão próximos a 0 explicam pouco. No caso o nosso \\(R^2\\) ficou baixo e portanto boa parte da variabilidade do feminicídio, não foi explicada pela taxa de homicídio.\n4. Estaística F: E por fim a estatística F mostra o grau de ajustamento do modelo. Se ela for significativa diz que o modelo é bem ajustados aos dados. As variáveis explicativas incluídas são importantes para a explicação da taxa de feminicídio.Essa estatística testa a seguinte hipótese.\n\\[H_0:\\beta_1=...=\\beta_k=0\\] contra\n\\[H_1: H_0\\text{ é falsa}\\]\nVISUALMENTE\nAbaixo tem-se os dados utilizados e a nossa reta de regressão estimada acima. Veja como ela se ajusta a nuve de pontos.\n\n# Ajustando a reta de regessão.\n plot(dados$homic_tx, dados$feminic_tx,\n     main = \"Taxa de Feminicídio vs.Tx de homicidio\",\n     xlab = \"Taxa de Homicidio\",\n     ylab = \"Taxa de Feminicídio\",\n     col = \"steelblue\",          # Cor dos pontos\n     pch = 16,              # Forma dos pontos (círculos sólidos)\n     cex = 1.0,         # Tamanho dos pontos\n     abline(modelo, col = \"lightsalmon3\", lwd = 3))"
  },
  {
    "objectID": "lineares.html#caracteristicas-do-método-dos-mínimos-quadrados-ordinários-em-determinadas-amostras-de-dados",
    "href": "lineares.html#caracteristicas-do-método-dos-mínimos-quadrados-ordinários-em-determinadas-amostras-de-dados",
    "title": "7  Modelos Lineares",
    "section": "7.4 Caracteristicas do Método dos Mínimos Quadrados Ordinários em Determinadas Amostras de Dados",
    "text": "7.4 Caracteristicas do Método dos Mínimos Quadrados Ordinários em Determinadas Amostras de Dados\n\n7.4.1 Valores Estimados e Resíduos\nUma vez estimados \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) temos os valores ajustados ou também denominados de valores preditos ou fitted values.\nPara uma observação qualquer \\(i\\), seu valor estimado é:\n\\[\\hat{y}_i= \\hat{\\beta}_0 + \\hat{\\beta}_1x_i\\]\nTodos os valores \\(\\hat{y}\\) estarão sobre a reta de regressão.\nO resíduo, tal qual definido anteriormente, será a diferença entre o valor ajustado \\(\\hat{y}\\) e o verdadeiro \\(y\\) em nosso banco de dados:\n\\[\\hat{u}_i = y_i - \\hat{y}_i\\]\nSe \\(\\hat{u_i} &gt; 0\\) a regressão subestima \\(y_i\\). Se \\(\\hat{u_i} &lt; 0\\) a reta superestima \\(y_i\\). O cenário ideal é quando \\(\\hat{u}_i= 0\\), algo que quase nunca acontece.\n\n##Obtendo os residuos da regressão\nresid &lt;- residuals(modelo)\n k &lt;- density(resid)\n  plot(k, xlab=\"Erro\",main=\"Densidade de Kernel para o erro\")\n  polygon(k, col=\"burlywood3\", border=\"burlywood4\")\n\n\n\n\n\n\n7.4.2 Propriedades Algébricas do MQO\n\nA Soma dos Resíduos é zero:\n\n\\[\\sum_{i=1}^{n} \\hat{u}_i = 0\\]\n\nsum(resid)\n\n[1] 8.881784e-16\n\n\n\nA covariancia amostral entre a variavel explicativa e os resíduos é zero:\n\n\\[\\sum_{i=1}^{n} x_i \\hat{u}_i = 0\\]\n\n#obtendo a variável x\nx &lt;- dados$homic_tx\n\n#somando com os residuos\nsum(x*resid)\n\n[1] 1.298961e-14\n\n\n\nO ponto \\((\\bar{x},\\bar{y})\\) sempre estará sob a reta de regressão.\nA média dos valores estimados, \\(\\bar{\\hat{y}}\\) é igual a média dos valores observados \\(\\bar{y}\\).\n\n\n#y dos dados \ny &lt;- dados$feminic_tx\nmean(y)\n\n[1] 1.651852\n\n#y estimado\ny_hat &lt;- fitted.values(modelo)\nmean(y_hat)\n\n[1] 1.651852\n\nmean(y)==mean(y_hat)\n\n[1] TRUE\n\n\n\nNote que as estimatvas de MQO decompõe \\(y\\) em 2 partes: 1) os valores ajustados \\(\\hat{y}\\) e os resíduos \\(\\hat{u}\\).\nOs valores de \\(\\hat{y}\\) e \\(\\hat{u}\\) são não correlacionados na amostra!\n\n\n\n7.4.3 Qualidade do Ajuste\nNesta seção vamos responder a seguinte questão: “Quão bem \\(x\\) explica \\(y\\) ?”\nConsidere as seguintes definições\nSoma dos Quadrado Totais (SQT):\n\\[\\text{SQT} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\\]\n\n# Calcular a média da variável dependente (feminic_tx)\nmedia_feminic_tx &lt;- mean(dados$feminic_tx)\n\n# Calcular a Soma dos Quadrados Totais (SQT)\nsqt &lt;- sum((dados$feminic_tx - media_feminic_tx)^2)\nsqt\n\n[1] 9.927407\n\n\nSoma dos Quadrados Explicados (SQE):\n\\[\\text{SQE} = \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2\\]\n\n# Calcular a Soma dos Quadrados Explicados (SQE)\nsqe &lt;- sum((y_hat - media_feminic_tx)^2)\nsqe\n\n[1] 1.27879\n\n\nSoma dos Quadrados dos Resíduos (SQR):\n\\[\\text{SQR} = \\sum_{i=1}^{n} \\hat{u}_i^2\\]\n\nresiduos_quadrados &lt;- residuals(modelo)^2\nsqr &lt;- sum(residuos_quadrados)\nsqr\n\n[1] 8.648617\n\n\nO resultado mais importante é o seguinte:\n\\[SQT =  SQE + SQR\\]\nÉ apartir dessa iguadade que podemos mostrar algo sobre o ajuste dos MQO.\nDívidindo ambos os lados por \\(SQT\\) teremos\n\\[1 = \\frac{\\text{SQE}}{\\text{SQT}}  + \\frac{\\text{SQR}}{\\text{SQT}}\\]\nRearranjando os termos\n\\[R^2 = \\frac{\\text{SQE}}{\\text{SQT}} = 1 - \\frac{\\text{SQR}}{\\text{SQT}}\\]\n\n#r-quadrado do modelo\nr_quadrado &lt;- 1 - (sqr/sqt)\nr_quadrado\n\n[1] 0.1288141\n\n\nNovamente, o \\(R^2\\) é a porcentagem da variação de y que é explicada por \\(x\\). O valor de \\(R^2\\) sempre estará na RLS entre \\(0\\) e \\(1\\)."
  },
  {
    "objectID": "lineares.html#ausência-de-viés-e-variância-dos-estimadores-de-mqo",
    "href": "lineares.html#ausência-de-viés-e-variância-dos-estimadores-de-mqo",
    "title": "6  Modelos Lineares",
    "section": "7.5 Ausência de Viés e Variância dos Estimadores de MQO",
    "text": "7.5 Ausência de Viés e Variância dos Estimadores de MQO\n\n7.5.1 Ausencia de Viés em MQO\nUm estimador não viésado (ou não tendêncioso) por definição, um estimador que em média “acerta” o verdadeiro valor do parâmetro estimado.\nConsidere um estimador arbitrario \\(\\hat{\\theta}\\). Quando dezemos que \\(\\hat{\\theta}\\) é não viesado, queremos dizer que\n\\[E(\\hat{\\theta}) = \\theta\\]\nSerá que os \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) estimados pelo método do MQO são não viésados?\nPara responder a essa pergunta precisamos, mais uma vez, recorrer a novas hipoteses sobre os dados. Esse novo conjunto de hipoteses irão nos permitir verificarmos algumas propriedades estatísticas do método de MQO. A depender das hipóteses, umas mais fracas que outras, as propriedades podem mudar.\nA garantia da ausência de viés, em dados de corte transversal, requer quatro hipóteses:\n1) Linearidade dos Parametros: No modelo Populacional a variavel dependente \\(y\\) está relacionada a variável dependente \\(x\\) e ao termo de erro \\(u\\) como:\n\\[y = \\beta_0 + \\beta_1x + u \\] Por exemplo no modelo \\(y= \\beta_0 + e^{\\beta_1} + u\\), não é linear no parametro \\(\\beta_1\\).\n2) Amostragem Aleatória: Usamos uma amostra aleatória de tamanho \\(n\\), \\(\\{(x_i, y_i): i = 1, 2, ..., n\\}\\) proveniente de um modelo populacional.\n3) Existe Variação Amostral em \\(x\\): Isto é, os valores de nossa variável explicativa não são todos iguais.\n4) Independencia da Média: O termo de erro \\(u\\) tem um valor esperado de zero, dado qualquer valor da variável explicativa.\\[E(u|x) = 0\\]\nDadas as hipóteses 1, 2, 3 e 4:\n\\[E(\\hat{\\beta_1}) = \\beta_1\\]\ne\n\\[E(\\hat{\\beta_0}) = \\beta_0\\]\nPortantos nossoa estimadores de MQO, são não viésados.\n\n\n7.5.2 Variância dos estimadores de MQO\nQuão distantes em média \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\) estão dos verdadeiros parâmetros? Saber disso nos permite escolher o melhor estimador entre todos os etimadores não viesados - ou ao menos entre uma ampla classe deles.\nPara obetermos expressões tratáveis das variâncias do MQO recorremos a mais uma hipótese.\n5) Hipótese de Homoscedasticidade: O erro \\(u\\) tem a mesma variâcia, dado qualquer valor da variável explicativa. Isto é,\n\\[Var(u|x)=\\sigma^2\\]\nA variância de \\(u\\) pode ser reescrita em termos de esperança:\n\\[Var(u|x)= \\sigma^2 = E(u^2|x) - [E(u|x)]^2\\]\nMas como temos por hipótese que \\([E(u|x)]=0\\), a hipótese de homoscedasticidade as vezes é representada como\n\\[ E(u^2|x) = \\sigma^2\\]\nNote também, que como \\(E(u)=0\\), a variancia do erro, não condicional a \\(x\\), será dada por:\n\\[\\sigma^2=E(u^2)=Var(u)\\] Por isso chamamos \\(\\sigma^2\\) de variância do erro.\nPodemos “vizualizar” a hipótese de homoscedasticidade na figura abaixo:\n\n\n\nModelo de Regressão Sob Homoscedasticidade\n\n\nApartir das hiopóteses 1,2,3,4 e 5 podemos progredir no entendimento dos MQO. Sob as hipoteses 1 - 5, as variancias de \\(\\hat{\\beta_1}\\) e \\(\\hat{\\beta_0}\\) são dadas por:\n\\[\\text{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}=\\frac{\\sigma^2}{\\text{SST}_x}\\] e\n\\[\\text{Var}(\\hat{\\beta}_0) = \\frac{\\sigma^2n^{-1}\\sum_{i=1}^{n} x_i^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\\]\nUma extenção da variância dos estimadores de MQO são seus desvios padrão definidos simplismente pela raiz quadrada da variância:\n\\[ep(\\hat{\\beta}_0) = \\sqrt{Var(\\hat{\\beta_0})}\\]\ne\n\\[ep(\\hat{\\beta}_1) = \\sqrt{Var(\\hat{\\beta_1})} = \\frac{\\sigma}{\\sqrt{SQT_x}}\\]\n\n\n7.5.3 Estimação da Variância do erro\nNote que, nas formulas das variâncias e dos desvios-padrão, o que aparece explicitamente é o parâmetro populacional, \\(\\sigma^2\\) e \\(\\sigma\\). Raramente conhecemos esses valores, logo as formulas derivadas acima terão pouca utilidade. Não obstante, caso encontremos um estimador para \\(\\sigma^2\\) e \\(\\sigma\\) podemos usar esse estimador.\nPodemos utilizar os resíduos para construir um estimador da variância dos erros. Lembre que o resíduos da \\(i\\)-ésima observação do modelo é dado por:\n\\[\\hat{u_i} = y_i - \\hat{y_i}\\] Pode-se demostrar que, um estimador não viesado de \\(\\sigma^2\\) será dado por:\n\\[\\hat{\\sigma}^2=\\frac{\\sum_{i=1}^{n} \\hat{u}_i^2}{n-2} = \\frac{\\text{SQR}}{n-2}\\]\nCom \\(\\hat{\\sigma}^2\\) em mãos, podemos reescrever os erros padrão dos estimadores de MQO:\n\\[ep(\\hat{\\beta}_1) = \\sqrt{Var(\\hat{\\beta_1})} = \\frac{\\hat{\\sigma}^2}{\\sqrt{SQT_x}}\\]\nOs erros padrão são utilizados para calcularmos as estatísticas de teste e Intervalos de Confiança para as Estimativas. Mais a frente iremos nos concentar nessas questões."
  },
  {
    "objectID": "lineares.html#aplicação-de-rls---foco-no-erro-padrão-do-parametro-b1",
    "href": "lineares.html#aplicação-de-rls---foco-no-erro-padrão-do-parametro-b1",
    "title": "6  Modelos Lineares",
    "section": "7.6 Aplicação de RLS - Foco no erro padrão do parametro b1",
    "text": "7.6 Aplicação de RLS - Foco no erro padrão do parametro b1\n\n### Aplicação do de RLS - Foco no erro padrão"
  },
  {
    "objectID": "lineares.html#exemplos-de-regressão-multipla-no-contexto-jurídico",
    "href": "lineares.html#exemplos-de-regressão-multipla-no-contexto-jurídico",
    "title": "6  Modelos Lineares",
    "section": "8.1 Exemplos de Regressão Multipla no Contexto Jurídico",
    "text": "8.1 Exemplos de Regressão Multipla no Contexto Jurídico\nDeterminação de Fatores que Afetam o Valor de Indenizações: Variáveis Independentes: Idade da Vítima, Gravidade do Dano, Jurisdição. Variável Dependente: Valor da Indenização.Objetivo: Analisar como a idade da vítima, a gravidade do dano e a jurisdição influenciam o valor das indenizações concedidas\n\\[Indenização = \\beta_0 + \\beta_1 idade+ \\beta_2 Gravidade + \\beta_2 Jurisdisção + u\\]\nAnálise de Variáveis que Influenciam Taxas de Condenação em Casos Criminais: Variáveis Independentes: Idade do Réu, Tipo de Crime, Local do Julgamento. Variável Dependente: Taxa de Condenação.Objetivo: Investigar como a idade do réu, o tipo de crime e o local do julgamento afetam a probabilidade de condenação.\n\\[Tx.Condenação = \\beta_0 + \\beta_1  idade  +  \\beta_2 Local  + \\beta_3  crime + u\\]\nnálise de Fatores que Influenciam a Taxa de Feminicídio: Variáveis Independentes (X): Taxa de Desemprego, Índice de Educação, Presença de Políticas de Proteção à Mulher. Variável Dependente (Y): Taxa de Feminicídio por 100.000 mulheres. Objetivo: Investigar como o desemprego, o nível de educação e a existência de políticas de proteção à mulher estão relacionados à taxa de feminicídio em diferentes regiões.\n\\[Tx.feminicidio = \\beta_0 + \\beta_1 desemprego + \\beta_2 educ + \\beta_3 política + u \\]"
  },
  {
    "objectID": "lineares.html#a-interpretação-da-equação-de-regressão-de-mqo",
    "href": "lineares.html#a-interpretação-da-equação-de-regressão-de-mqo",
    "title": "6  Modelos Lineares",
    "section": "8.2 A Interpretação da Equação de Regressão de MQO",
    "text": "8.2 A Interpretação da Equação de Regressão de MQO\nTal qual no modelo de RLS, temos que:\n\\[\\Delta y = \\beta_1 \\Delta x_1 + \\beta_2 \\Delta x_2 + ...+\\beta_k \\Delta x_k\\]\nO coefiente \\(\\beta_j\\), com \\(j=1,...k\\), mede o efeito do incremento de uma unidade de \\(x_j\\) em \\(y\\).\nSuponha que estejamos interessados no impacto de \\(x_1\\). Podemos fazer o seguinte exercício: Tudo o mais constante qual o impacto de \\(x_1\\) em \\(y\\):\n\\[\\frac{\\Delta y}{\\Delta x} = \\beta_1  \\]\nManter outros fatores fixos permite o cientista social, “mimetizar” um experimento, tal qual nas Ciências Naturasi. Obviamente, isso não tão simples assim. Entretanto, mater outros fatores fixos, e supondo que \\[E(u|x_1, . . . ,x_k) = 0\\] , nos aproxíma de afirmações de cunho causal."
  },
  {
    "objectID": "lineares.html#estimação-dos-k-parametros-na-rlm",
    "href": "lineares.html#estimação-dos-k-parametros-na-rlm",
    "title": "7  Modelos Lineares",
    "section": "7.8 Estimação dos k parametros na RLM",
    "text": "7.8 Estimação dos k parametros na RLM\n\n7.8.1 Estimadores de MQO\nA mecânica para conseguirmos estimativas de \\(\\beta_j\\), fica uma pouco mais complicada. Felizmente, os softwares, tais como o R, fornecem essas estimativas com muita facilidade. Não obstante, convêm apresentar uma abordagem para o cálculo desses parâmetros. Utilizaremos álgebra de matrizes para mostrar um “algoritmo” para calcular esses \\(\\beta_j\\). Em verdade, esse é o algoritmo utilizado pela função lm() do R no computo dos estimadores.\nConsidere o modelo para a \\(i\\)-ésima observação\n\\[y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_{2} x_{i2} + \\beta_{3} x_{i3} + \\ldots + \\beta_k x_{ik} + u\\]\ncomo temos \\(n\\) observações (tamanho de nossa amostra), podemos organizar esses valores em vetores e matrizes.\nAssim, representamos o modelo de RLM da seguinte maneira:\n\\[\\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{u}\\]\nQueremos encontrar um estimador de \\(\\boldsymbol{\\beta}\\), que chamaremos de \\(\\boldsymbol{\\hat{\\beta}}\\). Esse estimador sera dado por:\n\\[\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\\]\nOnde \\(\\mathbf{X}^T\\) é a matriz transposta de \\(\\mathbf{X}\\), e \\((\\mathbf{X}^T \\mathbf{X})^{-1}\\) é a matriz inversa da seguinte multiplicação de matrizes, \\((\\mathbf{X}^T \\mathbf{X})\\)\nEsse vetor de estimativas irá nos fornecer os valores para os \\(\\beta_j\\), com \\(j=1,...,k\\).\n\n\n7.8.2 Estimativas de MQO\nVamos analisar o efeito da taxa de homicídio e da renda per capita sobre a taxa de feminicídio. Ou seja:\n\\[Feminic_i = \\beta_0 + \\beta_1 Homic_{i} + \\beta_{2} Rendapc_i  + u\\]\n\n### Estimando uma regressão Linear Multipla\n\nrlm &lt;- lm(data = dados, feminic_tx ~ homic_tx + rendapc)\n\nsummary(rlm)\n\n\nCall:\nlm(formula = feminic_tx ~ homic_tx + rendapc, data = dados)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.32561 -0.31655 -0.00645  0.31188  1.11840 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) 0.8852186  0.5368738   1.649    0.112  \nhomic_tx    0.1167346  0.0588882   1.982    0.059 .\nrendapc     0.0001447  0.0002499   0.579    0.568  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5962 on 24 degrees of freedom\nMultiple R-squared:  0.1408,    Adjusted R-squared:  0.06921 \nF-statistic: 1.967 on 2 and 24 DF,  p-value: 0.1618\n\n\nA leitura dos resultados é análoga ao que já fizemos anteriormente. O aumento de uma unidade na taxa de homicídio aumenta em 0,11 a taxa de feminicídio e é significante a 10%. Veja o p-valor de 0.059. Entretanto, não há evidências de que a renda pc tem efeito sobre a taxa de feminicídio.\nAssim, estados mais violentos tendem a ter mais feminicídios. Entretanto, estados mais pobres e mais ricos possuem taxas similares de feminicídio.\n\n\n7.8.3 Qualidade do Ajuste na Regressão Linear Multipla\nUm fato importante sobre \\(R^2\\) é que ele nunca diminui ao incluirmos variáveis no modelo. Isso decorre de propriedades algébricas desse indicador. Em nosso exemplo:\n\nModelo somente com Homicídio: \\(R^2=0,12\\)\nModelo com Homicídio e Renda: \\(R^2=0,14\\)\n\nVeja que o \\(R^2\\) aumentou ao incluir a renda pc.\nPor isso, os softwares geralmente reportam uma outra estatística de ajuste o R-quadrado ajustado, \\(\\bar{R}^2\\):\n\\[\\bar{R}^2 = 1 - \\frac{(1 - R^2)(n - 1)}{n - k - 1}\\]\nO \\(\\bar{R}^2\\), tal como expresso acima conta com a presença do \\(R^2\\) original, mas note que, no denominador estamos dividindo por \\(n-k-1\\), onde \\(n\\) é o tamanho da amostra em mãos, e \\(k-1\\) se referem ao fato de termos \\(k\\) variáveis explicativas e uma constante. Portanto, o \\(\\bar{R}^2\\), impões uma penalidade à inclusão de variáveis independentes em um modelo de regressão. No nosso modelo:\n\nModelo somente com Homicídio: \\(R^2=0,12\\) e \\(\\bar{R}^2= 0,094\\)\nModelo com Homicídio e Renda: \\(R^2=0,14\\) e \\(\\bar{R}^2= 0,069\\)\n\nPodemos notar que a inclusão da renda pc contribui muito pouco para a explicação do modelo mas prejudicou as estimativas (menor grau de liberdade). Dessa forma observa-se que o \\(R^2_{ajust}\\) ou \\(\\bar{R}^2\\) ficou menor.\nNão obstante, cabe destacar que um \\(R^2\\) baixo não é uma evidencia definitiva contra nosso modelo. Em ciências sociais é comum verificarmos \\(R^2\\) relatvamente pequenos. Isso significa que, embora coletivamente as variáveis explicativas não expliquem muito das variações de \\(Y\\), é possível que as estimativas de MQO sejam efeitos parciais confiáveis- tudo o mais constante - de cada \\(X_j\\) sobre \\(Y\\).\n\n\n7.8.4 Uso de Variáveis Qualitativas na Análise de RLM\nO uso de variáveis binárias é a alternativa para utilizarmos variáveis qualitativas (discretas ou categóricas) no modelo de regressão. Dessa forma, variáveis que possuem categorias (homem/mulher; regiões, típo de homicídio). Considere os exemplos mencionados anteriormente.\nDeterminação de Fatores que Afetam o Valor de Indenizações:\n\nVariável Dependente \\((Y)\\): Valor da Indenização.\nVariáveis Independentes \\((X)\\): Idade da Vítima, Gravidade do Dano, Jurisdição.\nObjetivo: Analisar como a idade da vítima, a gravidade do dano e a jurisdição influenciam o valor das indenizações concedidas\n\n\\[Indenização = \\beta_0 + \\beta_1 idade+ \\beta_2 Gravidade + \\beta_2 Jurisdisção + u\\]\nAnálise de Variáveis que Influenciam Taxas de Condenação em Casos Criminais:\n\nVariável Dependente \\((Y)\\): Taxa de Condenação.\nVariáveis Independentes \\((X)\\): Idade do Réu, Tipo de Crime, Local do Julgamento.\nObjetivo: Investigar como a idade do réu, o tipo de crime e o local do julgamento afetam a probabilidade de condenação.\n\n\\[Tx.Condenação = \\beta_0 + \\beta_1  idade  +  \\beta_2 Local  + \\beta_3  crime + u\\]\nAnálise de Fatores que Influenciam a Taxa de Feminicídio:\n\nVariável Dependente \\((Y)\\): Taxa de Feminicídio por 100.000 mulheres.\nVariáveis Independentes \\((X)\\): Taxa de Desemprego, Índice de Educação, Presença de Políticas de Proteção à Mulher.\nObjetivo: Investigar como o desemprego, o nível de educação e a existência de políticas de proteção à mulher estão relacionados à taxa de feminicídio em diferentes regiões.\n\n\\[Tx.feminicidio = \\beta_0 + \\beta_1 desemprego + \\beta_2 educ + \\beta_3 política + u \\]\nEm todos esses exemplos temos o que denominamos de variáveis qualitativas. No primeiro exemplo, gravidade e jurisdição não são quantificaveis. No segundo exemplo, o tipo de crime, e a localidade. Por fim, no último exemplo, a variável que indica ou não a presença de uma política pública de proteção a mulher também é qualitativa.\nFelizmente, isso não traz problemas adcionais a estimação de MQO. Pelo menos quando tais variáveis aparecem como variáveis explicativas. Mais a frente veremos o que acontece quando a variável dependente é do tipo qualitativa.\nDuas coisas mudam quando temos as variáveis qualitativas como regressores:\n\nEm primeiro lugar temos que organizar essas informações no banco de dados de modo coerente.\nEm segundo lugar, a introdução de variáveis qualitativas muda a interpretação dos resultados.\n\nFatores qualitativos geralmente aparecem na forma de informações binárias, também denominadas,dummy.\n\n\n\n\n\n\nVariável Binária ou Dummy:\n\n\n\nÉ uma variável que assume o valor 1 se a “condição occorre” e 0 caso o contrário.\n\n\nExemplos:\nO crime de feminicídio ocorreu na região central? * Variável Binária: crime_centro (exemplo de nome) * se sim, ela recebe o valor 1, * se não ocorreu a variável recebe o valor 0.\nNesse caso teremos uma coluna em nosso banco de dados denominada crime_centro, na qual a linha recebe o valor 1 caso o crime tenha ocorrido no centro e 0 caso o contrário.\nO crime foi considerado grave?\n\nVariável Binária: cri_grav (exemplo de nome)\nSe sim, recebe o valor 1,\ncaso contráriorecebe o valor 0.\n\nOutras binárias….\n\n1 se mulher e 0 se for homem.\n1 se for autodeclarado não-branco e 0 se for branco\n1 se trabalha e 0 se não trabalha\n1 se feminicídio e 0 se não for feminicídio.\n\nUtilizar 1 ou 0 é, de fato, um criterio arbitrário, mas essa escolha reside justamente na vantagem de se capturar informações importantes que tornam a interpretação dos resultados mais simples.\nAs observações que receberam 1 como valor serão comparadas com aquelas observações que ficaram com o valor 0. Essas observações seriam nosso “grupo de comparação/grupo base”.\n\n7.8.4.1 Uma única Variável Dummy Independente\nA forma mais simples de incorporar uma variável qualitativa e simplismente adicionarmos a variável binária na equação de regressão.\nConsidere o exemplo prático retirado do livro do Wooldridge. Queremos entender os determinantes dos salários. Obviamente, o exemplo é bastante simples, mas será útil para avaliarmos a questão.\n\\[salario_h = \\beta_0 + \\delta_0 feminino + \\beta_1 educ + \\beta_3 exper + \\beta_4perm + u \\] Nesse exemplo, estamos tentando entender os quais os fatores que afetam os salários dos indivíduos. O salário pode ser explicado pela educação, experência, tempo no cargo e pelo fato de ser mulher. A variável feminino assume o valor 1, se o individuo for do sexo feminino e 0, caso o contrário. Na equação \\(\\delta_0\\) mede a diferença no salário entre homems e mulheres, dado os mesmos anos de estudos, experiência e tempo no cargo, e evidentemente o mesmo \\(u\\).\n\ndata(wage1, package= \"wooldridge\")\n\nwage_f&lt;-lm(wage ~ female+educ+exper+tenure, data=wage1)\nsummary(wage_f)\n\n\nCall:\nlm(formula = wage ~ female + educ + exper + tenure, data = wage1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.7675 -1.8080 -0.4229  1.0467 14.0075 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.56794    0.72455  -2.164   0.0309 *  \nfemale      -1.81085    0.26483  -6.838 2.26e-11 ***\neduc         0.57150    0.04934  11.584  &lt; 2e-16 ***\nexper        0.02540    0.01157   2.195   0.0286 *  \ntenure       0.14101    0.02116   6.663 6.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.958 on 521 degrees of freedom\nMultiple R-squared:  0.3635,    Adjusted R-squared:  0.3587 \nF-statistic:  74.4 on 4 and 521 DF,  p-value: &lt; 2.2e-16\n\n\nO coeficiente estimado para a binária que identifica mulheres foi de -1,81 e significativa a 1%. Isso indica que em média, uma mulher ganha menos US$ 1,81 por hora do que um homem com a mesma educação, experiência e tempo no cargo.\nVeja a figura abaixo ela mostra o efeito da binária feminina. Note que para um mesmo nível de escolaridade, o salário do homem é maior do que o salário da mulher. A dummy “desloca” o intercepto\n\n\n\nVariáveis binárias graficamente, fonte: SEmantic Scholar\n\n\nPodemos utilizar a binária para ver o efeito da experiência para homens e para mulheres. Podemos fazer isso criando uma variável que é a multiplicação entre experiência e feminino. Vejamos:\n\nwage1$exp_f&lt;-wage1$exper*wage1$female\n\n\nwage_f_2&lt;-lm(wage ~ educ+female+ exper+exp_f+tenure, data=wage1)\nsummary(wage_f_2)\n\n\nCall:\nlm(formula = wage ~ educ + female + exper + exp_f + tenure, data = wage1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.3215 -1.6447 -0.4678  1.0431 13.8889 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.27347    0.75952  -2.993 0.002891 ** \neduc         0.58954    0.04938  11.938  &lt; 2e-16 ***\nfemale      -0.87766    0.41570  -2.111 0.035223 *  \nexper        0.05720    0.01589   3.601 0.000348 ***\nexp_f       -0.05635    0.01944  -2.898 0.003908 ** \ntenure       0.12810    0.02148   5.964 4.56e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.937 on 520 degrees of freedom\nMultiple R-squared:  0.3737,    Adjusted R-squared:  0.3676 \nF-statistic: 62.04 on 5 and 520 DF,  p-value: &lt; 2.2e-16\n\nmean(wage1$wage)\n\n[1] 5.896103\n\n\nNesse novo modelo temos agora a binária de mulher, female, que mostra que o fato de ser mulher diminui o salário em -US$0,88. Veja que a média de salário é de US$ 5,9. A queda representa 15% a menos em relação ao homem.\nCom relação a multiplicação pela experiência, podemos assim analisar. Como a variável é 0 para homem, o efeito da experiência para os homens é o próprio coeficiente, exper. Para cada ano a mais de experiência o salário do homem aumenta em US$ 0,057. Para as mulheres é a soma do coeficiente, exper + exp_f. Para cada ao a mais da experência da mulher o mercado paga US$0,001 . Isso está representado no gráfico abaixo.\n\n\n\nVariáveis binárias multiplicativas graficamente, fonte: University of Washington\n\n\n\n\n\n7.8.5 O uso de Dummies para categorias multiplas e Interação entre a dummy e a variável dependente\nConsidere a equação abaixo considerando o mesmo banco de dados anterior:\n\\[log(salarioh) = \\beta_0 + \\beta_1  hsolteiro  +  \\beta_2 mcasadas  + \\beta_3 msolteiras + \\beta_4educ + \\beta_5exper + \\beta_6exper^2 + u\\] Agora vamos dividir entre homens e mulheres, casadas(os) solteiras(os). Note que definimos uma dummy para cada grupo e o grupo de comparação utilizaremos o grupo de homens casados.\nAs estimativas das dummies acima irão captar para cada grupo a diferença proporcional nos salarios-horas relativamente aos homens casados.\n\n###Aplicação de RLM multiplas dummies\n\ndata(wage1, package=\"wooldridge\")\n\n\n### criando as variáveis\nlibrary(\"dplyr\")\n\nwage1 &lt;- wage1 %&gt;%\n  mutate(hcasado = ifelse(female==0 & married==1, 1, 0))\n\nwage1 &lt;- wage1 %&gt;%\n  mutate(mcasada = ifelse(female==1 & married==1, 1, 0))\n\nwage1 &lt;- wage1 %&gt;%\n  mutate(msolteira = ifelse(female==1 & married==0, 1, 0))\n\nwage1 &lt;- wage1 %&gt;%\n  mutate(hsolteiro = ifelse(female==0 & married==0, 1, 0))\n\n\nstatus_civ &lt;- lm(log(wage)~  hsolteiro + msolteira + mcasada + educ+ exper  +I(exper^2)+tenure, data=wage1)\n\nsummary(status_civ)\n\n\nCall:\nlm(formula = log(wage) ~ hsolteiro + msolteira + mcasada + educ + \n    exper + I(exper^2) + tenure, data = wage1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.89832 -0.24486 -0.03093  0.23483  1.11291 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.5370094  0.1070982   5.014 7.33e-07 ***\nhsolteiro   -0.2196913  0.0555033  -3.958 8.61e-05 ***\nmsolteira   -0.3266998  0.0502974  -6.495 1.95e-10 ***\nmcasada     -0.4146530  0.0459328  -9.027  &lt; 2e-16 ***\neduc         0.0795322  0.0067169  11.841  &lt; 2e-16 ***\nexper        0.0297116  0.0051097   5.815 1.06e-08 ***\nI(exper^2)  -0.0005919  0.0001081  -5.475 6.84e-08 ***\ntenure       0.0149328  0.0028460   5.247 2.26e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3949 on 518 degrees of freedom\nMultiple R-squared:  0.4553,    Adjusted R-squared:  0.448 \nF-statistic: 61.86 on 7 and 518 DF,  p-value: &lt; 2.2e-16\n\n\nComo temos um modelos log-nível, a interpretação é dada por \\(\\% \\Delta y = (100 \\beta_1) \\Delta x\\). Com base nas estimativas, verificamos que com relação aos homens casados:\n\nHomens solteiros recebem cerca de 22% a menos.\nMulheres solteiras recebem 32,6% a menos.\nMulheres casadas recebem 41,5% a menos.\n\nMantendo fixas educaçao, experiência e tempo no emprego.\nVariáveis ao Quadrado: interpretando\nNote que temos uma nova variável, a experência, ao quadrado. A variável ao quadrado tenta capturar a seguinte ideia: se cada ano a mais de experiência sempre gera o mesmo incremento de salário, ou se o recebe cada vez menos por cada ano a mais de experiência. Temos agora uma mudança de interpretação\n\\[\\frac{\\% \\Delta y }{\\Delta x}= 100\\beta_5 +200\\beta_6exper  \\]\nCom base nas estimatvas:\n\\[\\frac{\\% \\Delta y }{\\Delta x}= 100\\times0,0297 +200\\times -0,000592 \\times exper\\]\n\\[\\frac{\\% \\Delta y }{\\Delta x}= 2,97 -0,118 \\times exper  \\] Vamos pensar em uma pessoa que tem 0 anos de experiência e adquire um ano. Logo:\n\\[\\frac{\\% \\Delta y }{1}= 2,97 -0,118 \\times 1 = 2,85\\% \\] Ela ira receber 2,85% a mais de salário devido a essa experiência adquirida. Vejamos agora uma pessoa com 9 anos e adquire mais um ano, vai para 10. Logo\n\\[\\frac{\\% \\Delta y }{1}= 2,97 -0,118 \\times 10 = 1,79\\% \\] Esse ano a mais agora adicionou apenas 1,79% no seu salário. Para finalizar vejamos de 24 para 25 anos de experiência\n\\[\\frac{\\% \\Delta y }{1}= 2,97 -0,118 \\times 25 = 0,02\\% \\] Adiciona praticamente zero. E a partir desse ponto a adição será negativa, mais experiência terá menor salário. Assim o ponto de mudança será:\n\\[ 2,97 -0,118 \\times exper = 0 \\implies exper=\\frac{2,97}{0,118}=25,16 \\] O salário vai aumentando até chegar a experiência de 25 anos, depois desse ponto o mercado tende a penalizar com salários menores quem tem mais experiência.\n\n\n7.8.6 Incorporando Informações Ordinais com o uso de Variáveis Dummy.\nVamos agora entender a criação de binárias para variáveis com várias categorias. Um exemplo clássico de variável com diversas categorias é a região onde mora o indivíduo. Podemos ver isso no nosso banco anterior chamado dados:\n\ntable(dados$regiao)\n\n\nCO  N NE  S SD \n 4  7  9  3  4 \n\n\nTemos que escolher uma região de comparação, por exemplo Sudeste. Assim, pode-se criar uma binária para o CO, uma para o N, uma para o NE e uma para o S. Veja o exemplo abaixo.\n\n### criando as variáveis\nlibrary(\"dplyr\")\n\ndados &lt;- dados %&gt;%\n  mutate(CO = ifelse(regiao==\"CO\", 1, 0))\n\ndados &lt;- dados %&gt;%\n  mutate(NE = ifelse(regiao==\"NE\", 1, 0))\n\ndados &lt;- dados %&gt;%\n  mutate(N = ifelse(regiao==\"N\", 1, 0))\n\ndados &lt;- dados %&gt;%\n  mutate(S = ifelse(regiao==\"S\", 1, 0))\n\nComo esse banco é muito pequeno, vamos retomar o banco o Wooldridge wage1. Neste banco já está criada a variável de região sendo a região leste a de comparação. Vamos adicionar na regressão as regiões, sul, centro-norte e oeste.\n\nreg_salar &lt;- lm(log(wage)~  northcen + west+ south + female+ educ+ exper +tenure, data=wage1)\n\nsummary(reg_salar)\n\n\nCall:\nlm(formula = log(wage) ~ northcen + west + south + female + educ + \n    exper + tenure, data = wage1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.01490 -0.25600 -0.02259  0.25361  1.30569 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.534853   0.108019   4.951 9.98e-07 ***\nnorthcen    -0.064811   0.052512  -1.234  0.21768    \nwest         0.078528   0.058211   1.349  0.17792    \nsouth       -0.061050   0.049041  -1.245  0.21374    \nfemale      -0.306808   0.037148  -8.259 1.23e-15 ***\neduc         0.086823   0.006943  12.504  &lt; 2e-16 ***\nexper        0.004808   0.001622   2.963  0.00318 ** \ntenure       0.017148   0.002968   5.777 1.31e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4137 on 518 degrees of freedom\nMultiple R-squared:  0.4022,    Adjusted R-squared:  0.3941 \nF-statistic: 49.79 on 7 and 518 DF,  p-value: &lt; 2.2e-16\n\n\nObserva-se no modelo acima que não há diferenças regionais importantes nos salários, quando controlamos para mulheres, educação, experiência e tempo no trabalho."
  },
  {
    "objectID": "lineares.html#qualidade-do-ajuste-na-regressão-linear-multipla",
    "href": "lineares.html#qualidade-do-ajuste-na-regressão-linear-multipla",
    "title": "6  Modelos Lineares",
    "section": "6.9 Qualidade do Ajuste na Regressão Linear Multipla",
    "text": "6.9 Qualidade do Ajuste na Regressão Linear Multipla\nTal qual na regressão linear simples, são válidas as seguintes relações:\nSoma dos Quadrado Totais (SQT):\n\\[\\text{SQT} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\\]\nSoma dos Quadrados Explicados (SQE):\n\\[\\text{SQE} = \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2\\]\nSoma dos Quadrados dos Resíduos (SQR):\n\\[\\text{SQR} = \\sum_{i=1}^{n} \\hat{u}_i^2\\] Novamente podemos definir a qualidade do ajuste, medido pelo \\(R^2\\), como sendo igual à\n\\[R^2 = \\frac{\\text{SQE}}{\\text{SQT}} = 1 - \\frac{\\text{SQR}}{\\text{SQT}}\\]\nExplicitamente podemos escrever o \\(R^2\\) tal como:\n\\[R^2 =  \\frac{[\\sum_{i=1}^n (y_i - \\bar{y}) ( \\hat{y}_i - \\bar{\\hat{y}} )]^2}{[\\sum_{i=1}^n (y_i - \\bar{y})^2][\\sum_{i=1}^n(\\hat{y}-\\bar{\\hat{y}})^2]}\\]\nUm fato importante sobre \\(R^2\\) é que ele nunca diminui ao incluirmos variáveis no modelo. Isso decorre de propriedades algébricas desse indicador.Por isso, os softwares geralmente reportam uma outra estatística de ajuste o R-quadrado ajustado,\\(\\bar{R}^2\\):\n\\[\\bar{R}^2 = 1 - \\frac{(1 - R^2)(n - 1)}{n - k - 1}\\] O \\(\\bar{R}^2\\), tal como expresso acima conta com a presença do \\(R^2\\) original, mas note que, no denominador estamos dividindo por \\(n-k-1\\), onde \\(n\\) é o tamanho da amostra em mãos, e \\(k-1\\) se referem ao fato de termos \\(k\\) variáveis explicativas e uma constante. Portanto, o \\(\\bar{R}^2\\), impões uma penalidade à inclusão de variáveis independentes em um modelo de regressão.\nCabe destacar que, diferente do \\(R^2\\), \\(\\bar{R}^2\\) pode ser negativo, indicando um ajuste bastante pobre do modelo.\nNão obstante, cabe destacar que um \\(R^2\\) baixo não é definitivamente uma evidencia definitiva contra nosso modelo. Em ciências sociais em geral é bastante comum verificarmos \\(R^2\\) relatvamente pequenos. Isso significa que, embora coletovamente as variáveis explicativas não expliquem muito das variações de \\(y\\), é possível que as estimativas de MQO sejam estimativas confiaveis dos efeitos parciais - tudo o mais constante - de cada \\(x_j\\) sobre \\(y\\)."
  },
  {
    "objectID": "lineares.html#valor-espererado-dos-estimadores-de-mqo",
    "href": "lineares.html#valor-espererado-dos-estimadores-de-mqo",
    "title": "6  Modelos Lineares",
    "section": "6.10 Valor Espererado dos Estimadores de MQO",
    "text": "6.10 Valor Espererado dos Estimadores de MQO\nQuando analisamos a ausencia de viés nos estimadores do modelo de RLS, um invocamos um conjunto de hipóteses. Felizmente, na nalises de RLM tais hipoteses se mantém, bastando apenas algumas modificações para o contexto de mais variáveis explicativas. Abaixo vamos enunciar essas hipoteses que garantem o não viés dos \\(\\beta_j\\) estimados.\n1) Linearidade dos Parametros: No modelo Populacional a variavel dependente \\(y\\) está relacionada as variáveis independentes e ao termo de erro \\(u\\) como:\n\\[y = \\beta_0 + \\beta_1x_1 + ...+\\beta_kx_k+u \\]\n2) Amostragem Aleatória: Usamos uma amostra aleatória de tamanho \\(n\\), \\(\\{(x_{i1},...,x_{ik}, y_i): i = 1, 2, ..., n\\}\\) proveniente de um modelo populacional.\n3) Colinearidade não Perfeita: Na amostra, e portanto na população, nehuma das variáveis explicativas são constantes e não há relações lineares extas entre as variáveis.Isto é, tais variáveis não são perfeitamente correlacionadas.\n***4) Independencia da Média:** O termo de erro \\(u\\) tem um valor esperado de zero, dado qualquer valor da variável explicativa.\n\\[E(u|x_1,...,x_k) = 0\\]\nEssa é a propriedade mais importante. Tal hipótese é violada quando a forma funciinal das variáveis explicativas e da variável dependente está incorreta ou mal especificada.\nQundo a hipótese se mantém, dizemos que as variáveis explicativas são exógenas.\nDadas as hipóteses 1, 2, 3 e 4:\n\\[E(\\hat{\\beta_j}) = \\beta_j\\] Para \\(j = 1,2,...,k\\). Isto é, \\(\\hat{\\beta_j}\\) são não viesados"
  },
  {
    "objectID": "lineares.html#variância-dos-estimadores-de-mqo-1",
    "href": "lineares.html#variância-dos-estimadores-de-mqo-1",
    "title": "6  Modelos Lineares",
    "section": "8.6 Variância dos Estimadores de MQO",
    "text": "8.6 Variância dos Estimadores de MQO\nAnalogamente ao que foi feito no caso da regressão simples, para obtermos a variância dos \\(\\hat{\\beta_j}\\) de MQO presisamos recorrer à mais uma hipótese. Tal hipótese é a de homoscedasticidade. Isto é, de que condicionadas as variáveis explicativas, a variância do termo de erro é constante para todas as observações.\n5) Hipótese de Homoscedasticidade: O erro \\(u\\) tem a mesma variâcia, dado qualquer valor das variáveis explicativas:\n\\[Var(u|x_1,...,x_k)=\\sigma^2\\]\nSob as hipóteses 1,2,3,4 e 5, a varincias de \\(\\hat{\\beta_j}\\) e dada por:\n\\[\\text{Var}(\\hat{\\beta}_j) = \\frac{\\hat{\\sigma}^2}{\\sum_{i=1}^{n} (x_{ij} - \\bar{x_j})^2(1-R^2_j)}=\\frac{\\hat\\sigma^2}{\\text{SQT}_j(1-R^2_j)}\\] Onde \\(SQT_j\\) é a a variação amostral de \\(x_j\\)e \\(R^2_j\\) é o R-quadrado da regressão de \\(x_j\\) sobre as outras variáveis explicativas.O termo \\(\\hat{\\sigma}^2\\) é o estimador da variâcia do termo de erro \\(u\\), dado por:\n\\[\\hat{\\sigma}^2=\\frac{\\sum_{i=1}^{n} \\hat{u}_i^2}{n-k-1} = \\frac{\\text{SQR}}{n-k-1}\\] Onde \\(n-k-1\\) são os graus de liberdade do problema de MQO: \\(k\\) variáveis e uma constantante.\n\n8.6.1 Eficiencia de MQO: O Teorema de Gauss-Markov\nTeorema de Gauss-Markov:Sob as hipóteses 1,2,3,4 e 5 os estimadores \\(\\hat{\\beta}_0,\\hat{\\beta}_1,...,\\hat{\\beta}_k\\) são os melhores estimadores lineares não viesados de \\(\\beta_1, \\beta_2,...,\\beta_k\\).\nSe alguma das hipóteses falhar, o teorema não é mais válido.\nÉ o teorema de Gauss-Markov que justifica o uso do MQO para estimar modelos de Regressão Linear Múltipla."
  },
  {
    "objectID": "lineares.html#uso-de-variáveis-qualitativas-na-análise-de-rlm",
    "href": "lineares.html#uso-de-variáveis-qualitativas-na-análise-de-rlm",
    "title": "6  Modelos Lineares",
    "section": "6.12 Uso de Variáveis Qualitativas na Análise de RLM",
    "text": "6.12 Uso de Variáveis Qualitativas na Análise de RLM\nConsidere os exemplos mencionados anteriormente.\nDeterminação de Fatores que Afetam o Valor de Indenizações: Variáveis Independentes: Idade da Vítima, Gravidade do Dano, Jurisdição. Variável Dependente: Valor da Indenização.Objetivo: Analisar como a idade da vítima, a gravidade do dano e a jurisdição influenciam o valor das indenizações concedidas\n\\[Indenização = \\beta_0 + \\beta_1 idade+ \\beta_2 Gravidade + \\beta_2 Jurisdisção + u\\]\nAnálise de Variáveis que Influenciam Taxas de Condenação em Casos Criminais: Variáveis Independentes: Idade do Réu, Tipo de Crime, Local do Julgamento. Variável Dependente: Taxa de Condenação.Objetivo: Investigar como a idade do réu, o tipo de crime e o local do julgamento afetam a probabilidade de condenação.\n\\[Tx.Condenação = \\beta_0 + \\beta_1  idade  +  \\beta_2 Local  + \\beta_3  crime + u\\]\nAnálise de Fatores que Influenciam a Taxa de Feminicídio: Variáveis Independentes (X): Taxa de Desemprego, Índice de Educação, Presença de Políticas de Proteção à Mulher. Variável Dependente (Y): Taxa de Feminicídio por 100.000 mulheres. Objetivo: Investigar como o desemprego, o nível de educação e a existência de políticas de proteção à mulher estão relacionados à taxa de feminicídio em diferentes regiões.\n\\[Tx.feminicidio = \\beta_0 + \\beta_1 desemprego + \\beta_2 educ + \\beta_3 política + u \\]\nEm todos esses exemplos temos o denominamos de variáveis qualitativas. No primeiro exemplo, gravidade e jurisdição não são quantificaveis. No segundo exemplo, o tipo de crime, e a localidade também não. Por fim, no último exemplo, a variável que indica ou não a presença de uma política pública de proteção a mulher também é qualitativa.\nFelizmente, isso não traz problemas adcionais a estimação de MQO. Pelo menos quando tais variáveis aparecem como variáveis explicativas. Mais a frente veremos o que acontece quando a variável dependente é do tipo qualitativa.\nDuas coisas mudam quando temos as variáveis qualitativas como regressores. Em primeiro lugar temos que organizar essas informações no banco de dados de modo coerente. Em segundo lugar, a introdução de variáveis qualitativas muda a interpretação dos resultados.\nFatores qualitativos geralmente aparecem na forma de informações binárias, também denominadas,dummy.\nVariável Binária ou Dummy: É uma variável que assume o valor 1 se a “condição occorre” e 0 caso o contrario.\nExemplos: O crime de feminicio ocorreu na região central? se sim, ela recebe o valor 1, se não ocorreu a variável recebe o valor 0. Nesse caso teremos uma coluna em nosso banco de dados denominada centro, nas quais a linha recebe o valor 1 caso o crime tenha ocorrido, por exemplo, no centro e 0 caso o contrário.\nO crime foi considerado grave? Se sim, recebe o valor 1 se não recebe o valor 0.\nSuponha que queiramos investigar descriminação de gênero no mercado de trabalho. Se tivermos uma base de dados com informçoes sobre diversos individuos como anos de estudo, experiencia no mercado de trabalho. Podemos ter também uma variavel binaria que assume o valor 1 caso o individuo na amostra for do sexo feminino ou 0 caso o contrario.\nO mesmo pode acontecer com etnia. Podemos ter uma dummy que assuma o valor 1, caso o individuo seja autodeclarado não-branco e 0, caso o contrário.\nAs observações que tiveram 1 como valor serão comparadas com aquelas observações que ficaram com o valor 0. Essas observações seriam nosso “grupo de comparação/grupo base”.\nTrabalhar com variáveis qualitativas é muito comum. Na maioria das vezes cabe ao pesquisador o julgamento de trabalhar com uma variável desse tipo.\nUtilizar 1 ou 0 é, de fato, um criterio arbitrario, mas essa escolha reside justamente na vantagem de se capturar informações importantes que tornam a interpretação dos resultados mais simples.\n\n6.12.1 Uma única Variável Dummy Independente\nA forma mais simples de incorporar uma variável qualitativa e simplismente adcionarmos ela na equação de regressão.\nConsidere o exemplo prático. Queremos relacionar anos de estudo e salários. Obviamente, o exemplo é bastante simples, mas será útil para avaliarmos a questão.\n\\[salarioh = \\beta_0 + \\delta_0 feminino + \\beta_1 educ + \\beta_3 exper + \\beta_4perm + u \\] Nesse exemplo, estamos controlando educação e experiência. A variável feminino assume o valor 1, se o individuo for do sexo feminino e 0, caso o contrário, isto é, o indivíduo é um homem. Na equação \\(\\delta_0\\) mede a diferença no salario entre homems e mulheres, dado os mesmos anos de estudos e de experiencia, e evidentemente o mesmo \\(u\\).\n\ndata(wage1, package= \"wooldridge\")\n\nlm(wage ~ female+educ+exper+tenure, data=wage1)\n\n\nCall:\nlm(formula = wage ~ female + educ + exper + tenure, data = wage1)\n\nCoefficients:\n(Intercept)       female         educ        exper       tenure  \n    -1.5679      -1.8109       0.5715       0.0254       0.1410  \n\n\nSeu coeficiente estimado de -1,81 indica que, em média, uma mulher ganha menos US$ 1,81 por hora do que um homem com a mesma educação, experiência e tempo no cargo."
  },
  {
    "objectID": "lineares.html#alguns-problemas-que-podem-surgir-na-análise-de-regressão",
    "href": "lineares.html#alguns-problemas-que-podem-surgir-na-análise-de-regressão",
    "title": "7  Modelos Lineares",
    "section": "9.8 Alguns Problemas que podem surgir na análise de regressão",
    "text": "9.8 Alguns Problemas que podem surgir na análise de regressão\n\n9.8.1 Viés de Variável Omitida\n\n\n9.8.2 Multicolinearidade\n\n\n9.8.3 Heteroscedasticidade"
  },
  {
    "objectID": "lineares.html#hipótese-de-normalidade",
    "href": "lineares.html#hipótese-de-normalidade",
    "title": "6  Modelos Lineares",
    "section": "7.1 Hipótese de Normalidade",
    "text": "7.1 Hipótese de Normalidade\nPara realizarmos procedimentos de inferência sobre os parâmetros estimados do modelo adotamos a hipótese de normalidade.\n\nHipótese de Normalidade do erro: O termo de erro \\(u\\) é independente das variáveis explicativas com média zero e variância dada por \\(\\sigma^2\\).\n\nCom as hipoteses anteriores mais a hipótese de normalidade, pode-se demostrar que os parâmetros estimados \\(\\hat{\\beta_j}\\) são normalmente distibuídos com média dada por \\(\\beta_j\\) e variância dada por \\(Var(\\hat{\\beta_j})\\).\nNote que, os parâmetros são variáveis aleatórias normalmente distribuídas. Com isso, podemos usar a distribuição normal padrão para calcular as estatísticas de teste, bem como a distribuição \\(t\\).\nIsto é\n\\[\\frac{(\\hat{\\beta_j} - \\beta_j)}{ep(\\hat{\\beta_j})} \\sim N(0,1) \\]\nou\n\\[\\frac{(\\hat{\\beta_j} - \\beta_j)}{ep(\\hat{\\beta_j})} \\sim t_{n-k-1} \\]"
  },
  {
    "objectID": "lineares.html#teste-de-hipotese-sob-um-unico-parametro",
    "href": "lineares.html#teste-de-hipotese-sob-um-unico-parametro",
    "title": "7  Modelos Lineares",
    "section": "10.2 Teste de Hipotese sob um unico Parametro",
    "text": "10.2 Teste de Hipotese sob um unico Parametro\n\n10.2.1 Teste contra Hipoteses Alternativas Unilaterais\n\n\n10.2.2 Teste contra Hipoteses Alternativas Bilaterais\n\n\n10.2.3 Cálculos dos p-valores dos Testes t\n\n\n10.2.4 Teste de Restrições de Lineares Múltiplas: O teste F"
  },
  {
    "objectID": "lineares.html#teste-de-hipótese-sob-um-único-parametro",
    "href": "lineares.html#teste-de-hipótese-sob-um-único-parametro",
    "title": "6  Modelos Lineares",
    "section": "7.2 Teste de Hipótese sob um Único Parametro",
    "text": "7.2 Teste de Hipótese sob um Único Parametro\nNa maior parte do tempo testamos hipóteses do tipo\n\\[H_0: \\hat{\\beta_j}=0\\] Nesse caso a estatística usada no teste será do tipo\n\\[t_{\\hat{\\beta_j}} \\equiv \\frac{\\hat{\\beta_j}}{ep(\\hat{\\beta_j})}\\]\n\n7.2.1 Teste contra Hipoteses Alternativas Unilaterais\nPodemos testar a hipótese de que um dado parâmetro \\(j\\) seja zero, contra uma alternativa unilateral de que \\(\\beta_j &gt; 0\\)\nFormalmente, a hípotese alternativa é\n\\[H_1:  \\beta_j &gt; 0\\] Dado um nível de segnificancia adequado rejeitamos a hipotese nula se\n\\[t_{\\hat{\\beta_j}}  &gt; t_c\\]\nOnde \\(t_c\\) é o valor crítico do teste.\n Oviamente, podemos ter o caso onde\n\\[H_1 = \\beta &lt; 0\\] e a regra de rejeição será\n\\[t_{\\hat{\\beta_j}} &lt; - t_c\\] \n\n\n7.2.2 Teste contra Hipoteses Alternativas Bilaterais\nPode ser o caso onde testa-se \\(H_0\\) contra\n\\[H_1: \\beta_j \\neq 0\\] Nesse caso a região de regeição é dada por:\n\\[|t_{\\hat{\\beta_j}}|  &gt; t_c\\]  ### Cálculos dos p-valores dos Testes t\nDado o valor observado de \\(t_c\\) qual é o menor nível de significancia ao qual a hipótese nula é rejeitada? esse nível é denominado de p-valor do teste de hipótese.\n\n\n7.2.3 Teste de Restrições de Lineares Múltiplas: O teste F\nApós o uso da função summary nota-se que o r também reporta uma estatística denominada de F. Essa estatistica tal qual reportada pelo software testa a seguinte hipótese.\n\\[H_0:\\beta_1=...=\\beta_k=0\\] contra\n\\[H_1: H_0\\text{ é falsa}\\] Essa estatistica de teste é dada por:\n\\[F = \\frac{R^2/k}{(1-R^2)/n-k-1}\\] Pode ser mostrado que \\(F \\sim F_{q,n-k-1}\\)."
  },
  {
    "objectID": "lineares.html#multicolinearidade-pefeita",
    "href": "lineares.html#multicolinearidade-pefeita",
    "title": "6  Modelos Lineares",
    "section": "8.1 5.1 - Multicolinearidade Pefeita",
    "text": "8.1 5.1 - Multicolinearidade Pefeita\nA multicolinearidade é uma violação da hipótese 3. Nesse caso as variáveis ou alguma das variáveis podem ser escritas como uma combinação linear das demais. Esse é um caso extremo e que, no limite, não aparece com frequência nas aplicaçoes empíricas. Não obstante, uma multicolinearidade alta pode aparecer. Na presença de Multicolinearidade, nossos estimadores continuam sendo não viésados. Entretanto, a variância de \\(\\hat{\\beta_j}\\) pode ficar muito elevada, prejudicando os procedimentos de inferência.\nPodemos ver isso ao avaliarmos a formula da variância de uma dado \\(\\hat{\\beta_j}\\) estimado:\n\\[\\text{Var}(\\hat{\\beta}_j) = \\frac{\\hat{\\sigma}^2}{\\sum_{i=1}^{n} (x_{ij} - \\bar{x_j})^2(1-R^2_j)}=\\frac{\\hat\\sigma^2}{\\text{SQT}_j(1-R^2_j)}\\]\nNote que, se a relação linear entre os \\(x_1,...,x_k\\) forem elevadas, o \\(R^2_j\\) será alto. No limite, um \\(R^2_j\\) proximo de faz o denominador da divisão acima ficar muito pequeno. Com um denominador pequeno a \\(\\text{Var}(\\hat{\\beta}_j)\\) fica muito alta. No caso em que há multicolinearidade perfeita, o \\(R^2_j =1\\). logo, a \\(Var(\\hat{\\beta_j})\\) não estará nem mesmo definida (haverá um divisão por zero!).\nNa prática o problema da multicolinearidade não é uma unanimidade entre os autores. Muitos livros textos dedicam capítulos interios para tratar do problema, ao passo que outros autores a enxergam como uma mal menor.\nA razão de se enchergar a multicolinearidade como uma mal menor é o fato de que ao olharmos novamente para o denominador da variância de \\(\\beta_j\\), veremos que a variância de \\(\\hat{\\beta_j}\\) pode diminuir ao aumentarmos a Soma dos Quadrados dos Totais de \\(x_j\\), \\(SQT_j\\). Isso pode ser feito aumentando o tamanho da amostra, e por conseguinte a variabilidade dos valores de \\(x_j\\). Por isso alguns autores se referem de maneira satírica ao problema da multicolinearidade como o problema da micronumerosidade. A razão disso é que, muitas vezes, nossa variância é alta porque nossa amostra é muito pequena."
  },
  {
    "objectID": "lineares.html#heteroscedasticidade",
    "href": "lineares.html#heteroscedasticidade",
    "title": "6  Modelos Lineares",
    "section": "8.2 Heteroscedasticidade",
    "text": "8.2 Heteroscedasticidade\nA heteroscedasticidade é a violação da hipótese de homoscedasticidade. Nesse caso, a variância do termo de erro \\(u\\) deixa de ser constante. Logo cada observação passa a ter sua própria variância.\nNão entraremos nos detalhes técnicos de como resolver o problema. Felizmente, a heterocesdasticidade pode ser detectada e corrigida sem grandes problemas.\nA heteroscedasticidade, embora não interfira no viés das estimativas de MQO, interfere na variância. Quando ela esta presente nossos estimadores de MQO não serão mais eficientes. Isto é, MQO deixa de ter variância mínima. Com isso os erros padrão reportados pelo software estátistico serão problemáticos e todo nosso procedimento de inferência poderá estar comprometido.\nUma saída é computar erros-padrão robustos para nossos estimadores. Tais erros padrão robustos à heteroscedasticidade são maiores que os erros padrão convencionais. Não obstante, podemos nos resguardar do problema da heteroscedasticidade.\nVamos observ\nVamos verificar isso com um exemplo:\n\n### Aplicação: Erros Padrão Robustos à Heteroscedasticidade\n\ndata(gpa3, package=\"wooldridge\")\nlibrary(lmtest)\n\nCarregando pacotes exigidos: zoo\n\n\n\nAnexando pacote: 'zoo'\n\n\nOs seguintes objetos são mascarados por 'package:base':\n\n    as.Date, as.Date.numeric\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\n\n\nAnexando pacote: 'car'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    recode\n\n# Estimativa do modelo para dados do 1 semestre \n reg &lt;- lm(cumgpa~ sat+hsperc+tothrs+female+black+white,\n data=gpa3, subset=(spring==1))\n \n #cumgpa - nota cumulativa do GPA\n #tothrs - Horas totais de estudo\n # sat - score no SAT\n #hsperc - percenti em horas.\n #female - 1 se for mulher\n #black - 1 se for negro\n #white - 1 se for branco\n \n \n # Usual SE:\ncoeftest(reg)\n\n\nt test of coefficients:\n\n               Estimate  Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  1.47006477  0.22980308  6.3971 4.942e-10 ***\nsat          0.00114073  0.00017856  6.3885 5.197e-10 ***\nhsperc      -0.00856636  0.00124042 -6.9060 2.275e-11 ***\ntothrs       0.00250400  0.00073099  3.4255 0.0006847 ***\nfemale       0.30343329  0.05902033  5.1412 4.497e-07 ***\nblack       -0.12828368  0.14737012 -0.8705 0.3846164    \nwhite       -0.05872173  0.14098956 -0.4165 0.6772953    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Refined White heteroscedasticity-robust SE:\n coeftest(reg, vcov=hccm)\n\n\nt test of coefficients:\n\n               Estimate  Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  1.47006477  0.22938036  6.4089 4.611e-10 ***\nsat          0.00114073  0.00019532  5.8402 1.169e-08 ***\nhsperc      -0.00856636  0.00144359 -5.9341 6.963e-09 ***\ntothrs       0.00250400  0.00074930  3.3418   0.00092 ***\nfemale       0.30343329  0.06003964  5.0539 6.911e-07 ***\nblack       -0.12828368  0.12818828 -1.0007   0.31762    \nwhite       -0.05872173  0.12043522 -0.4876   0.62615    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "lineares.html#viés-de-variável-omitida-e-a-correlação-entre-as-variáveis-explicativas-e-o-termo-de-erro.",
    "href": "lineares.html#viés-de-variável-omitida-e-a-correlação-entre-as-variáveis-explicativas-e-o-termo-de-erro.",
    "title": "6  Modelos Lineares",
    "section": "10.3 Viés de Variável Omitida e a Correlação entre as variáveis explicativas e o termo de Erro.",
    "text": "10.3 Viés de Variável Omitida e a Correlação entre as variáveis explicativas e o termo de Erro."
  },
  {
    "objectID": "descritiva.html",
    "href": "descritiva.html",
    "title": "6  Análise Descritiva",
    "section": "",
    "text": "7 Conceitos Básicos de Probabilidade e Estatística"
  },
  {
    "objectID": "descritiva.html#probabilidade-conceitos-básicos",
    "href": "descritiva.html#probabilidade-conceitos-básicos",
    "title": "6  Análise Descritiva",
    "section": "7.1 Probabilidade Conceitos Básicos",
    "text": "7.1 Probabilidade Conceitos Básicos"
  },
  {
    "objectID": "descritiva.html#medidas-de-tendência-central",
    "href": "descritiva.html#medidas-de-tendência-central",
    "title": "6  Análise Descritiva",
    "section": "6.3 Medidas de Tendência Central",
    "text": "6.3 Medidas de Tendência Central"
  },
  {
    "objectID": "descritiva.html#variáveis-aleatórias-e-esperança-matématica",
    "href": "descritiva.html#variáveis-aleatórias-e-esperança-matématica",
    "title": "6  Análise Descritiva",
    "section": "6.4 Variáveis Aleatórias e Esperança Matématica",
    "text": "6.4 Variáveis Aleatórias e Esperança Matématica\n\n6.4.1 Uma Breve Introdução as Variáveis Aleatórias Conjuntamente Distribuídas"
  },
  {
    "objectID": "descritiva.html#conceitos-básicos-inferência-estatística",
    "href": "descritiva.html#conceitos-básicos-inferência-estatística",
    "title": "6  Análise Descritiva",
    "section": "6.3 Conceitos Básicos Inferência Estatística",
    "text": "6.3 Conceitos Básicos Inferência Estatística\nDado a nossa pergunta ou problema, gostariamos de saber as carcateística de uma população.\nEntretantom um processo de levantamento de informações é em geral caro e em muitas situações é destrutivo. Em ciências sociais estamos interessados em características de pessoas, empresas, municípios, estados, países etc. Não é destrutivo mas é uma coleta cara. Por exemplo, o Censo demográfico de 2010 custou R$ 1,3 bilhões, ou aproximadamente R$ 2,2 bi em reais de 2020. O valor é de aproximadamente R$ 35,00 por domicílio.\nDessa forma nosso objetivo aqui é:\n\n\n\n\n\n\nObjetivo\n\n\n\nA partir de uma amostra da população realizar inferência sobre toda a população\n\n\n\n6.3.1 Exemplos do príncipio no dia a dia\nPense nessas situações:\n\nPara medir a glicose muitos pacientes usam uma gota de sangue e um pequeno aparelho. A partir dele sabem quanto tem no corpo todo, basta uma gota para termos boa certeza de quanto é taxa de glicose!\nPara saber se a quantidade de sal está adequada em uma grande panela de arroz, basta uma pequena colher de chá para termos uma boa certeza!\nAbacaxis às vezes são vendidos em caminhões na rua. Quando paramos provamos e são doces. Compramos 4 por 10. Qual a certeza que esses que vc está levando estejam também doces? É diferente das situações anteriores?\n\nCom certeza vc deve ter pensado que essas situações tem grau de certeza variáveis. A diferença está em quão homogênea é a característica na população, o sal no arroz e a glicose no sangue devem ser muito bem distribuidas, ou seja, bem homogêneas. Já a doçura no abacaxi deve ter distribuição maior e provar apenas um abacaxi não nos dá uma ideia do todo.\nEsse é um erro muito comum, a partir de uma ou poucas observações dizer que o todo se comporta da mesma maneira, esse erro se agrava quando maior é a heterogeneidade!!!\n\n\n6.3.2 População, Amostra, Parâmetros e Estimadores\n\n\n6.3.3 População e amostra\n\n\n\n\nflowchart LR\n  A[POPULAÇÃO] --&gt; B[Totalidade das observações sob Investigação]\n  A --&gt; C[AMOSTRA]\n  C --&gt; D[Subconjunto da População]\n\n\n\n\n\nA definição da população depende da pergunta de pesquisa ou análise. Se queremos saber qual o salário médio dos empregados do setor industrial no estado de São Paulo para determinado ano, nossa população são todos os funcionários das indústrias instaladas no estado de São Paulo para esse ano. Se queremos os determinantes do desempenho escolar dos alunos do ensino fundamental no Brasil em 2019, nossa população será esse grupo de alunos nesse ano. Se quisermos avaliar o gasto municipal no ano anterior as eleições no Brasil, temos nossa população formada pelos municípios para o ano de análise.\n\n\n\n\n\n\nPopulação\n\n\n\nQuem define a população é o objetivo do seu trabalho!! Ou seja, seu problema de pesquisa\n\n\n\n\n6.3.4 Amostragem Aleatória Simples\nExistem várias maneiras de fazer uma análise aleatória, uma delas é a simples. Vejamos primeiro um processo de amostragem não aleatório e que possui tendenciosidade. A figura abaixo mostra esse processo[^7]:\n\n\n\nUm processo de amostragem viesádo. Fonte:Data Basecamp\n\n\nObserva-se que existe uma supervalorização do vermelho e uma subvalorização do azul. Chegariamos a conclusão, caso isso fosse uma pesquisa eleitoral, que o candidato vermelho, segunda amostra teria mais chance de ganhar e o azul quase nenhuma chance. O que não condiz com a população. Dizemos que temos uma amostra viesada ou tendenciosa.\nUm processo de amostragem aleatório requer que as características presentes na população estejam presentes na amostras e estejam balanceadas, ou seja, que a sua leitura represente bem o todo."
  },
  {
    "objectID": "manipulacao.html#criando-um-projeto",
    "href": "manipulacao.html#criando-um-projeto",
    "title": "5  Manipulação de Dados",
    "section": "5.1 Criando um projeto",
    "text": "5.1 Criando um projeto\nPrimeiramente precisamos criar um projeto. Clique no icone +R crie um projeto chamado feminicídio em uma nova pasta"
  },
  {
    "objectID": "manipulacao.html#instalando-os-packages-necessários",
    "href": "manipulacao.html#instalando-os-packages-necessários",
    "title": "5  Manipulação de Dados",
    "section": "5.2 Instalando os Packages Necessários",
    "text": "5.2 Instalando os Packages Necessários"
  },
  {
    "objectID": "manipulacao.html#regressão-linear-simples---rls",
    "href": "manipulacao.html#regressão-linear-simples---rls",
    "title": "5  Maipulando os Dados",
    "section": "5.1 Regressão Linear Simples - RLS",
    "text": "5.1 Regressão Linear Simples - RLS\nVamos iniciar o estudo de modelos lineares começando pela Regresão Linear Simples (RLS). Mais específicamente, vamos estudar a RLS no contexto de dados de corte transversal. Tal abordagem, segmentada por tipos de dados, facilíta o entendimento das hipóteses do modelo."
  },
  {
    "objectID": "manipulacao.html",
    "href": "manipulacao.html",
    "title": "5  Maipulando os Dados",
    "section": "",
    "text": "6 O R-project e as Boas Práticas"
  },
  {
    "objectID": "manipulacao.html#o-software-r",
    "href": "manipulacao.html#o-software-r",
    "title": "5  Maipulando os Dados",
    "section": "6.1 O software R",
    "text": "6.1 O software R\nO R é uma linguagem e ambiente de desenvolvimento de Estatística e gráficos. É uma ferramenta poderosa, fornecendo ao seu usuário maior integração e qualidade gráfica e de análise. Alguns motivos para utilizar o R:\n\nÉ Gratuito: é um projeto open-source. Pode ser utilizado em qualquer sistema operacional e tem aberto seus códigos e pactos para poder ser inspecionado.\nR é uma Linguagem:Requer que seja escrito um script ao invés de clicar. A primeira vista uma característica negativa, entretanto, permite maior exploração, organização, memória da atividade, maior integração entre processos etc.\nGráficos e Visualizações: É sem sombra de dúvida o pacote estatístico com melhor e mais poderosa ferramenta de elaboração de gráficos e visualização.\nPacotes Estatísticos:Já possui muitas rotinas de análises já programadas nos diversos pacotes desenvolvidos, sendo muito bem documentados. Já possui muitas rotinas para regressão, regressão com séries temporais, regressão em painel, finanças, modelos de causalidade etc.\nFronteira do Conhecimento: Os principais desenvolvimentos teóricos em Econometria tem sua aplicação demonstrada e desenvolvida utilizando o R. Isso é valido para todas as subáreas do conhecimento em econometria, séries temporais, painel, finanças, etc.\nRecursos de Ajuda: Há uma comunidade muito grande disponível para solucionar dúvidas e uma vasta documentação disponível para consulta na rede.\nConexão com Outros Pacotes: O R integra com outros pacotes que automatizam o nosso trabalho cotidiano. Pode se conectar com o Python, Java, SQL, Latex etc."
  },
  {
    "objectID": "manipulacao.html#utilizando-interface-gráfica---o-rstudio",
    "href": "manipulacao.html#utilizando-interface-gráfica---o-rstudio",
    "title": "5  Maipulando os Dados",
    "section": "6.2 Utilizando Interface Gráfica - O Rstudio",
    "text": "6.2 Utilizando Interface Gráfica - O Rstudio\nPode-se realizar seu script diretamente no console do R. Ele irá realizar um comando por vez. O R é uma interface leve e com poucos recursos gráficos.\nUma alternativa ao uso do R diretamente é o Rstudio, o qual é um editor de código ou um ambiente de desenvolvimento integrado. Ele possui quatro janelas, sendo a primeira a janela de script (superior esquerda) onde escrevemos os comandos em R.\nA segunda janela é o console (inferior esquerda) similar ao que temos no R e onde os resultados são apresentados. Pode-se digitar comando diretamente no console do RStudio.\nA terceira é a janela de ambiente e história (superior direita) ela armazena seus dados, valores e funções e a aba história possui a memoria dos comandos realizados.\nPor fim a quarta janela (inferior direita) apresenta os pacotes, os gráficos, os arquivos gerados e ajuda. Essa janela facilita a instalação de pacotes, carregamento de bibliotecas, visualização de gráficos e o caminho dos arquivos."
  },
  {
    "objectID": "manipulacao.html#ajuda",
    "href": "manipulacao.html#ajuda",
    "title": "5  Maipulando os Dados",
    "section": "6.3 Ajuda",
    "text": "6.3 Ajuda\nPara abrir a ajuda geral o seguinte abaixo pode ser utilizado e abrirá uma janela no seu navegador.\n\nhelp.start()\n\nSuponha que queiramos saber de uma função específica, assim pode-se utilizar o seguinte comando:\n\nhelp(summary)\n\nou\n\n?summary\n\nInclusive pode pedir um exemplo de como utilizar a função que está buscando\n\nexample(summary)"
  },
  {
    "objectID": "manipulacao.html#boas-práticas",
    "href": "manipulacao.html#boas-práticas",
    "title": "5  Maipulando os Dados",
    "section": "6.4 Boas Práticas",
    "text": "6.4 Boas Práticas\nÉ fundamental que o usuário seja organizado. Forma é muito importante! Assim o usuário deve adotar padrões que auxiliem na organização do seu script ou programa.\nCase Sensitivy: O R diferencia letras minúsculas e maiúscula. Ou seja, m é diferente de M. Por exemplo, considere as três formas de escrever a palavra idade.\n\nidade ou Idade ou IDADE\n\nCada uma delas representa variáveis diferentes.\n\n\n\n\n\n\nDICA\n\n\n\nSempre utilize as suas variáveis em minúsculo. Adote isso como regra geral.\n\n\nCriando Bons Nomes: Vamos supor que queiramos criar uma variável que indique a idade que se formou na Universidade. Temos algumas opções:\n\nid: Ruim, pois não tem significado claro e pode confundir com a variável de identificação\nidade_formou_na_universidade: Ruim, pois o nome da variável é muito grande, difícil de escrever e de visualizar no banco de dados.\nidade_form: Bom nome, significativo, minúsculo e pequeno separa os dois nomes por underline\nidadeForm :Bom nome, significativo, minúsculo e pequeno separa os dois nomes por uma letra maiúscula.\n\n\n\n\n\n\n\nDICA\n\n\n\nAdote uma regra de criação para você e evite mudar. Crie nomes pequenos e significativos. Nunca inicie uma variável com número."
  },
  {
    "objectID": "manipulacao.html#criando-projeto-no-r",
    "href": "manipulacao.html#criando-projeto-no-r",
    "title": "5  Maipulando os Dados",
    "section": "6.5 Criando projeto no R",
    "text": "6.5 Criando projeto no R\nPara saber em qual diretório o R está utilizando para salvar seu espaço de trabalho utilize o seguinte comando:\n\ngetwd() \n\nNo RStudio, sempre prefira a criação de um projeto para a organização de seus dados, com isso, ao mudar de máquina (ou estrutura de diretórios) seu código continuará funcionando normalmente.\n\n  File -&gt; New Project"
  },
  {
    "objectID": "manipulacao.html#identação-é-importante",
    "href": "manipulacao.html#identação-é-importante",
    "title": "5  Maipulando os Dados",
    "section": "6.6 Identação é Importante",
    "text": "6.6 Identação é Importante\nIdentar é o recuo no texto em relação a margem. É importante que esse recuo exista para linhas do seu programa que são hierarquicamente conectadas. Vejamos dois exemplos com e sem identação:\nSem Identação\n\nx=c()\nx[1] = 3\nfor (i in 2:9) { \nx[i]=2*x[i-1]\n}\n\nNote que a quarta linha desse programa está hierarquicamente conectada a linha 3 do “for”, ou seja, é uma continuação do comando e portanto deve ser identado para demonstrar essa relação de dependência. Vejamos\nCom Identação\n\nx=c()\nx[1] = 3\nfor (i in 2:9) { \n  x[i]=2*x[i-1]\n}"
  },
  {
    "objectID": "manipulacao.html#tipos-de-variáveis",
    "href": "manipulacao.html#tipos-de-variáveis",
    "title": "5  Maipulando os Dados",
    "section": "7.1 Tipos de Variáveis",
    "text": "7.1 Tipos de Variáveis\nO R possui diversos tipos de variáveis. Alguns desses tipos são:\nVetores: Vamos inserir os dados denúmero de homicídios de mulheres nos diversos Estados brasileiros para o ano de 2022.No primeiro elemento teremos um erro, ao invés de 22 colocaremos 2.E não colocamos o valor do Distrito Federal e nem Tocantins\n\nhomic &lt;- c(2,  73,  22,  88,  406,  264,    95,  137,  127,  101,  75,  309,  200,  86,  256,  219,  70,  283,  60,  281,  88,  33,  101,  423,  37)\nhomic\n\n [1]   2  73  22  88 406 264  95 137 127 101  75 309 200  86 256 219  70 283  60\n[20] 281  88  33 101 423  37\n\n\nPodemos inserir vetores de texto, por exemplo, iremos inserir os estados brasileiros na mesma ordem do homicídio acima.\n\n\n [1] \"Acre\"                \"Alagoas\"             \"Amapá\"              \n [4] \"Amazonas\"            \"Bahia\"               \"Ceará\"              \n [7] \"Distrito Federal \"   \"Espírito Santo\"      \"Goiás\"              \n[10] \"Maranhão\"            \"Mato Grosso\"         \"Mato Grosso do Sul\" \n[13] \"Minas Gerais\"        \"Pará\"                \"Paraíba\"            \n[16] \"Paraná\"              \"Pernambuco\"          \"Piauí\"              \n[19] \"Rio de Janeiro\"      \"Rio Grande do Norte\" \"Rio Grande do Sul\"  \n[22] \"Rondônia\"            \"Roraima\"             \"Santa Catarina\"     \n[25] \"São Paulo\"           \"Sergipe\"             \"Tocantins\"          \n\n\nAlgumas manipulações importantes que podemos fazer com os vetores. Renomeando e removendo o vetor antigo:\nTrocando o primeiro elemento do vetor e dando o print do novo resultado:\n\nhomic_abs[1]=22\nhomic_abs\n\n [1]  22  73  22  88 406 264  95 137 127 101  75 309 200  86 256 219  70 283  60\n[20] 281  88  33 101 423  37\n\n\nAlgumas maneiras de pedir o print do vetor de homicídios femininos. Somente o estado 7, todos menos o estado 7, Estado de 1 até 7 etc:\n\nhomic_abs[7] \n\n[1] 95\n\nhomic_abs[-7] \n\n [1]  22  73  22  88 406 264 137 127 101  75 309 200  86 256 219  70 283  60 281\n[20]  88  33 101 423  37\n\nhomic_abs[1:7]\n\n[1]  22  73  22  88 406 264  95\n\n\nPodemos incorporar novos dados no nosso vetor de homicídio feminino, Vamos incorporar o dado do Tocantins na posição 7 e o valor do Distrito Federal na útima posição - 27. Depois trocaremos os dois estados de posição:\n\n#colcar exemplo de inserir no inicio\n\n#inserir no meio e no final \nhomic_abs &lt;- c(homic_abs[1:6], 36,homic_abs[7:25], 32)\nhomic_abs\n\n [1]  22  73  22  88 406 264  36  95 137 127 101  75 309 200  86 256 219  70 283\n[20]  60 281  88  33 101 423  37  32\n\n#troca de posicoes\ntemp &lt;- homic_abs[27]\nhomic_abs[27] &lt;- homic_abs[7]\nhomic_abs[7] &lt;- temp\nhomic_abs\n\n [1]  22  73  22  88 406 264  32  95 137 127 101  75 309 200  86 256 219  70 283\n[20]  60 281  88  33 101 423  37  36\n\n\nString ou Texto:\nString são as variáveis tipo texto. Esse tipo de variável já apareceu na seção anterior quando apresentamos um vetor com a classificação dos Estados. Vejamos mais uma vez. Podemos criar uma variável que contêm “estado homicidio”. Uma segunda maneira é criar um vetor com dois elementos “estado” e “homicidio”. O comando paste cola a variável texto “estado” e a variável texto “homicidio”, separado por um espaço.\n\na &lt;- \"estado homicidio\"\na\n\n[1] \"estado homicidio\"\n\nb &lt;- c(\"estado\",\"homicidio\")\nb\n\n[1] \"estado\"    \"homicidio\"\n\nb[1]\n\n[1] \"estado\"\n\npaste(b[1],b[2],sep=' ')\n\n[1] \"estado homicidio\"\n\n\nFator:\nFator são variáveis de classe. Fator armazenam os valores inteiros na forma de um vetor com as quantidades das k classes e o vetor string dos valores originais. Vejamos o exemplo de um vetor. Podemos análisar os homicídios por região geográfica do país. Assim, classificaremos os estados por região:\n\nregiao &lt;- c(\"N\",  \"NE\",  \"N\",  \"N\",  \"NE\",  \"NE\",  \"CO\",  \"SD\",  \"CO\",  \"NE\",  \"CO\",  \"CO\",  \"SD\",  \"N\",  \"NE\",  \"S\",  \"NE\",  \"NE\",  \"SD\",  \"NE\",  \"S\",  \"N\",  \"N\",  \"S\",  \"SD\",  \"NE\",  \"N\")\nsummary(regiao)\n\nAgora vamos transformar o vetor anterior em um fator\n\nregiao &lt;- factor(regiao)\nsummary(regiao)\n\nCO  N NE  S SD \n 4  7  9  3  4 \n\nlevels(regiao)\n\n[1] \"CO\" \"N\"  \"NE\" \"S\"  \"SD\"\n\n\nO comando levels fornece as classes existentes, no caso acima temos 5, sendo elas 4, 7, 9, 3 e 4.\nFatores podem ser as características de raça, gênero, status familiar, status de saúde, qualidade do atendimento etc.\n\n7.1.1 Data Frame ou Banco de Dados\nEsse é um tipo mais geral de variável e consegue lidar na mesma estrutura com variaveis de tipos distintos como numérica, texto e fator. Um banco de dados similar aos outros programas estatísticos. Podemos criar essa variável de forma manual. Nosso banco de dados será composto por 4 variáveis, a primeira o estado, a segunda a região, a terceira o número de homicídios femininos e a quarta o número de feminicidios. As três primeiras já foram incluidas acima e vamos criar somente a quarta. O comando typeof mostra qual o tipo de variável.\n\nfeminic_abs=c(11,  31,  8,  21,  107,  28,  19,  33,  56,  69,  47,  40,  171,  49,  26,  77,  72,  24,  111,  16,  110,  24,  3,  56,  195,  19,  14) \ntypeof(feminic_abs)\n\n[1] \"double\"\n\n\nPara criar o banco de dados utilizamos o seguinte comando:\n\ndata_feminic22&lt;-data.frame(estados, regiao, homic_abs, feminic_abs)  \n\nPodemos modificar o nome das variáveis com o comando names. Entretanto, tem que renomear todas\n\nnames(data_feminic22)&lt;-c(\"estado\", \"regioa\", \"homic_abs\", \"feminic_abs\") \ndata_feminic22\n\nOu podemos renomear somente algumas com o comando reshape:\n\nlibrary(reshape)\ndata_feminic22 &lt;- rename(data_feminic22, c(estado=\"estados\", regioa=\"regiao\"))\ndata_feminic22\n\n               estados regiao homic_abs feminic_abs\n1                 Acre      N        22          11\n2              Alagoas     NE        73          31\n3                Amapá      N        22           8\n4             Amazonas      N        88          21\n5                Bahia     NE       406         107\n6                Ceará     NE       264          28\n7    Distrito Federal      CO        32          19\n8       Espírito Santo     SD        95          33\n9                Goiás     CO       137          56\n10            Maranhão     NE       127          69\n11         Mato Grosso     CO       101          47\n12  Mato Grosso do Sul     CO        75          40\n13        Minas Gerais     SD       309         171\n14                Pará      N       200          49\n15             Paraíba     NE        86          26\n16              Paraná      S       256          77\n17          Pernambuco     NE       219          72\n18               Piauí     NE        70          24\n19      Rio de Janeiro     SD       283         111\n20 Rio Grande do Norte     NE        60          16\n21   Rio Grande do Sul      S       281         110\n22            Rondônia      N        88          24\n23             Roraima      N        33           3\n24      Santa Catarina      S       101          56\n25           São Paulo     SD       423         195\n26             Sergipe     NE        37          19\n27           Tocantins      N        36          14\n\n\nPodemos também listar variáveis do banco de dados, por exemplo, listar colunas de 1 a 2 ou listar por nome das variáveis, conforme apresentado abaixo:\n\ndata_feminic22\ndata_feminic22[,2:3]\ndata_feminic22[1:2,2:3]\ndata_feminic22[c(\"regiao\",\"feminic_abs\")]\n\nEntretanto, inserir dados na mão pode ser uma tarefa muito penosa e existem soluções bem mais simples e rápidas para inserção de dados. Nas seções seguintes veremos aprenderemos mais funções úteis para lidar com banco de dados.\n\n\n7.1.2 Trabalhando com as variáveis:\nVamos retomar duas variáveis homic_abs e estado e vamos manipular essas duas variáveis. Primeiramente vejamos o número de elementos, estrutura, classe e nome:\n\nlength(homic_abs) \n\n[1] 27\n\nstr(homic_abs)    \n\n num [1:27] 22 73 22 88 406 264 32 95 137 127 ...\n\nclass(homic_abs)  \n\n[1] \"numeric\"\n\nnames(homic_abs) \n\nNULL\n\n\nObservamos que a variável não possui labels. Vamos colocar os Labels nessa variável, ou seja, os rótulos.\n\nnames(dolar15) &lt;-c(\"cambio15_jan\",\"cambio15_fev\",\"cambio15_mar\",\"cambio15_abr\",\n                   \"cambio15_mai\",\"cambio15_jun\",\"cambio15_jul\",\"cambio15_ago\",\n                   \"cambio15_set\",\"cambio15_out\",\"cambio15_nov\",\"cambio15_dez\") \n\nPodemos combinar as duas variáveis de forma distintas, por exemplo combinar na forma de um vetor, combinar como coluna ou combinar como linha, vejamos a diferença:\n\n#Precisa mudar essa parte de posição está confuso pois falamos de dataframe e aqui de vetor\ncomb1 &lt;- c(homic_abs,estados)      \ncomb2&lt;- cbind(homic_abs,estados)\ncomb3 &lt;-rbind(homic_abs,estados)\ncomb4 &lt;- data.frame(\n              homic_abs,\n              estados\n              ,stringsAsFactors = F)\ncomb1\ncomb2 \ncomb3\ncomb4\n\nVejamos quais objetos temos e vamos pedir para visualizar os objetos que acabamos de criar. Por fim removeremos o vetor comb1.\n\nls()  \ncomb1\ncomb2\ncomb3\nrm(comb1)"
  },
  {
    "objectID": "manipulacao.html#importando-os-dados",
    "href": "manipulacao.html#importando-os-dados",
    "title": "5  Maipulando os Dados",
    "section": "7.2 Importando os Dados",
    "text": "7.2 Importando os Dados\nDisponibilizamos dois banco de dados, um contendo os homicídios e feminicídios por estado e outro com as tentativas. Esses arquivos estão em formato csv (comma separated values).\nPara leitura desse arquivo em csv o seguinte comando é necessário read.csv, indicado que possui cabeçalho e que o separador é “;”\n\ndf_feminic22&lt;-read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/dados_feminic.csv\", head=TRUE,sep=\";\")\n\ndf_t_feminic22&lt;-read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/dados_tent_feminic.csv\", head=TRUE,sep=\";\")\n\nPara leitura de arquivos em Stata terá que utilizar o pacote foreign, conforme exemplo abaixo:\n\nlibrary(foreign)\nstata_feminic &lt;- read.dta(\"~/feminic.dta\")\n\nAlém desses, o R é capaz de trabalhar com SQL, SAS, SPSS, Excel entre outros.\n\n\n\n\n\n\nCuidado com o Ponto\n\n\n\nO R usa o formato americano de separação numérica. Usa ponto ao invés da vírgula para separar a unidade dos decimais. No Brasil usamos a vírgula. Isso sempre gera conflito. No seu csv evite usar acentos nas palavras e use ponto como separados dos decimais e não use separador dos milhares. Exemplo: 12500.97"
  },
  {
    "objectID": "manipulacao.html#exportanto-os-dados",
    "href": "manipulacao.html#exportanto-os-dados",
    "title": "5  Maipulando os Dados",
    "section": "7.3 Exportanto os Dados",
    "text": "7.3 Exportanto os Dados\nPodemos exportar os dados em diferentes formatos. Alguns exemplos são csv, texto delimitado, excel, stata. Vejamos em csv:\n\nwrite.table(df_feminic22, \"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/export_feminic.csv\", sep=\";\")\n\nPara exportar em Stata utilize os seguintes comandos:\n\nlibrary(foreign)\nwrite.dta(df_feminic22, paste(getwd(),\"~/Banco de dados/export_feminic.dta\",sep=''))"
  },
  {
    "objectID": "manipulacao.html#características-dos-dados",
    "href": "manipulacao.html#características-dos-dados",
    "title": "5  Maipulando os Dados",
    "section": "7.4 Características dos Dados",
    "text": "7.4 Características dos Dados\n\n7.4.1 Lidando com Dados Missing\nNão temos informação para as tentativas de feminicidio para os estados de São Paulo e Mato Grosso. Uma maneira de lidar com valores missing seria fazer um subconjunto que veremos mais a frente. Agora seguiremos alguns passos para analisar os valores missing do nosso banco de dados.\nPrimeiramente, analisamos se há valores missing no banco de dados:\n\nis.na(df_t_feminic22)\n\nPodemos desconsiderar os valores missing da análise de interesse, vamos fazer a média do dolar sem considerar os valores missing:\n\nmean(df_t_feminic22$t_feminic_abs) \n\n[1] NA\n\nmean(df_t_feminic22$t_feminic_abs, na.rm=TRUE)\n\n[1] 102.52\n\n\nPodemos criar um novo banco de dados sem os valores missing.\n\ndf_t_feminic22_sem_missing &lt;- na.omit(df_t_feminic22)\nmean(df_t_feminic22_sem_missing$t_feminic_abs)\n\n[1] 102.52\n\nrm(df_t_feminic22_sem_missing)\n\nOutra maneira de excluir os valores missing seria a utilização do comando subset removendo as observações que contenham valor missing. Isso será explicado em seção a frente.\nPode-se também recodificar uma determinada variável para missing. Muito comum nas pesquisas do IBGE os valores missing serem identificados por um número, por exemplo 999999999999. Dessa forma podemos indicar que esse não é número e sim um valor missing da seguinte maneira:\n\ndf_t_feminic22$t_feminic_abs[df_t_feminic22$t_feminic_abs==999999] &lt;- NA\n\nTodos os valores que forem 99 serão exluídos e a celula ficará com um NA\n\n\n\n\n\n\nDados Missing\n\n\n\nDoois pontos importantes, dados missing não é 0 e nunca devem ser substituídos por 0. Pois 0 é um valor e missing é que não sabemos. Outro ponto é que devemos evitar excluir do banco os dados missing, melhor é fazer as contas retirando apensa do cálculo"
  },
  {
    "objectID": "manipulacao.html#criando-uma-nova-variável",
    "href": "manipulacao.html#criando-uma-nova-variável",
    "title": "5  Maipulando os Dados",
    "section": "8.1 Criando uma Nova Variável",
    "text": "8.1 Criando uma Nova Variável\nVamos criar uma variável que seria a soma dos homicídios e feminicídios no estado. Para criar a variável precisamos dizer primeiro qual o banco de dados em que queremos criar e qual o nome da variável, conforme apresentado na expressão abaixo.\n\nlibrary(reshape)\ndf_feminic22 &lt;- rename(df_feminic22, c(feminico_abs=\"feminic_abs\"))\n\n\ndf_t_feminic22$t_total_abs&lt;- df_t_feminic22$t_feminic_abs + df_t_feminic22$t_homic_abs\n\ndf_feminic22$total_abs&lt;- df_feminic22$feminic_abs + df_feminic22$homic_abs\n\nAgora vamos criar uma variável binária que representa como 1 os estados que possuem a taxa de feminicídio em relação ao total de homicídios maior que 50%. Novamente, precisamos indicar o banco de dados e o nome da variável no banco de dados.\n\n#attach(dolar_ipa_total1)\ndf_feminic22$mais_50[df_feminic22$part_feminic &lt; 50] &lt;- 0\ndf_feminic22$mais_50[df_feminic22$part_feminic &gt;= 50] &lt;- 1\n#head(dolar_ipa_total1)\n#detach(dolar_ipa_total1)\ndf_feminic22$mais_50\n\n [1] 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0"
  },
  {
    "objectID": "manipulacao.html#operadores-aritméticos-e-lógicos",
    "href": "manipulacao.html#operadores-aritméticos-e-lógicos",
    "title": "5  Maipulando os Dados",
    "section": "8.2 Operadores Aritméticos e Lógicos",
    "text": "8.2 Operadores Aritméticos e Lógicos"
  },
  {
    "objectID": "manipulacao.html#o-r-project-e-as-boas-práticas",
    "href": "manipulacao.html#o-r-project-e-as-boas-práticas",
    "title": "3  Maipulando os Dados",
    "section": "3.1 O R-project e as Boas Práticas",
    "text": "3.1 O R-project e as Boas Práticas\n\n3.1.1 O software R\nO R é uma linguagem e ambiente de desenvolvimento de Estatística e gráficos. É uma ferramenta poderosa, fornecendo ao seu usuário maior integração e qualidade gráfica e de análise. Alguns motivos para utilizar o R:\n\nÉ Gratuito: é um projeto open-source. Pode ser utilizado em qualquer sistema operacional e tem aberto seus códigos e pactos para poder ser inspecionado.\nR é uma Linguagem:Requer que seja escrito um script ao invés de clicar. A primeira vista uma característica negativa, entretanto, permite maior exploração, organização, memória da atividade, maior integração entre processos etc.\nGráficos e Visualizações: É sem sombra de dúvida o pacote estatístico com melhor e mais poderosa ferramenta de elaboração de gráficos e visualização.\nPacotes Estatísticos:Já possui muitas rotinas de análises já programadas nos diversos pacotes desenvolvidos, sendo muito bem documentados. Já possui muitas rotinas para regressão, regressão com séries temporais, regressão em painel, finanças, modelos de causalidade etc.\nFronteira do Conhecimento: Os principais desenvolvimentos teóricos em Econometria tem sua aplicação demonstrada e desenvolvida utilizando o R. Isso é valido para todas as subáreas do conhecimento em econometria, séries temporais, painel, finanças, etc.\nRecursos de Ajuda: Há uma comunidade muito grande disponível para solucionar dúvidas e uma vasta documentação disponível para consulta na rede.\nConexão com Outros Pacotes: O R integra com outros pacotes que automatizam o nosso trabalho cotidiano. Pode se conectar com o Python, Java, SQL, Latex etc.\n\n\n\n3.1.2 Utilizando Interface Gráfica - O Rstudio\nPode-se realizar seu script diretamente no console do R. Ele irá realizar um comando por vez. O R é uma interface leve e com poucos recursos gráficos.\nUma alternativa ao uso do R diretamente é o Rstudio, o qual é um editor de código ou um ambiente de desenvolvimento integrado. Ele possui quatro janelas, sendo a primeira a janela de script (superior esquerda) onde escrevemos os comandos em R.\nA segunda janela é o console (inferior esquerda) similar ao que temos no R e onde os resultados são apresentados. Pode-se digitar comando diretamente no console do RStudio.\nA terceira é a janela de ambiente e história (superior direita) ela armazena seus dados, valores e funções e a aba história possui a memoria dos comandos realizados.\nPor fim a quarta janela (inferior direita) apresenta os pacotes, os gráficos, os arquivos gerados e ajuda. Essa janela facilita a instalação de pacotes, carregamento de bibliotecas, visualização de gráficos e o caminho dos arquivos.\n\n\n3.1.3 Ajuda\nPara abrir a ajuda geral o seguinte abaixo pode ser utilizado e abrirá uma janela no seu navegador.\n\nhelp.start()\n\nSuponha que queiramos saber de uma função específica, assim pode-se utilizar o seguinte comando:\n\nhelp(summary)\n\nou\n\n?summary\n\nInclusive pode pedir um exemplo de como utilizar a função que está buscando\n\nexample(summary)\n\n\n\n3.1.4 Boas Práticas\nÉ fundamental que o usuário seja organizado. Forma é muito importante! Assim o usuário deve adotar padrões que auxiliem na organização do seu script ou programa.\nCase Sensitivy: O R diferencia letras minúsculas e maiúscula. Ou seja, m é diferente de M. Por exemplo, considere as três formas de escrever a palavra idade.\n\nidade ou Idade ou IDADE\n\nCada uma delas representa variáveis diferentes.\n\n\n\n\n\n\nDICA\n\n\n\nSempre utilize as suas variáveis em minúsculo. Adote isso como regra geral.\n\n\nCriando Bons Nomes: Vamos supor que queiramos criar uma variável que indique a idade que se formou na Universidade. Temos algumas opções:\n\nid: Ruim, pois não tem significado claro e pode confundir com a variável de identificação\nidade_formou_na_universidade: Ruim, pois o nome da variável é muito grande, difícil de escrever e de visualizar no banco de dados.\nidade_form: Bom nome, significativo, minúsculo e pequeno separa os dois nomes por underline\nidadeForm :Bom nome, significativo, minúsculo e pequeno separa os dois nomes por uma letra maiúscula.\n\n\n\n\n\n\n\nDICA\n\n\n\nAdote uma regra de criação para você e evite mudar. Crie nomes pequenos e significativos. Nunca inicie uma variável com número.\n\n\n\n\n3.1.5 Criando projeto no R\nPara saber em qual diretório o R está utilizando para salvar seu espaço de trabalho utilize o seguinte comando:\n\ngetwd() \n\nNo RStudio, sempre prefira a criação de um projeto para a organização de seus dados, com isso, ao mudar de máquina (ou estrutura de diretórios) seu código continuará funcionando normalmente.\n\n  File -&gt; New Project\n\n\n\n3.1.6 Identação é Importante\nIdentar é o recuo no texto em relação a margem. É importante que esse recuo exista para linhas do seu programa que são hierarquicamente conectadas. Vejamos dois exemplos com e sem identação:\nSem Identação\n\nx=c()\nx[1] = 3\nfor (i in 2:9) { \nx[i]=2*x[i-1]\n}\n\nNote que a quarta linha desse programa está hierarquicamente conectada a linha 3 do “for”, ou seja, é uma continuação do comando e portanto deve ser identado para demonstrar essa relação de dependência. Vejamos\nCom Identação\n\nx=c()\nx[1] = 3\nfor (i in 2:9) { \n  x[i]=2*x[i-1]\n}"
  },
  {
    "objectID": "manipulacao.html#inserindo-dados-no-r",
    "href": "manipulacao.html#inserindo-dados-no-r",
    "title": "3  Maipulando os Dados",
    "section": "3.2 Inserindo Dados no R",
    "text": "3.2 Inserindo Dados no R\n\n3.2.1 Tipos de Variáveis\nO R possui diversos tipos de variáveis. Alguns desses tipos são:\nVetores: Vamos inserir os dados denúmero de homicídios de mulheres nos diversos Estados brasileiros para o ano de 2022.No primeiro elemento teremos um erro, ao invés de 22 colocaremos 2.E não colocamos o valor do Distrito Federal e nem Tocantins\n\nhomic &lt;- c(2,  73,  22,  88,  406,  264,    95,  137,  127,  101,  75,  309,  200,  86,  256,  219,  70,  283,  60,  281,  88,  33,  101,  423,  37)\nhomic\n\n [1]   2  73  22  88 406 264  95 137 127 101  75 309 200  86 256 219  70 283  60\n[20] 281  88  33 101 423  37\n\n\nPodemos inserir vetores de texto, por exemplo, iremos inserir os estados brasileiros na mesma ordem do homicídio acima.\n\n\n [1] \"Acre\"                \"Alagoas\"             \"Amapá\"              \n [4] \"Amazonas\"            \"Bahia\"               \"Ceará\"              \n [7] \"Distrito Federal \"   \"Espírito Santo\"      \"Goiás\"              \n[10] \"Maranhão\"            \"Mato Grosso\"         \"Mato Grosso do Sul\" \n[13] \"Minas Gerais\"        \"Pará\"                \"Paraíba\"            \n[16] \"Paraná\"              \"Pernambuco\"          \"Piauí\"              \n[19] \"Rio de Janeiro\"      \"Rio Grande do Norte\" \"Rio Grande do Sul\"  \n[22] \"Rondônia\"            \"Roraima\"             \"Santa Catarina\"     \n[25] \"São Paulo\"           \"Sergipe\"             \"Tocantins\"          \n\n\nAlgumas manipulações importantes que podemos fazer com os vetores. Renomeando e removendo o vetor antigo:\nTrocando o primeiro elemento do vetor e dando o print do novo resultado:\n\nhomic_abs[1]=22\nhomic_abs\n\n [1]  22  73  22  88 406 264  95 137 127 101  75 309 200  86 256 219  70 283  60\n[20] 281  88  33 101 423  37\n\n\nAlgumas maneiras de pedir o print do vetor de homicídios femininos. Somente o estado 7, todos menos o estado 7, Estado de 1 até 7 etc:\n\nhomic_abs[7] \n\n[1] 95\n\nhomic_abs[-7] \n\n [1]  22  73  22  88 406 264 137 127 101  75 309 200  86 256 219  70 283  60 281\n[20]  88  33 101 423  37\n\nhomic_abs[1:7]\n\n[1]  22  73  22  88 406 264  95\n\n\nPodemos incorporar novos dados no nosso vetor de homicídio feminino, Vamos incorporar o dado do Tocantins na posição 7 e o valor do Distrito Federal na útima posição - 27. Depois trocaremos os dois estados de posição:\n\n#colcar exemplo de inserir no inicio\n\n#inserir no meio e no final \nhomic_abs &lt;- c(homic_abs[1:6], 36,homic_abs[7:25], 32)\nhomic_abs\n\n [1]  22  73  22  88 406 264  36  95 137 127 101  75 309 200  86 256 219  70 283\n[20]  60 281  88  33 101 423  37  32\n\n#troca de posicoes\ntemp &lt;- homic_abs[27]\nhomic_abs[27] &lt;- homic_abs[7]\nhomic_abs[7] &lt;- temp\nhomic_abs\n\n [1]  22  73  22  88 406 264  32  95 137 127 101  75 309 200  86 256 219  70 283\n[20]  60 281  88  33 101 423  37  36\n\n\nString ou Texto:\nString são as variáveis tipo texto. Esse tipo de variável já apareceu na seção anterior quando apresentamos um vetor com a classificação dos Estados. Vejamos mais uma vez. Podemos criar uma variável que contêm “estado homicidio”. Uma segunda maneira é criar um vetor com dois elementos “estado” e “homicidio”. O comando paste cola a variável texto “estado” e a variável texto “homicidio”, separado por um espaço.\n\na &lt;- \"estado homicidio\"\na\n\n[1] \"estado homicidio\"\n\nb &lt;- c(\"estado\",\"homicidio\")\nb\n\n[1] \"estado\"    \"homicidio\"\n\nb[1]\n\n[1] \"estado\"\n\npaste(b[1],b[2],sep=' ')\n\n[1] \"estado homicidio\"\n\n\nFator:\nFator são variáveis de classe. Fator armazenam os valores inteiros na forma de um vetor com as quantidades das k classes e o vetor string dos valores originais. Vejamos o exemplo de um vetor. Podemos análisar os homicídios por região geográfica do país. Assim, classificaremos os estados por região:\n\nregiao &lt;- c(\"N\",  \"NE\",  \"N\",  \"N\",  \"NE\",  \"NE\",  \"CO\",  \"SD\",  \"CO\",  \"NE\",  \"CO\",  \"CO\",  \"SD\",  \"N\",  \"NE\",  \"S\",  \"NE\",  \"NE\",  \"SD\",  \"NE\",  \"S\",  \"N\",  \"N\",  \"S\",  \"SD\",  \"NE\",  \"N\")\nsummary(regiao)\n\nAgora vamos transformar o vetor anterior em um fator\n\nregiao &lt;- factor(regiao)\nsummary(regiao)\n\nCO  N NE  S SD \n 4  7  9  3  4 \n\nlevels(regiao)\n\n[1] \"CO\" \"N\"  \"NE\" \"S\"  \"SD\"\n\n\nO comando levels fornece as classes existentes, no caso acima temos 5, sendo elas 4, 7, 9, 3 e 4.\nFatores podem ser as características de raça, gênero, status familiar, status de saúde, qualidade do atendimento etc.\n\n3.2.1.1 Data Frame ou Banco de Dados\nEsse é um tipo mais geral de variável e consegue lidar na mesma estrutura com variaveis de tipos distintos como numérica, texto e fator. Um banco de dados similar aos outros programas estatísticos. Podemos criar essa variável de forma manual. Nosso banco de dados será composto por 4 variáveis, a primeira o estado, a segunda a região, a terceira o número de homicídios femininos e a quarta o número de feminicidios. As três primeiras já foram incluidas acima e vamos criar somente a quarta. O comando typeof mostra qual o tipo de variável.\n\nfeminic_abs=c(11,  31,  8,  21,  107,  28,  19,  33,  56,  69,  47,  40,  171,  49,  26,  77,  72,  24,  111,  16,  110,  24,  3,  56,  195,  19,  14) \ntypeof(feminic_abs)\n\n[1] \"double\"\n\n\nPara criar o banco de dados utilizamos o seguinte comando:\n\ndata_feminic22&lt;-data.frame(estados, regiao, homic_abs, feminic_abs)  \n\nPodemos modificar o nome das variáveis com o comando names. Entretanto, tem que renomear todas\n\nnames(data_feminic22)&lt;-c(\"estado\", \"regioa\", \"homic_abs\", \"feminic_abs\") \ndata_feminic22\n\nOu podemos renomear somente algumas com o comando reshape:\n\nlibrary(reshape)\ndata_feminic22 &lt;- rename(data_feminic22, c(estado=\"estados\", regioa=\"regiao\"))\ndata_feminic22\n\n               estados regiao homic_abs feminic_abs\n1                 Acre      N        22          11\n2              Alagoas     NE        73          31\n3                Amapá      N        22           8\n4             Amazonas      N        88          21\n5                Bahia     NE       406         107\n6                Ceará     NE       264          28\n7    Distrito Federal      CO        32          19\n8       Espírito Santo     SD        95          33\n9                Goiás     CO       137          56\n10            Maranhão     NE       127          69\n11         Mato Grosso     CO       101          47\n12  Mato Grosso do Sul     CO        75          40\n13        Minas Gerais     SD       309         171\n14                Pará      N       200          49\n15             Paraíba     NE        86          26\n16              Paraná      S       256          77\n17          Pernambuco     NE       219          72\n18               Piauí     NE        70          24\n19      Rio de Janeiro     SD       283         111\n20 Rio Grande do Norte     NE        60          16\n21   Rio Grande do Sul      S       281         110\n22            Rondônia      N        88          24\n23             Roraima      N        33           3\n24      Santa Catarina      S       101          56\n25           São Paulo     SD       423         195\n26             Sergipe     NE        37          19\n27           Tocantins      N        36          14\n\n\nPodemos também listar variáveis do banco de dados, por exemplo, listar colunas de 1 a 2 ou listar por nome das variáveis, conforme apresentado abaixo:\n\ndata_feminic22\ndata_feminic22[,2:3]\ndata_feminic22[1:2,2:3]\ndata_feminic22[c(\"regiao\",\"feminic_abs\")]\n\nEntretanto, inserir dados na mão pode ser uma tarefa muito penosa e existem soluções bem mais simples e rápidas para inserção de dados. Nas seções seguintes veremos aprenderemos mais funções úteis para lidar com banco de dados.\n\n\n3.2.1.2 Trabalhando com as variáveis:\nVamos retomar duas variáveis homic_abs e estado e vamos manipular essas duas variáveis. Primeiramente vejamos o número de elementos, estrutura, classe e nome:\n\nlength(homic_abs) \n\n[1] 27\n\nstr(homic_abs)    \n\n num [1:27] 22 73 22 88 406 264 32 95 137 127 ...\n\nclass(homic_abs)  \n\n[1] \"numeric\"\n\nnames(homic_abs) \n\nNULL\n\n\nPodemos combinar as duas variáveis de forma distintas, por exemplo combinar na forma de um vetor, combinar como coluna ou combinar como linha, vejamos a diferença:\n\n#Precisa mudar essa parte de posição está confuso pois falamos de dataframe e aqui de vetor\ncomb1 &lt;- c(homic_abs,estados)      \ncomb2&lt;- cbind(homic_abs,estados)\ncomb3 &lt;-rbind(homic_abs,estados)\ncomb4 &lt;- data.frame(\n              homic_abs,\n              estados\n              ,stringsAsFactors = F)\ncomb1\ncomb2 \ncomb3\ncomb4\n\nVejamos quais objetos temos e vamos pedir para visualizar os objetos que acabamos de criar. Por fim removeremos o vetor comb1.\n\nls()  \ncomb1\ncomb2\ncomb3\nrm(comb1)              \n\n\n\n\n3.2.2 Importando os Dados\nDisponibilizamos dois banco de dados, um contendo os homicídios e feminicídios por estado e outro com as tentativas. Esses arquivos estão em formato csv (comma separated values).\nPara leitura desse arquivo em csv o seguinte comando é necessário read.csv, indicado que possui cabeçalho e que o separador é “;”\n\ndf_feminic22&lt;-read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/dados_feminic.csv\", head=TRUE,sep=\";\")\n\ndf_t_feminic22&lt;-read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/dados_tent_feminic.csv\", head=TRUE,sep=\";\")\n\nPara leitura de arquivos em Stata terá que utilizar o pacote foreign, conforme exemplo abaixo:\n\nlibrary(foreign)\nstata_feminic &lt;- read.dta(\"~/feminic.dta\")\n\nAlém desses, o R é capaz de trabalhar com SQL, SAS, SPSS, Excel entre outros.\n\n\n\n\n\n\nCuidado com o Ponto\n\n\n\nO R usa o formato americano de separação numérica. Usa ponto ao invés da vírgula para separar a unidade dos decimais. No Brasil usamos a vírgula. Isso sempre gera conflito. No seu csv evite usar acentos nas palavras e use ponto como separados dos decimais e não use separador dos milhares. Exemplo: 12500.97\n\n\n\n\n3.2.3 Exportanto os Dados\nPodemos exportar os dados em diferentes formatos. Alguns exemplos são csv, texto delimitado, excel, stata. Vejamos em csv:\n\nwrite.table(df_feminic22, \"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/export_feminic.csv\", sep=\";\")\n\nPara exportar em Stata utilize os seguintes comandos:\n\nlibrary(foreign)\nwrite.dta(df_feminic22, paste(getwd(),\"~/Banco de dados/export_feminic.dta\",sep=''))\n\n\n\n3.2.4 Lidando com Dados Missing\nNão temos informação para as tentativas de feminicidio para os estados de São Paulo e Mato Grosso. Uma maneira de lidar com valores missing seria fazer um subconjunto que veremos mais a frente. Agora seguiremos alguns passos para analisar os valores missing do nosso banco de dados.\nPrimeiramente, analisamos se há valores missing no banco de dados:\n\nis.na(df_t_feminic22)\n\nPodemos desconsiderar os valores missing da análise de interesse, vamos fazer a média do dolar sem considerar os valores missing:\n\nmean(df_t_feminic22$t_feminic_abs) \n\n[1] NA\n\nmean(df_t_feminic22$t_feminic_abs, na.rm=TRUE)\n\n[1] 102.52\n\n\nPodemos criar um novo banco de dados sem os valores missing.\n\ndf_t_feminic22_sem_missing &lt;- na.omit(df_t_feminic22)\nmean(df_t_feminic22_sem_missing$t_feminic_abs)\n\n[1] 102.52\n\nrm(df_t_feminic22_sem_missing)\n\nOutra maneira de excluir os valores missing seria a utilização do comando subset removendo as observações que contenham valor missing. Isso será explicado em seção a frente.\nPode-se também recodificar uma determinada variável para missing. Muito comum nas pesquisas do IBGE os valores missing serem identificados por um número, por exemplo 999999999999. Dessa forma podemos indicar que esse não é número e sim um valor missing da seguinte maneira:\n\ndf_t_feminic22$t_feminic_abs[df_t_feminic22$t_feminic_abs==999999] &lt;- NA\n\nTodos os valores que forem 99 serão exluídos e a celula ficará com um NA\n\n\n\n\n\n\nDados Missing\n\n\n\nDoois pontos importantes, dados missing não é 0 e nunca devem ser substituídos por 0. Pois 0 é um valor e missing é que não sabemos. Outro ponto é que devemos evitar excluir do banco os dados missing, melhor é fazer as contas retirando apensa do cálculo"
  },
  {
    "objectID": "manipulacao.html#operando-o-banco-de-dados",
    "href": "manipulacao.html#operando-o-banco-de-dados",
    "title": "3  Maipulando os Dados",
    "section": "3.3 Operando o Banco de Dados",
    "text": "3.3 Operando o Banco de Dados\n\n3.3.1 Criando uma Nova Variável\nVamos criar uma variável que seria a soma dos homicídios e feminicídios no estado. Para criar a variável precisamos dizer primeiro qual o banco de dados em que queremos criar e qual o nome da variável, conforme apresentado na expressão abaixo.\n\nlibrary(reshape)\ndf_feminic22 &lt;- rename(df_feminic22, c(feminico_abs=\"feminic_abs\"))\n\n\ndf_t_feminic22$t_total_abs&lt;- df_t_feminic22$t_feminic_abs + df_t_feminic22$t_homic_abs\n\ndf_feminic22$total_abs&lt;- df_feminic22$feminic_abs + df_feminic22$homic_abs\n\nAgora vamos criar uma variável binária que representa como 1 os estados que possuem a taxa de feminicídio em relação ao total de homicídios maior que 50%. Novamente, precisamos indicar o banco de dados e o nome da variável no banco de dados.\n\ndf_feminic22$mais_50[df_feminic22$part_feminic &lt; 50] &lt;- 0\ndf_feminic22$mais_50[df_feminic22$part_feminic &gt;= 50] &lt;- 1\n\ndf_feminic22$mais_50\n\n [1] 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n\n\n\n\n3.3.2 Operadores Aritméticos e Lógicos\nUtilizando os vetores criados anteriormente:\n\nfeminic_abs&gt;50\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE\n[13]  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE\n[25]  TRUE FALSE FALSE\n\nfeminic_abs[feminic_abs&gt;50]\n\n [1] 107  56  69 171  77  72 111 110  56 195\n\nfeminic_abs[feminic_abs &lt; 50 | feminic_abs &gt; 100]\n\n [1]  11  31   8  21 107  28  19  33  47  40 171  49  26  24 111  16 110  24   3\n[20] 195  19  14\n\nfeminic_abs[feminic_abs &gt; 50 & feminic_abs &lt; 100]\n\n[1] 56 69 77 72 56\n\nmean(feminic_abs)\n\n[1] 53.22222\n\nfeminic_M &lt;- (feminic_abs[feminic_abs&lt; 100 & feminic_abs &gt; 50])\nfeminic_M\n\n[1] 56 69 77 72 56\n\n\nA tabela abaixo contém alguns operadaroes lógicos frequentemente utilizados.\n\nOperadores Lógicos no R\n\n\nOperador\nSignificado\n\n\n\n\n&lt;\nMenor que\n\n\n&lt;=\nMenor igual\n\n\n&gt;\nMaior que\n\n\n&gt;=\nMaior igual\n\n\n==\nExatamente igual\n\n\n!=\nDiferente\n\n\n!x\nNão x\n\n\nx | y\nx OU y\n\n\nx & y\nx E y"
  },
  {
    "objectID": "manipulacao.html#algumas-funções-importantes",
    "href": "manipulacao.html#algumas-funções-importantes",
    "title": "3  Maipulando os Dados",
    "section": "3.4 Algumas Funções Importantes",
    "text": "3.4 Algumas Funções Importantes\n\n3.4.1 Ordenando os Dados\nVamos ordenar os estados dos nossos 2 data frames pela participação do feminicídio no total de homicídios de mulheres.\n\ndf_feminic22_ord&lt;-df_feminic22[order(df_feminic22$part_feminic, decreasing = TRUE),] \n\ndf_t_feminic22_ord&lt;-df_t_feminic22[order(df_t_feminic22$part_t_feminic, decreasing = TRUE),] \n\n\n\n3.4.2 Fazendo Merge\nTemos dois data frames um contendo homicídios e feminicídios e outro contendo as tentativas. Vamos agora juntar os dois. Para isso os bancos devem conter uma chave única que identifica cada linha e essa deve estar presente nos dois bancos. Inclusive devem ter o mesmo nome.No caso em questão podemos usar o estado como nossa chave que irá conectar os dois bancos.\n\ndf_final_feminic_22 &lt;- merge(df_feminic22,df_t_feminic22,by=\"sigla\",keep.all=TRUE)\n\nAgora temos um banco único com homicídios e tentativas de homicídios.\n\n\n3.4.3 Agregando\nVamos criar um banco de dados que contenha os valores médios das variáveis. Para isso vamos agregar fazendo a média por região. Poderíamos utilizar outra função, como a soma, para fazer a agregação:\n\nregiao_media &lt;-aggregate(df_final_feminic_22, by=list(df_final_feminic_22$regiao.x), FUN=mean, na.rm=TRUE)\nregiao_media\n\n  Group.1 sigla estado.x regiao.x homic_abs homic_tx feminic_abs feminic_tx\n1      CO    NA       NA       NA  86.25000 4.250000    40.50000   2.100000\n2       N    NA       NA       NA  69.85714 6.785714    18.57143   1.871429\n3      NE    NA       NA       NA 149.11111 4.355556    43.55556   1.422222\n4       S    NA       NA       NA 212.66667 4.000000    81.00000   1.600000\n5      SD    NA       NA       NA 277.50000 3.300000   127.50000   1.375000\n  part_feminic  rendapc total_abs   mais_50 estado.y regiao.y t_homic_abs\n1     50.02500 2011.250 126.75000 0.5000000       NA       NA    258.2500\n2     30.01429 1175.286  88.42857 0.1428571       NA       NA    161.7143\n3     34.36667 1053.222 192.66667 0.2222222       NA       NA    257.7778\n4     41.53333 1983.667 293.66667 0.3333333       NA       NA    450.6667\n5     43.82500 1842.750 405.00000 0.2500000       NA       NA    455.7500\n  t_homic_tx t_feminic_abs t_feminic_tx part_t_feminic t_total_abs\n1  13.375000     126.33333     6.500000       32.67667    387.6667\n2  24.657143      50.28571     5.285714       26.44286    212.0000\n3   9.311111      85.11111     3.044444       25.72444    342.8889\n4   8.966667     169.66667     3.500000       25.98667    620.3333\n5   8.875000     185.66667     3.000000       26.50000    660.3333\n\n\n\n\n3.4.4 Criando Subconjunto\nSelecionando Variáveis:\nPodemos estar interessado em manter somente algumas variáveis no nosso banco de dados, por exemplo, queremos manter estado e a participação do feminicídio no total. Assim:\n\nvar_sel &lt;- c(\"sigla\", \"part_feminic\", \"part_t_feminic\")\nfeminic_sel &lt;- df_final_feminic_22[var_sel]\n\nfeminic_sel1 &lt;- df_final_feminic_22[c(\"sigla\", \"part_feminic\", \"part_t_feminic\")]\n\nOu podemos fazer indicar as colunas que queremos selecionar. Na segunda opção selecionamos até o final do nosso banco\n\nfeminic_sel2 &lt;- df_final_feminic_22[c(1:3,5:6,12:15)]\nfeminic_sel3 &lt;- df_final_feminic_22[c(1:3,10:ncol(df_final_feminic_22))]\n\n:\nAo fazer o merge as variáveis que tinham o mesmo nome nos dois bancos, como estado, foram mantidas e agora possuem os nomes estado.x e estado.y, vamos manter apenas uma e trocar o seu nome. O comando namesajuda a saber a posição da variável no banco\n\nnames(df_final_feminic_22)\n\n [1] \"sigla\"          \"estado.x\"       \"regiao.x\"       \"homic_abs\"     \n [5] \"homic_tx\"       \"feminic_abs\"    \"feminic_tx\"     \"part_feminic\"  \n [9] \"rendapc\"        \"total_abs\"      \"mais_50\"        \"estado.y\"      \n[13] \"regiao.y\"       \"t_homic_abs\"    \"t_homic_tx\"     \"t_feminic_abs\" \n[17] \"t_feminic_tx\"   \"part_t_feminic\" \"t_total_abs\"   \n\nfinal_fem_22 &lt;- df_final_feminic_22[c(-12)]\n\nlibrary(reshape)\nfinal_fem_22 &lt;- rename(final_fem_22, c(estado.x=\"estados\"))\n\n\n\n\n\n\n\nCuidado ao tirar colunas\n\n\n\nSe fizermos o comando de tirar colunas no mesmo data frame, ao rodar novamente ele continuará sempre tirando a coluna indicada. O ideal seria construir outro data frame como fizemos acima.\n\n\nOu podemos especificar a o nome da coluna que será retirada. Vamos agora tirar a região que ficou duplicada\n\nfinal_fem_22$regiao.y &lt;-  NULL\n\nlibrary(reshape)\nfinal_fem_22 &lt;- rename(final_fem_22, c(regiao.x=\"regiao\"))\n\nsave(final_fem_22, file = \"dados.RData\")\nwrite.table(final_fem_22, \"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/final_fem_22.csv\", sep=\";\")\n\nSelecionando Variáveis:\nVamos selecionar as observações dos estados da região Norte e Nordeste:\n\nfem_n_nd &lt;- final_fem_22[ which(final_fem_22$regiao==\"NE\" | final_fem_22$regiao==\"N\"),]\n\nfem_n_nd1 &lt;- final_fem_22[ which((final_fem_22$regiao==\"NE\" | final_fem_22$regiao==\"N\") & final_fem_22$part_feminic&gt;=50),]\n\nOu podemos selecionar as observações em que a participação do feminicídio está entre 30 e 50%:\n\nfem_n_nd2 &lt;- subset(final_fem_22, final_fem_22$part_feminic &gt;= 30 & final_fem_22$part_feminic &lt;= 50 )"
  },
  {
    "objectID": "descritiva.html#porque-estudar-estatística",
    "href": "descritiva.html#porque-estudar-estatística",
    "title": "6  Análise Descritiva",
    "section": "6.1 Porque Estudar Estatística?",
    "text": "6.1 Porque Estudar Estatística?\nPodemos dizer que a existência da estatística e de outras ciências está conectada a existência de problemas. Não somente a ciência mas o nosso trabalho está conectado a superação de problemas cotidianos. Tomar decisão é o dia a dia do gestor.\nSegundo Popper “we study not disciplines, but problems. Often, problems transcend the boundaries of a particular discipline”\nA questão central é: Como solucionamos os problemas? Utilizamos a melhor estratégia? A solução foi boa?\n\n\n\n\nflowchart LR\n  A[PROBLEMA] --&gt; B[Estratégia de Decisão]\n  B --&gt; C{Solução é BOA?}\n\n\n\n\n\n\n6.1.1 Os dois sistemas cognitivos\nOs livros abaixo são boas referências sobre a tomada de decisão.\n\n\n\n\n\n\nRápido e Devagar: Duas Formas de Pensar\n\n\n\n\n \n\n\n\n\n\nProcesso Decisório\n\n\n\n\n\nExistem dois sistemas que utilizamos para tomar decisão. O chamado Sistema 1 e o chamado Sistema 2. Segue uma breve descrição de cada um:\nSistema 1:\n\nIntuitivo, rápido, automático, sem esforço, implícito e emocional\n\nPressa,\nFalta de tempo,\nProblemas menos importante\nMais Falhas/Erros\n\n\nSistema 2\n\nRaciocíonio lento, consciente, esforçado, explícito, lógico\n\nRequer tempo,\nMais recursos\nProblemas mais importante\nMenos Falhas\n\n\nPara o Sistema 1 usamos a nossa intuição que chamamos de Heurística. Vejamos um pouco mais sobre esse sistema.\nHEURÍSTICA\nSão rotinas inconscientes ou atalhos que o nosso cérebro utiliza para lidar com a complexidade.\n\nModelo/Regras Intuitivas.\nPróprio do Sistema 1.\nApesar de processo sofisticado, são passíveis de falhas. Intuição falha\n\nUm Exemplo\nVeja a figura abaixo retirada do livro do Bazerman.Responda rápido.\nQual delas tem o tampo mais quadrado?\n\n\n\nBazerman: Exemplo das mesas\n\n\nSe você achou que é a segunda mesa, você está alinhado com a grande maioria. Nesse caso você usou o seu sistema 1\nVamos repitir a pergunta:\nQual delas tem o tampo mais quadrado?\nAgora use uma régua para medir as mesas. Usamos aqui o sistema 2. Mais tempo e recursos são utlizados. Qual mesa agora você considera mais quadrada? Mudou sua opinião?\nCom a régua vemos que as mesas são iguais. Isso mostra que a nossa intuição FALHA.\nTipos de Heurísticas\n\nHeurística da disponibilidade: Usamos o que está mais próximo na memória para calcular a probabilidade.\nHeurística da representatividade: Buscamos aquilo que reforça o padrão.\nHeurística da hipótese positiva: Assumimos que uma determinada hipótese é verdadeira e não olhamos o contrafactual.\nHeurística do afeto: Decisão considera o emocional. Seu humor afetam as decisões.\n\nPara contornar os problemas da intuição e seus viéses na tomada de decisão o primeiro passo é compreender que eles existem e estarmos alerta. E para problemas maiores o uso do sistema 2 torna-se relevante.\nUma das principais ferramentas do sistema 2 é a Estatística. Com os avanços computacionais essa ciência tem se destacado como um dos elementos centrais do data science. Abaixo a figura resume as diversas áreas de desenvolvimento da análise de dados, obviamente não exaustiva:\n\n\n\nBazerman: mesas\n\n\nNosso objetivo é explorar nessa seção a análise descritiva. Chamado hoje no Business Intelligence, que e uma das áreas do Data Science."
  },
  {
    "objectID": "descritiva.html#conceitos-básicos-de-estatística",
    "href": "descritiva.html#conceitos-básicos-de-estatística",
    "title": "6  Análise Descritiva",
    "section": "6.2 Conceitos Básicos de Estatística",
    "text": "6.2 Conceitos Básicos de Estatística\nNovamente começamos com um problema e esse definirá a nossa análise. Vejamos alguns problemas que poderiam nos interessar…\n\n\n\n\n\n\nProblema 1\n\n\n\nO prefeito de Ribeirão Preto vai lançar uma política que fornece vouchers de alimentação para mulheres que estão em situação de pobreza.\nProblema: Qual o valor que devo reservar ao programa? Quantas mulheres serão atendidas?\n\n\n\n\n\n\n\n\nProblema 2\n\n\n\nO TJSP vai lançar um programa para reduzir o tempo médio em processos de feminicídio.\nProblema: Qual o tempo médio de um processo de feminicídio?\n\n\n\n\n\n\n\n\nProblema 3\n\n\n\nO O governo federal vai lançar um programa para capacitar mulheres que estão fora do mercado de trabalho.\nProblema: Quantas mulheres serão alvos dessa política?\n\n\n\n6.2.1 A Variável Aleatória\nO problema nos define a população que estou interessado. Vamos seguir, a princípio, com o nosso probelma 1 para definirmos alguns conceitos importantes.\nNo problema 1: me interessa compreender a renda das mulheres que moram em Ribeirão Preto em dado ano. Para ficar simples vamos abreviar o que nos interessa\n\\[X=\\text{Renda das mulheres que moram em Ribeirão Preto em determinado ano}\\] Agora posso utilizar o X no lugar do nome. Olhando para a população e pensando que cada nível de renda pode ser representada por uma cor, teremos a seguinte imagem pouco de como a renda se distribui nessa população:\n\n\n\nRenda pc das mulheres de Ribeirão Preto.\n\n\nA questão é: quais cores existem e quantas peças de cada cor temos? Para isso usamos um experimento\nEXPERIMENTO ALEATÓRIO\nO experimento em ciências sociais aplicadas em geral está associada a observação sistemática de pessoas, cidades, empresas ou processos. A ideia é:\n\nSortear pessoas e observar a sua caracteristica de forma indefinida e sempre na mesma condição.\n\nNão consigo dizer o que vai sair no próximo sorteio, apenas consigo descrever os resultados possíveis\nSe repetir o experimento um número grande de vezes uma regularidade aparece.\n\nSe eu conseguir sortear de forma indefinida e na mesma condição as mulheres que moram em Ribeirão Preto e perguntar sobre a sua renda. Eu consigo reorganizar a figura acima da seguinte forma:\n\n\n\nRenda pc das mulheres de Ribeirão Preto.\n\n\nESPAÇO AMOSTRAL\nAgora conseguimos organizar os nossos resultados em um lugar chamado espaço amostral. Nele teremos todas as cores (azul, branca, amarela…) que podem acontecer e o número de peças de cada cor (a chance). Em outras palavras teremos todos os possíveis valores de \\(X\\) e suas probabilidades.\nVARIÁVEL ALEATÓRIA\nQuanto representamos esse espaço amostral em formato de números é o que chamamos de Variável Aleatória (V.A.). A V.A. é a combinação de tudo que pode acontecer, ou seja, todas as rendas que existem associadas a probabilidade de cada uma das rendas acontecerem.\nExistem dois tipos principais de variáveis aleatórias: discretas e contínuas.\nVARIÁVEIS ALEATÓRIAS DISCRETAS\nÉ um tipo de variável que conseguimos colocar em lista, seja finita ou infinita \\(x_1; x_2;...; x_n;...\\) e associa-se a cada um dessses valores uma probabilidade \\(p(x_1); p(x_2);...; p(x_n);...\\)\nPodemos pensar aqui se a pessoa é casada, solteira, divorciada, viúva ou outra condição. Se no processo classificamos como homicídio ou feminicídio, se mora na área urbana ou rural…\nNa figura abaixo iremos coletar de 20 processos de homicídio e gostariamos de saber quando é classificado como feminicídio e quanto é classificado como homicídio (p=0,3).\n\nfeminicidio &lt;- 0:20\n\nplot(feminicidio,dbinom(feminicidio,size=20,prob=.3),\n     type='h',\n     main='Distribuição Binomial (n=20, p=0.3)',\n     ylab='Probabilidade',\n     xlab ='Feminicídio',\n     lwd=3)\n\n\n\n\nDistribuição Normal\n\n\n\n\nVARIÁVEIS ALEATÓRIAS CONTÍNUAS\nPor outro lado, uma variável aleatória contínua pode assumir infinito valores dentro de um intervalo específico. Agora temos infinitas possibilidades de resultados para \\(X\\) e agora associamos uma função \\(f(x)\\) que irá descrever o comportamento da probabilidade.\nPor exemplo, a altura de uma pessoa, a sua renda, a sua idade, o tempo que demora um processo.\nAbaixo temos uma representação de uma distriuição continua da renda das mulheres em Ribeirão Preto, chamada distribuição normal:\n\nrm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.\nx&lt;-seq(700,1300,1)\nfdnorm&lt;-dnorm(x = x, mean = 1000, sd=100)  \nfdanorm&lt;-pnorm(q = x, mean = 1000, sd=100)\ncurve(dnorm(x,1000,100),xlim=c(700,1300),main='',xaxt=\"n\",xlab=\"Renda pc Mulheres\", ylab=\"f(x)\",col=\"darkblue\",cex.axis=0.65, cex.lab=0.8) \naxis(1,at=c(900, 1000, 1100),labels =\n       c(\"-DP(X)\",\"E(x)\",\"DP(x)\"),cex.axis=0.65, cex.lab=0.8) \nlines(x=c(1000,1000),y=c(0,fdnorm[x==1000]),lty=2, col=\"black\") \nlines(x=c(1100,1100),y=c(0,fdnorm[x==1100]),lty=2, col=\"black\")\nlines(x=c(900,900),y=c(0,fdnorm[x==900]),lty=2, col=\"black\")\n\n\n\n\nDistribuição Normal\n\n\n\n\n\n6.2.1.1 Esperança e Variância\nO fomato das distribuições vistas dependem principalmente de dois parâmetros: A esperança que é uma medida de centralidade e a variância que é uma medida de dispersão.\nESPERANÇA - \\(E(X)\\)\nÉ uma medida de centralidade da variável aleatória. É definida como a média ponderada de todos os possíveis resultados de \\(X\\), onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança de \\(X\\), \\(E(X)\\), é calculada como:\n\\[E(X) = \\sum_{x} x \\cdot P(X = x)\\]\npara variáveis discretas.\n\\[E(X) = \\int_{-\\infty}^{\\infty} x \\cdot f(x)\\],\npara variáveis contínuas\nVARIÂNCIA POPULACIONAL - \\(Var(X)\\)\nA variância é uma medida que captura como os dados populacionais se dispersão em relação a sua média (ou esperança).\n\\[Var(X) =\\frac{1}{N} \\sum_{1}^{N} (X_i-E(X))^2\\] Ou podemos assim representar: \\[\\text{Var}(X) = E(X^2) - [E(X)]^2\\].\nDESVIO PADRÃO POPULACIONAL - \\(DP(X)\\)\nA variãncia é uma medida ao quadrado. Se estamos falando da renda seria uma medida da dispersão ao quadrado, ou seja, em \\(R\\$^{2}\\). Para retornar a unidade original usamos o desvio padrão que é:\n\\[DP(X)=\\sqrt{Var(X)}\\]\nVejamos o que acontece quando mudamos a esperança e o desvio padrão. No gráfico em azul temos a esperança igual a 10 e devio padrão de 2,5. No gráfico em vermelho temos esperança de 20 e desvio padrão de 10. E no grafico em verde temos esperança de 10 e desvio padrão de 1. Nota-se que quanto menor o desvio padrão mais concentrados são os valores que podem acontecer.\n\ncurve(dnorm(x,mean=10,sd=sqrt(2.5)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs=\"i\",yaxs=\"i\",ylab=\"\", col=\"darkblue\") \npar(new=T)\ncurve(dnorm(x,mean=20,sd=sqrt(10)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs=\"i\",yaxs=\"i\",ylab=\"\", col=\"darkred\") \npar(new=T)\ncurve(dnorm(x,mean=20,sd=sqrt(1)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs=\"i\",yaxs=\"i\",ylab=\"\", col=\"darkgreen\") \n\n\n\n\nMédias e desvios distintos entre distribuições\n\n\n\n\n\n\n\n6.2.2 Variáveis Aleatórias Bidimensionais\nMuito provavelmente nos interessa observar mais de uma característica de um experimento. Por exemplo, não somente a renda das mulheres em Ribeirão Preto nos interessa, mas o seu consumo alimentar também julgamos importante para o projeto.\nPortanto, queremos observar duas características de forma simultânea das mulheres: sua renda e seu consumo alimentar. Ou seja, duas características simultaneamente do mesmo experimento \\(\\epsilon\\) que foi observar as mulheres no município.\nApesar de termos coletados duas informações, temos na realidade três informações. A informação da renda, a informação do consumo alimentar e a informação de como renda e consumo alimentar interagem.\nVISUALIZAÇÃO GRÁFICA\nVejamos agora um exemplo de variável aleaória bidimensional:\nNormal Bivariada:\nAbaixo tem-se uma variável aleatória \\((X,Y)\\) com distribuição normal bivariada com a esperança de \\(X\\) igual a 1, de \\(Y\\) igual a 0, o desvio-padrões iguais a 3 e 2 respectivamente. Aqui consideremaos a correlação de 1 (veremos mais a frente esse conceito)\n\nlibrary(mnormt)\n\n#Para tornar reproduzível\nset.seed(0)\n\n#cCriando a normal bivariada\nx     &lt;- seq(-3, 3, 0.1) \ny     &lt;- seq(-3, 3, 0.1)\nmu    &lt;- c(1, 0)\nsigma &lt;- matrix(c(3, 1, 1, 2), nrow=2)\nf     &lt;- function(x, y) dmnorm(cbind(x, y), mu, sigma)\nz     &lt;- outer(x, y, f)\n\n#Criando um gráfico de superfície\npersp(x, y, z, theta=-30, phi=25, expand=0.6, ticktype='detailed')\n\n\n\n\nNormal Bivariada\n\n\n\n\nSurge aqui um conceito importante que tenta medir como as características da população se relacionam - uma medida do relacionamento. Assim:\nO que acontece com o consumo de alimentos quando a renda das mulheres sobem?\n\n6.2.2.1 Covariância e Correlação\nDuas medidas que tentam mensurar o “grau de associação” linear entre X e Y são:\nCOVARIÂNCIA\n\\[Cov(X,Y)=E[(X-E(X))(Y-E(Y))]= E(X.Y)-E(X).E(Y)\\]\nEla mede a variabilidade conjunta de uma variável aleátoria multidimensional. Como no caso da variância, ela sofre do efeito das escalas de medidas. Para corrigir dividimos pelos desvios padrões. Surge dessa maneira a medida de correlação.\nCORRELAÇÃO\n\\[\\rho_{X,Y}=\\frac{E[(X-E(X))(Y-E(Y))]}{\\sqrt{Var(X)Var(Y)}}=\\frac{Cov(X,Y)}{DP(X).DP(Y)}\\]\n\n\n\n\n\n\nCorrelação\n\n\n\nA correlação mede o GRAU DE ASSOCIAÇÃO LINEAR. Associações não lineares não são capturadas pela correlação.\n\n\n\n\n\n\n\n\nLendo a Correlação\n\n\n\nA correlação \\(\\rho_{X,Y}\\) varia de -1 até 1. Sendo que:\n\\(\\rho\\) próximo a 1 e -1 indicam alto grau de linearidade e \\(\\rho\\) próximo a 0 indica ausência de relação linear - mas não diz nada sobre relações não-lineares.\n\n\nVISUALIZAÇÃO GRÁFICA\nVeja no gráfico abaixo que a variável 4 e 5 possuem correlação perfeita, igual a -1. E as variáveis 3 e 1 não possuem grau de associação linear, correlação próxima a 0.\n\n\n\n\n\nGráfico de correlação para variáveis simuladas v1 a v5"
  },
  {
    "objectID": "descritiva.html#problema-1",
    "href": "descritiva.html#problema-1",
    "title": "6  Análise Descritiva",
    "section": "6.3 Problema 1",
    "text": "6.3 Problema 1"
  },
  {
    "objectID": "descritiva.html#problema-3",
    "href": "descritiva.html#problema-3",
    "title": "6  Análise Descritiva",
    "section": "6.3 Problema 3",
    "text": "6.3 Problema 3\nO O governo federal vai lançar um programa para capacitar mulheres que estão fora do mercado de trabalho.\nProblema Quantas mulheres serão alvos dessa política? :::\n\n6.3.1 A Variável Aleatória\nUm experimento aleatório é um processo ou evento cujo resultado não pode ser previsto com certeza, mesmo que as condições iniciais sejam conhecidas. Ele geralmente envolve uma série de possíveis resultados, onde cada resultado tem uma probabilidade associada de ocorrer. Por exemplo, jogar um dado é um experimento aleatório, pois o resultado (o número que aparece no dado) não pode ser determinado com certeza antes do lançamento, embora saibamos que o resultado possível será um dos números de 1 a 6.\nCom base nesse conceito, podemos introduzir variáveis aleatórias, que são utilizadas para descrever e quantificar os resultados possíveis de um experimento aleatório de uma forma mais abstrata e matemática. Existem dois tipos principais de variáveis aleatórias: discretas e contínuas.\nUma variável aleatória discreta é aquela que pode assumir apenas um conjunto específico de valores isolados, geralmente inteiros, com probabilidades associadas a cada valor possível. Por exemplo, o número de caras em cinco lançamentos de uma moeda é uma variável aleatória discreta, pois só pode assumir valores inteiros (0, 1, 2, 3, 4, ou 5) com probabilidades específicas para cada valor.\nPor outro lado, uma variável aleatória contínua pode assumir um intervalo infinito de valores dentro de um intervalo específico. Por exemplo, a altura de uma pessoa é uma variável aleatória contínua, pois pode assumir qualquer valor real dentro de um intervalo específico (por exemplo, entre 1,50 metros e 2,00 metros). Nesse caso, a probabilidade é representada pela área sob a curva da função de densidade de probabilidade ao longo do intervalo de valores possíveis.\nEm resumo, as variáveis aleatórias discretas e contínuas são ferramentas importantes na teoria da probabilidade e estatística para modelar e analisar resultados de experimentos aleatórios. Elas nos permitem quantificar e entender a incerteza associada aos resultados desses experimentos de uma forma matematicamente rigorosa.\nO conceito de esperança matemática \\((E)\\) em probabilidade e estatística representa uma medida de valor médio esperado de uma variável aleatória. Matematicamente, a esperança de uma variável aleatória \\(X\\) é definida como o valor ponderado de todos os possíveis resultados de \\(X\\), onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança matemática de \\(X\\), denotada por \\(E(X)\\). \\(E(X)\\), é calculada como:\nO conceito de esperança matemática (E) em probabilidade e estatística representa uma medida de valor médio esperado de uma variável aleatória. Matematicamente, a esperança de uma variável aleatória X é definida como o valor ponderado de todos os possíveis resultados de X, onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança matemática de X, denotada por X, é calculada como:\n\\[E(X) = \\sum_{x} x \\cdot P(X = x)\\]\npara variáveis discretas.\n\\[E(X) = \\int_{-\\infty}^{\\infty} x \\cdot f(x) \\],\npara variáveis contínuas\nonde \\(x\\) representa os possíveis valores que \\(X\\) pode assumir, \\(P(X = x)\\) é a probabilidade de \\(X\\) ser igual a \\(x\\) (para variáveis discretas), e \\(f(x)\\) é a função de densidade de probabilidade de \\(X\\) (para variáveis contínuas).\nA média \\(mu\\), a variância \\(\\sigma^2\\), e a covariância entre duas variáveis \\(X\\) e \\(Y\\), \\(Cov(X, Y)\\) podem ser expressas em termos de esperança matemática:\nA média de uma variável \\(X\\) é simplesmente a esperança de \\(X\\), ou seja, \\(\\mu = E(X)\\).\nA variância de \\(X\\), denotada por \\(\\sigma^2\\), é calculada como \\[\\text{Var}(X) = E(X^2) - [E(X)]^2\\].\nA covariância entre duas variáveis \\(X\\) e \\(Y\\) é dada por \\[\\text{Cov}(X, Y) = E(XY) - E(X)E(Y)\\], onde \\(\\mu_X\\) e \\(\\mu_Y\\) são as médias de \\(X\\) e \\(Y\\), respectivamente."
  },
  {
    "objectID": "descritiva.html#esperança-e-variância",
    "href": "descritiva.html#esperança-e-variância",
    "title": "6  Análise Descritiva",
    "section": "6.3 Esperança e Variância",
    "text": "6.3 Esperança e Variância\nO conceito de esperança matemática \\((E)\\) em probabilidade e estatística representa uma medida de valor médio esperado de uma variável aleatória. Matematicamente, a esperança de uma variável aleatória \\(X\\) é definida como o valor ponderado de todos os possíveis resultados de \\(X\\), onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança matemática de \\(X\\), denotada por \\(E(X)\\). \\(E(X)\\), é calculada como:\nO conceito de esperança matemática (E) em probabilidade e estatística representa uma medida de valor médio esperado de uma variável aleatória. Matematicamente, a esperança de uma variável aleatória X é definida como o valor ponderado de todos os possíveis resultados de X, onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança matemática de X, denotada por X, é calculada como:\n\\[E(X) = \\sum_{x} x \\cdot P(X = x)\\]\npara variáveis discretas.\n\\[E(X) = \\int_{-\\infty}^{\\infty} x \\cdot f(x)\\],\npara variáveis contínuas\nonde \\(x\\) representa os possíveis valores que \\(X\\) pode assumir, \\(P(X = x)\\) é a probabilidade de \\(X\\) ser igual a \\(x\\) (para variáveis discretas), e \\(f(x)\\) é a função de densidade de probabilidade de \\(X\\) (para variáveis contínuas).\nA média \\(mu\\), a variância \\(\\sigma^2\\), e a covariância entre duas variáveis \\(X\\) e \\(Y\\), \\(Cov(X, Y)\\) podem ser expressas em termos de esperança matemática:\nA média de uma variável \\(X\\) é simplesmente a esperança de \\(X\\), ou seja, \\(\\mu = E(X)\\).\nA variância de \\(X\\), denotada por \\(\\sigma^2\\), é calculada como \\[\\text{Var}(X) = E(X^2) - [E(X)]^2\\].\nA covariância entre duas variáveis \\(X\\) e \\(Y\\) é dada por \\[\\text{Cov}(X, Y) = E(XY) - E(X)E(Y)\\], onde \\(\\mu_X\\) e \\(\\mu_Y\\) são as médias de \\(X\\) e \\(Y\\), respectivamente."
  },
  {
    "objectID": "descritiva.html#correlação",
    "href": "descritiva.html#correlação",
    "title": "6  Análise Descritiva",
    "section": "6.3 Correlação",
    "text": "6.3 Correlação\nA correlação mede o GRAU DE ASSOCIAÇÃO LINEAR. Associações não lineares não são capturadas pela correlação."
  },
  {
    "objectID": "descritiva.html#estatisticas-descritivas-medidas-numéricas-a-partir-da-amostra",
    "href": "descritiva.html#estatisticas-descritivas-medidas-numéricas-a-partir-da-amostra",
    "title": "6  Análise Descritiva",
    "section": "6.6 Estatisticas Descritivas: Medidas Numéricas a partir da amostra",
    "text": "6.6 Estatisticas Descritivas: Medidas Numéricas a partir da amostra\nExistem outros métodos númericos que se constituem como alternativas adcionais para sintetizar os dados. Podemos dividir as medidas numericas em duas, temos as medidas de posíção e as de variabilidade.\nMEDIDAS DE POSIÇÃO:\n\nMédia,\nMediana,\nModa,\nPercentis,\nQuartis.\n\nMEDIDAS DE VARIABILIDADE:\n\nAmplitude,\nAmplitude interquartil,\nVariância,\nDesvio Padrão e\nCoeficiente de Variação.\n\nMEDIDAS DE ASSOCIAÇÃO:\n\nCovariancia e\nCoeficiente de Correlção.\n\nVamos apresentar as fórmulas de algumas dessas principais medidas.\n\nfinal_fem_22 &lt;- read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/final_fem_22.csv\", head=T ,sep=\";\")\n\n\n6.6.1 Medidas de Posição:\nMÉDIA AMOSTRAL:\n\\[\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]\n\nmean(final_fem_22$feminic_tx)\n\n[1] 1.651852\n\n\n\nlibrary(kableExtra)\n\nmean_1&lt;- aggregate(final_fem_22[4:17], list(final_fem_22$regiao), mean,  na.rm=T)\n\nt(mean_1) %&gt;% \n  kbl(digits = 2) %&gt;%\n     kable_styling()\n\n\n\n\nGroup.1\nCO\nN\nNE\nS\nSD\n\n\nhomic_abs\n86.25000\n69.85714\n149.11111\n212.66667\n277.50000\n\n\nhomic_tx\n4.250000\n6.785714\n4.355556\n4.000000\n3.300000\n\n\nfeminic_abs\n40.50000\n18.57143\n43.55556\n81.00000\n127.50000\n\n\nfeminic_tx\n2.100000\n1.871429\n1.422222\n1.600000\n1.375000\n\n\npart_feminic\n50.02500\n30.01429\n34.36667\n41.53333\n43.82500\n\n\nrendapc\n2011.250\n1175.286\n1053.222\n1983.667\n1842.750\n\n\ntotal_abs\n126.75000\n88.42857\n192.66667\n293.66667\n405.00000\n\n\nmais_50\n0.5000000\n0.1428571\n0.2222222\n0.3333333\n0.2500000\n\n\nt_homic_abs\n258.2500\n161.7143\n257.7778\n450.6667\n455.7500\n\n\nt_homic_tx\n13.375000\n24.657143\n9.311111\n8.966667\n8.875000\n\n\nt_feminic_abs\n126.33333\n50.28571\n85.11111\n169.66667\n185.66667\n\n\nt_feminic_tx\n6.500000\n5.285714\n3.044444\n3.500000\n3.000000\n\n\npart_t_feminic\n32.67667\n26.44286\n25.72444\n25.98667\n26.50000\n\n\nt_total_abs\n387.6667\n212.0000\n342.8889\n620.3333\n660.3333\n\n\n\n\n\n\n\nMEDIANA:\nOrganize os dados em ordem crescente.\n\nPara um numero impar de observações a mediana é o valor que ocupa a posição central.\npara um número par de observações, a mediana é a média dos dois valores centrais.\n\n\nmedian(final_fem_22$feminic_tx)\n\n[1] 1.5\n\n\n\nfun1 &lt;- function(x, na.rm = TRUE) c(media=mean(x, na.rm = TRUE), mediana=median(x, na.rm = TRUE))\n\nmedian_1 &lt;- (sapply(final_fem_22[4:17], fun1))\n\nt(median_1) %&gt;% \n  kbl(digits = 2) %&gt;%\n     kable_styling()\n\n\n\n\n\nmedia\nmediana\n\n\n\n\nhomic_abs\n145.33\n95.00\n\n\nhomic_tx\n4.77\n4.50\n\n\nfeminic_abs\n53.22\n33.00\n\n\nfeminic_tx\n1.65\n1.50\n\n\npart_feminic\n37.76\n38.90\n\n\nrendapc\n1447.15\n1267.00\n\n\ntotal_abs\n198.56\n128.00\n\n\nmais_50\n0.26\n0.00\n\n\nt_homic_abs\n283.70\n264.00\n\n\nt_homic_tx\n13.79\n10.00\n\n\nt_feminic_abs\n102.52\n88.00\n\n\nt_feminic_tx\n4.14\n3.60\n\n\npart_t_feminic\n26.88\n29.73\n\n\nt_total_abs\n383.00\n377.00\n\n\n\n\n\n\n\nMODA:\nModa é o valor que ocorre com mais frequência.\n\nmoda &lt;- function(x, na.rm=T) {\nmodal &lt;- unique(x, na.rm=T)\nmodal[which.max(tabulate(match(x, modal)))]\n}\nmoda(final_fem_22$feminic_tx)\n\n[1] 1.3\n\n\n\nfun1 &lt;- function(x, na.rm = TRUE) c(media=mean(x, na.rm = TRUE), mediana=median(x, na.rm = TRUE), moda=moda(x))\n\nmedian_1 &lt;- (sapply(final_fem_22[4:17], fun1))\n\nt(median_1) %&gt;% \n  kbl(digits = 2) %&gt;%\n     kable_styling()\n\n\n\n\n\nmedia\nmediana\nmoda\n\n\n\n\nhomic_abs\n145.33\n95.00\n22.0\n\n\nhomic_tx\n4.77\n4.50\n4.5\n\n\nfeminic_abs\n53.22\n33.00\n19.0\n\n\nfeminic_tx\n1.65\n1.50\n1.3\n\n\npart_feminic\n37.76\n38.90\n50.0\n\n\nrendapc\n1447.15\n1267.00\n1010.0\n\n\ntotal_abs\n198.56\n128.00\n112.0\n\n\nmais_50\n0.26\n0.00\n0.0\n\n\nt_homic_abs\n283.70\n264.00\n373.0\n\n\nt_homic_tx\n13.79\n10.00\n4.2\n\n\nt_feminic_abs\n102.52\n88.00\n54.0\n\n\nt_feminic_tx\n4.14\n3.60\n2.3\n\n\npart_t_feminic\n26.88\n29.73\nNA\n\n\nt_total_abs\n383.00\n377.00\nNA\n\n\n\n\n\n\n\n\n6.6.1.1 Visualizando as medidas por categorias\nGráfico de Pizza\nO gráfico de pizza indica as proporções de uma determinada variável de classe. Aqui utilizamos a média do número de feminicídios absoluto por região.\n\npie(mean_1$feminic_abs , main = \"Média Feminicídio por Região\", \n    labels = c(\"CO\",\"N\",\"NE\",\"S\",\"SD\"), border=\"lightgray\")\n\n\n\n\nGráfico de Barra\nEm geral a utilização do gráfico de barras está relacionado ao entendimento da frequência de valores associados a uma determinada categoria. Por exemplo, imagine que temos um banco de dados com as pessoas classificadas como: i)Não trabalha; ii)Trabalha e iii)Desempregado. Teríamos três categorias e a frequência de pessoas em cada categoria. Poderíamos ainda dividir essa categoria entre homens e mulheres. Essa é a utilização mais padrão do gráfico de barras. Vejamos alguns gráficos:\n\nfinal_fem_22&lt;- final_fem_22[order(-final_fem_22$feminic_tx),]\n\nbarplot(final_fem_22$feminic_tx, main=\"Taxa de Feminicídio por Estado\", \n        names.arg=final_fem_22$estados,\n        col=\"salmon2\",border=\"lightsalmon3\",\n        las = 2, \n        cex.names = 0.7,\n        xlab=\"\", ylab=\"Tx. por 100 mil\")\n\n\n\n\n\nfinal_fem_22&lt;- final_fem_22[order(-final_fem_22$part_feminic),]\n\nbarplot(final_fem_22$part_feminic, main=\"Participação da Taxa de Feminicídio no Total por Estado\", \n        names.arg=final_fem_22$estados,\n        col=\"darkblue\",border=\"steelblue\",\n        las = 2, \n        cex.names = 0.7,\n        xlab=\"\", ylab=\"Tx. por 100 mil\")\n\n\n\n\n\ng_b1&lt;- mean_1[c(1,5,13)]\ng_b1$tx_f &lt;- \"Feminicídio (tx)\" \ng_b1$tx_t_f &lt;- \"Tentativa de Fem. (tx)\"\ng_b2&lt;- g_b1[c(1,2,4)]\nnames(g_b2)&lt;-c(\"regiao\", \"taxa\", \"tipo\")\ng_b3&lt;- g_b1[c(1,3,5)]\nnames(g_b3)&lt;-c(\"regiao\", \"taxa\", \"tipo\")\ng_barra1&lt;-rbind(g_b2, g_b3)\n\n\nbarplot(taxa ~ tipo + regiao, data = g_barra1, \n        beside = T,\n        #legend.text = TRUE,\n        ylim = c(0,8),\n        ylab = \"Taxa (100 mil mulheres)\",\n        xlab = \"Região\",\n        col = c(\"lightsalmon3\", \"lightskyblue3\"))\n\n# Adicionando a legenda\nlegend(\"topright\", title = \"\", legend = c(\"Feminicídio \", \"Tentativa Feminicídio\"), pch = 15 , box.lwd = 0,box.col = \"white\",bg = \"white\", col = c(\"lightsalmon3\", \"lightskyblue3\")\n)\n\n# Incluindo o eixo x\nabline(h=0)\n\n\n\n\nGráfico de Linha\nO gráfico de linha ou pontos é muito utilizado para visualização da evolução de séries. É um gráfico que nos permite ver a evolução dos salários entre homens e mulheres, evolução dos preços dos alimentos, evolução do número de casos de feminicídio, evolução dos processos em determinada Vara.\nNosso banco é uma fotografia e não uma evolução, o que torna esse tipo de visualização menos útil. Vejamos a participação de feminicídio por estado\n\nfinal_fem_22&lt;- final_fem_22[order(-final_fem_22$total_abs),]\n\nplot(x=final_fem_22$total_abs, y=final_fem_22$t_feminic_tx,\n     type=\"b\" , bty=\"l\" , \n     ylim=c(0,12),\n     col=rgb(0.2,0.4,0.1,0.7) , lwd=2 , pch=17,\n     main=\"Tentativa eFeminídio Taxa\", \n     xlab = \"Total de Homicídios\", ylab=\"Taxa / 100 mil \"\n      )\n# Adicionando nova variável\nlines(x=final_fem_22$total_abs, y=final_fem_22$feminic_tx, col=rgb(0.8,0.4,0.1,0.7) , lwd=2 , pch=19 , type=\"b\" )\n\n# Inserindo a Legenda\n\nlegend(\"topright\", \n  legend = c(\"Tentativa\", \"Feminicídio\"), \n  col = c(rgb(0.2,0.4,0.1,0.7), \n  rgb(0.8,0.4,0.1,0.7)), \n  pch = c(17,19), \n  bty = \"n\", \n  pt.cex = 1, \n  cex = 0.8, \n  text.col = \"black\", \n  horiz = F , \n  inset = c(0.1, 0.1))\n\n\n\n\nPERCENTIL:\nO p-esimo percentil é um valor tal que ao menos p por cento das observações são menores ou iguais à ele e pelo menos (100-p) por cento das observações são maiores ou iguais a esse valor.\nEtapas para calcular o p-ésimo percentil\nEtapa 1: Organize os dados em ordem crescente.\nEtapa 2: Calcule um indice, \\(i\\) tal que \\[i = \\frac{p}{100} \\times n\\] onde \\(p\\) é o percentil procurado\nEtapa 3:\n\nSe \\(i\\) não for um número inteiro, arredondeo-o para cima. O próximo número inteiro maior que \\(i\\) denota a posição do p-esimo percentil.\nSe \\(i\\) for um número inteiro o p-esimo percentil será a média dos valores que o ocupam as posições \\(i\\) e \\(i + 1\\).\n\n\nquantile(final_fem_22$feminic_tx, probs = c(0.10,0.30,0.60,0.85), na.rm=T)\n\n 10%  30%  60%  85% \n0.96 1.30 1.66 2.24 \n\n\nQUARTIS:\nOs quartis são medidas estatísticas que dividem um conjunto de dados ordenados em quatro partes iguais.\nO três quartis são:\nPrimeiro Quartil (Q1): Representa o valor abaixo do qual está situada a primeira quarta parte (ou 25% inferiores) dos dados quando eles estão ordenados em ordem crescente. O primeiro quartil é o valor que divide os dados em 25% (ou 0.25) abaixo e 75% (ou 0.75) acima desse ponto.\nSegundo Quartil (Q2): Corresponde à mediana dos dados, dividindo o conjunto em duas metades iguais. É o valor que separa os 50% inferiores dos 50% superiores dos dados.\nTerceiro Quartil (Q3): Indica o valor acima do qual está situada a terceira quarta parte (ou 25% superiores) dos dados quando eles estão ordenados. Assim como o primeiro quartil, o terceiro quartil divide os dados em 75% (ou 0.75) abaixo e 25% (ou 0.25) acima desse ponto\n\nquantile(final_fem_22$feminic_tx, na.rm=T)\n\n  0%  25%  50%  75% 100% \n0.60 1.30 1.50 1.95 3.10 \n\n\nAMPLITUDE:\nAmplitude é a diferença entre o valor mínimo e máximo de uma série de dados.\n\\[\\text{Amplitude} = \\text{Maior Valor} - \\text{Menor Valor}\\]\n\nmin_max&lt;-range(final_fem_22$feminic_tx)\namp&lt;-min_max[2]-min_max[1]\namp\n\n[1] 2.5\n\n\nAMPLITUDE INTERQUANTIL:\nA amplitude interquartil é dada pela diferenca entre o terceiro (\\(Q_3\\)) e o primeiro quartil (\\(Q_1\\)).\n\\[IQR = Q_3 - Q_1\\]\n\nqs&lt;-quantile(final_fem_22$feminic_tx, na.rm=T)\niq&lt;-qs[4]-qs[2]\nIQR(final_fem_22$feminic_tx)\n\n[1] 0.65\n\niq\n\n 75% \n0.65 \n\n\n\n\n6.6.1.2 Visualizando a Distribuição dos Dados\nBoxplot\nO boxplot é um gráfico que traz muitas informações e pode ser visto como a distribuição de probabilidade dos dados. O box contém 50% dos dados. O limite superior indica o percentil de 75% (Q3) e o limite inferior indica o percentil de 25% (Q1). A linha que corta o box indica a mediana, ou seja, Q2. Os bigodes são calculados com base na distância interquantílica, ou seja,\nLimite inferior: Q1-1,5(Q3-Q1)\nLimite superior:Q3+1,5(Q3-Q1)\nDados fora desses limites são classificados como suspeitos de serem outlier. Podemos observar a assimetria dos dados quando a mediana não está no meio da caixa, indicando maior densidade na menor distância entre os quartis Q1 ou Q3 e a mediana Q2. Vejamos agora o boxplot da taxa de feminicídio e da taxa de feminicídio por região.\n\nboxplot(final_fem_22$feminic_tx,data=final_fem_22, main=\"Boxplot da taxa de feminicídio no Brasil, 2022\", horizontal=TRUE,\n  xlab=\"\", ylab=\"Tx de Feminicídio/100mil\", col=\"steelblue\")\n\n\n\n\n\nboxplot(final_fem_22$feminic_tx~final_fem_22$regiao,data=final_fem_22, main=\"Boxplot da taxa de feminicídio no Brasil, 2022\", horizontal=TRUE,\n  xlab=\"\", ylab=\"Tx de Feminicídio/100mil\", col=\"steelblue\")\n\n\n\n\nO Violin Plot é muito parecido com o BoxPlot mas com a densidade de kernel rotacionada em cada um dos lados. Assim, indica a distribuição dos dados em cada ponto e vem anotado a mediana na forma de um ponto ou marca e um pequeno boxplot no centro do violin plot.\n\n#Binária para nordeste e centro oeste 1 e demais regiões 0\nfinal_fem_22$N_NE_CO&lt;-0\nfinal_fem_22$N_NE_CO[final_fem_22$regiao == \"N\" | final_fem_22$regiao == \"NE\" | final_fem_22$regiao == \"CO\"] &lt;- 1\n\ntable(final_fem_22$N_NE_CO, final_fem_22$regiao)\n\n   \n    CO N NE S SD\n  0  0 0  0 3  4\n  1  4 7  9 0  0\n\n\n\nlibrary(vioplot) \nx1 &lt;- final_fem_22$feminic_tx[final_fem_22$N_NE_CO==1]\nx2 &lt;- final_fem_22$feminic_tx[final_fem_22$N_NE_CO==0]\nvioplot(x1, x2, names=c(\"Norte, Nord. e C.Oeste\", \"Sul e Sudeste\"), col=c(\"steelblue\", \"lightblue\"), border=\"white\" )\ntitle(\"Violin Plots da taxa de feminicídio por região do Brasil\")\n\n\n\n\nAqui segue uma sugestão de plotar o histograma juntamente com o boxplot, possibilitando em um mesmo gráfico uma maior quantidade de observação. Veja abaixo:\n\npar(fig=c(0,0.6,0,0.6), new=TRUE)\nhist(final_fem_22$feminic_tx, main=\"\", xlab=\"Taxa Feminicídio\", ylab=\"Frequência\", col=\"lightblue2\")\npar(fig=c(0,0.6,0.15,0.9), new=TRUE)\nboxplot(final_fem_22$feminic_tx, main=\"Taxa de Feminicídio\", horizontal=TRUE, axes=FALSE, col=\"navajowhite2\")\n\n\n\n\nGráfico de Densidade\nVisualizar a distribuição empírica dos dados fornece uma grande quantidade de informação. Um gráfico básico em análise descritiva é o histograma, o qual fornece a distribuição de probabilidade empírica dos dados em um formato de barras. A área do histograma é igual a 1 e altura da sua barra da a densidade de observações em cada classe.\n\n  hist(final_fem_22$feminic_tx, \n       breaks=8,  # número de barras do histograma\n       col=\"steelblue\",  #cor do preenchimento\n       xlab=\"Taxa de Feminicídio\",  # Títulos de eixos e gráfico\n       ylab=\"Frequência\", \n       main=\"Histograma da Taxa de Feminicídio\")\n\n\n\n\nPodemos plotar o histograma conjuntamente com um modelo de distribuição de probabilidade. Utilizaremos a distribuição normal com mesma esperança e desvio padrão.\n\nx &lt;- final_fem_22$feminic_tx \nh&lt;-hist(x, breaks=8, col=\"steelblue\",xlab=\"Taxa de Feminicídio\", ylab=\"Frequência\",\n        main=\"Histograma da taxa de feminicídio e a aproximação pela normal\") \n\nxfit&lt;-seq(0,max(x),length=40) \nyfit&lt;-dnorm(xfit,mean=mean(x),sd=sd(x)) \nyfit &lt;- yfit*diff(h$mids[1:2])*length(x) \nlines(xfit, yfit, col=\"lightsalmon\", lwd=2)\n\n\n\n\nUma outra maneira de visualizar os dados é utilizando uma distribuição continua e não mais a discreta. Para isso, utiliza-se a densidade de Kernel para visualização da distribuição de probabilidade da taxa de feminicídio. Vejamos\n\n  k &lt;- density(final_fem_22$feminic_tx)\n  plot(k, xlab=\"Taxa de Feminicídio\",main=\"Densidade de Kernel para a taxa de feminicídio\")\n  polygon(k, col=\"burlywood3\", border=\"burlywood4\")\n\n\n\n\nOutra forma útil de visualizar os dados a é distribuição por classe, por exemplo distribuição de salários entre homens e mulheres, tempo do processo por vara, distribuição da taxa de feminicídio por regiaão. Vamos utilizar a densidade de Kernel para analisar a distribuição dos valores da taxa de feminicídio por região. Para isso precisa instalar o pacote sm.\n\n#install.packages(\"sm\")\nlibrary(sm)\nsm.density.compare(final_fem_22$feminic_tx, final_fem_22$N_NE_CO, xlab=\"Taxa de Feminicídio\", lwd=c(3, 3),col=c('darkgreen', 'darkblue'))\ntitle(main=\"Comparação da taxa de feminicídio entre regiôes\")\n\nlegend(\"topright\", c(\"S SD\", \"N NE CO\"), xpd = TRUE, horiz = FALSE , bty = \"n\",  col=c('darkgreen', 'darkblue'), lwd=c(4, 4), cex = 0.6)\n\n\n\n\n\n\n\n6.6.2 Medidas de Variabilidade\nA variância amostral é uma medida estatística que indica o quão dispersos estão os dados em relação à média amostral. Em outras palavras, ela quantifica a extensão das diferenças individuais entre os valores observados e a média da amostra.\nA variância populacional é semelhante à variância amostral, mas é calculada utilizando todos os dados de uma população em vez de uma amostra. Ela descreve a dispersão dos dados em relação à média populacional.\nVARIÂNCIA E DESVIO PADRÃO AMOSTRAL:\nDefinimos a vriância amostral como:\n\\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\] onde \\(\\bar{x}\\) é a média amostral.\nVejamos a variância da taxa de feminicídio e do femnicídio absoluto:\n\nvar(final_fem_22$feminic_tx, na.rm=T)\n\n[1] 0.3818234\n\nvar(final_fem_22$feminic_abs, na.rm=T)\n\n[1] 2364.718\n\n\nO Desvio padrão amostral é derivado da variância. Podemos qualcular essa estatistica da seguinte maneira:\n\\[s = \\sqrt{s^2} = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}}\\]\nPara os nossos dados anteriores:\n\n# Tx Feminicídio\nsd(final_fem_22$feminic_tx, na.rm=T)\n\n[1] 0.6179186\n\n#Feminicídio Absoluto\nsd(final_fem_22$feminic_abs, na.rm=T)\n\n[1] 48.62837\n\n\nVamos consolidar agora nossas estatísticas descritivas\n\nfun1 &lt;- function(x, na.rm = TRUE) c(media=mean(x, na.rm = TRUE), med=median(x, na.rm = TRUE), var=var(x, na.rm = TRUE), dp=sd(x, na.rm = TRUE))\n\nest_descrit &lt;- (sapply(final_fem_22[4:17], fun1))\n\nt(est_descrit) %&gt;% \n  kbl(digits = 2) %&gt;%\n     kable_styling()\n\n\n\n\n\nmedia\nmed\nvar\ndp\n\n\n\n\nhomic_abs\n145.33\n95.00\n13985.00\n118.26\n\n\nhomic_tx\n4.77\n4.50\n4.39\n2.10\n\n\nfeminic_abs\n53.22\n33.00\n2364.72\n48.63\n\n\nfeminic_tx\n1.65\n1.50\n0.38\n0.62\n\n\npart_feminic\n37.76\n38.90\n175.84\n13.26\n\n\nrendapc\n1447.15\n1267.00\n243910.59\n493.87\n\n\ntotal_abs\n198.56\n128.00\n26451.33\n162.64\n\n\nmais_50\n0.26\n0.00\n0.20\n0.45\n\n\nt_homic_abs\n283.70\n264.00\n25685.83\n160.27\n\n\nt_homic_tx\n13.79\n10.00\n286.92\n16.94\n\n\nt_feminic_abs\n102.52\n88.00\n5692.09\n75.45\n\n\nt_feminic_tx\n4.14\n3.60\n5.94\n2.44\n\n\npart_t_feminic\n26.88\n29.73\n83.27\n9.13\n\n\nt_total_abs\n383.00\n377.00\n51470.00\n226.87\n\n\n\n\n\n\n\nCOEFICIENTE DE VARIAÇÃO:\nO coeficiente de variação (CV) é uma medida de dispersão relativa que expressa a variabilidade dos dados como uma porcentagem da média.\n\\[\\text{CV} = \\left( \\frac{\\text{Desvio padrão}}{\\text{Média}} \\right) \\times 100\\%\\]\n\n# Vamos calcular o coeficiente de variacao\n\n# O R nao tem nehuma funçao para isso, mas podemos fazer isso rapidamente\n\n# Acessando os dados da variável\nfeminic_abs &lt;- final_fem_22$feminic_abs\n\n# Calcular a média da variável\nmedia_variavel &lt;- mean(feminic_abs, na.rm = TRUE)\n\n# Calcular o desvio padrão da variável\ndesvio_padrao_variavel &lt;- sd(feminic_abs, na.rm = TRUE)\n\n# Calcular o coeficiente de variação\ncoeficiente_variacao &lt;- (desvio_padrao_variavel / media_variavel) * 100\n\n# Exibindo o coeficiente de variação\nprint(coeficiente_variacao)\n\n[1] 91.36854\n\nprint((sd(final_fem_22$t_feminic_abs, na.rm = TRUE)/ mean(final_fem_22$t_feminic_abs, na.rm = TRUE)) * 100)\n\n[1] 73.59146\n\n\nPara entendermos vamos supor que existam duas variáveis com mesmo desvio padrão, igual a 10. A primeira terá média de 10 e a segunda de 20, vejamos a diferença no coeficiente de variação.\n\\(\\text{CV}_{X_1}=\\frac{10}{10}.100=100\\%\\) e \\(\\text{CV}_{X_2}=\\frac{10}{20}.100=50\\%\\)\nA variabilidade relativa é menor para a segunda variável. No exemplo acima a taxa de feminicídio tem uma variabilidade relativa maior (91%) do que a tentativa de feminicídio (74%) entre os Estados Brasileiros.\n\n\n6.6.3 Medidas de Associação\nCOVARIÂNCIA AMOSTRAL\nCovariância entre duas variáveis: A covariância entre duas variáveis X e Y é uma medida estatística que descreve como essas variáveis variam juntas. Em outras palavras, a covariância indica a tendência de X e Y de se moverem na mesma direção (covariância positiva) ou em direções opostas (covariância negativa).\n\\[\\text{Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})\\]\n\n cov(final_fem_22$feminic_tx, final_fem_22$homic_tx)\n\n[1] 0.4648575\n\n\nCORRELAÇÃO\nO coeficiente de correlação entre duas variáveis X e Y é uma medida estatística que descreve a força e a direção da relação linear entre essas variáveis. O coeficiente de correlação é frequentemente representado pelo coeficiente de correlação de Pearson, \\(r_{XY}\\).\n\\[r_{XY} = \\frac{\\text{Cov}(X, Y)}{s_X s_Y}\\] O coeficiente de correlação de Pearson é uma medida amplamente utilizada para avaliar a relação linear entre variáveis, pois fornece uma interpretação padronizada da força e direção da relação, independentemente das unidades das variáveis.\n\n cor(final_fem_22$feminic_tx, final_fem_22$homic_tx)\n\n[1] 0.3589068\n\n\nScatter plot\nO Scatter plot é conhecido como o gráfico de dispersão. Ele relaciona duas ou três variáveis, ou seja, plota \\(X\\) contra \\(Y\\). Muito utilizado para ver o comportamento conjunto de duas séries. Observe que renda e a taxa de feminicídio não mostram um comportamento conjunto, estão dispersas.\n\n##Dispersão entre renda per capita e a taxa de feminicidio\nplot(final_fem_22$rendapc, final_fem_22$feminic_tx,\n     main = \"Taxa de Feminicídio vs. Renda Per Capita\",\n     xlab = \"Renda Per Capita\",\n     ylab = \"Taxa de Feminicídio\",\n     col = \"steelblue\",          # Cor dos pontos\n     pch = 16,              # Forma dos pontos (círculos sólidos)\n     cex = 1.5              # Tamanho dos pontos\n)\nabline(lm(final_fem_22$feminic_tx~final_fem_22$rendapc), col=\"lightblue4\", lwd=2)\n\n\n\n\nAo observar a taxa de homicídio e a taxa de feminicídio, estados com maior taxa de homicídio tendem a ter maior taxa de feminicídio.\n\n##Dispersão entre renda per capita e a taxa de feminicidio\nplot(final_fem_22$homic_tx, final_fem_22$feminic_tx,\n     main = \"Taxa de Feminicídio vs. Taxa de Homicidios\",\n     xlab = \"Taxa de Homicidio\",\n     ylab = \"Taxa de Feminicídio\",\n     col = \"lightgoldenrod3\",          # Cor dos pontos\n     pch = 16,              # Forma dos pontos (círculos sólidos)\n     cex = 1.5              # Tamanho dos pontos\n)\nabline(lm(final_fem_22$feminic_tx~final_fem_22$homic_tx), col=\"lightblue4\", lwd=2)\n\n\n\n\n\nlibrary(corrgram)\ncorrel&lt;- final_fem_22[c(5,7,8,9,13,15,16)]\ncorrgram(correl, order=TRUE, lower.panel=panel.shade, upper.panel=panel.cor,  main=\"Correlação entre as diversas variáveis\") \n\n\n\n\n\n\n6.6.4 Teste de Hipótese\nVamos testar a hipótese de que as taxas de feminicídio são iguais entre as regiões norte, nordeste e centro oeste e as regiões sul e sudeste. Vamos permitir que as variâncias sejam diferentes entre as duas regiões\n\\[H_0: \\mu_{N-NE-CO} = \\mu_{S-SD}\\] \\[H_1: \\mu_{N-NE-CO} \\neq \\mu_{S-SD}\\]\n\nt.test(feminic_tx~N_NE_CO, data=final_fem_22) \n\n\n    Welch Two Sample t-test\n\ndata:  feminic_tx by N_NE_CO\nt = -1.2049, df = 20.949, p-value = 0.2417\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.6640345  0.1768916\nsample estimates:\nmean in group 0 mean in group 1 \n       1.471429        1.715000 \n\n\nO teste mostra que não rejeitamos a hipótese nula de que as duas regiões possuem a mesma média de taxa de feminicídio.\nVejamos agora a renda per capita:\n\nt.test(rendapc~N_NE_CO, data=final_fem_22) \n\n\n    Welch Two Sample t-test\n\ndata:  rendapc by N_NE_CO\nt = 4.6401, df = 22.301, p-value = 0.0001225\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n 340.6685 890.5172\nsample estimates:\nmean in group 0 mean in group 1 \n       1903.143        1287.550 \n\n\nObserva-se que rejeita-se a hipótese nula, e há evidências de que a média da renda per capita entre as duas regiões são diferentes.\nGRÁFICOS COM GGPLOT2\nO pacote ggplot2 vem se consolidando como um dos pacotes mais usados para geração de gráficos. Ele tem algumas vantagens como:\n\nBastante flexível\nPoderoso\nMuito personalizável\nBonito!\n\nMas algumas coisas não deveriam ser feitas com ggplot, pois existem pacotes mais especializados:\n\nGráficos 3D (pacote rgl)\nGrafos (pacote igraph)\nGráficos interativos (pacote ggvis)\n\nA gramática dos gráficos\nPara criarmos gráficos com ggplot, utilizamos blocos de sintaxe que vão sendo empilhados para criar o gráfico pretendido\nOs blocos com os quais podemos trabalhar são:\n\nDados\nMapeamento estético\nObjetos geométricos\nTransformações estatíticas\nEscalas\nSistema de coordenadas\nAjustes de posição"
  },
  {
    "objectID": "descritiva.html#estatística-e-parâmetro",
    "href": "descritiva.html#estatística-e-parâmetro",
    "title": "6  Análise Descritiva",
    "section": "6.4 Estatística e Parâmetro",
    "text": "6.4 Estatística e Parâmetro\n\n\n\n\nflowchart LR\n  A[PARÂMETRO] --&gt; B[Medida que descreve uma característica da população]\n\n\n\n\n\nOs parâmetros definem as características de uma população. Qual a renda média da população, qual o desemprego médio da população, qual o desempenho médio educacional, qual a expectativa de vida média na população etc. São características que em geral não observamos.\nUma pergunta, qual o tempo médio que demora um processo de feminicídio? Perceba que mesmo características da população que conhecemos são de difíceis de conhecermos. Temos que nos valer de uma parte e tentar estimar o que seriam os valores dessas características.\n\n\n\n\nflowchart LR\n  A[ESTATÍSTICA] --&gt; B[Medida que descreve uma característica da amostra]\n\n\n\n\n\nSejam \\(x_1, x_2,..., x_{n}\\) os valores medidos a cada para cada medição de \\(X\\). Podemos definir uma estatística como:\n\\[ t= H (x_1, x_2, ..., x_{n})\\]\nAlguns exemplos de T:\n\\[ \\text{Média}: \\ \\overline{x}=\\frac{\\sum_{i=1}^{n} x_i}{n}\\]\n\\[ \\text{Variância:} \\ s^{2}= \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\overline{x})^{2} \\]\n\\[ x_{(1)}: Min\\{x_1, ..., x_n\\}\\]\nVejamos a tabela abaixo que já faz uma primeira associação entre estatística e parâmetro:\n\n\n\n\n\n\n\n\n\nParâmetro\n\nEstatística\n\n\n\n\n\nEsperança\n\\(E(X)=\\mu\\)\n\\(\\bar{X}\\)\nMédia\n\n\nVariância Pop.\n\\(Var(X)=\\sigma^2\\)\n\\(S^2;\\sigma^2\\)\nVariância Amostral\n\n\nMediana Pop.\nMd\nmd\nMediana Amostral\n\n\nProporção Pop.\np\n\\(\\hat{p}\\)\nProporção Amostral\n\n\n\nTabela 1 - Parâmetros populacionais e as Estatísticas associadas\nComo regra geral, os parâmetros são representados por letras gregas e as estatística com letras do nosso alfabeto (latino) ou letra grega com com chapéu para indicar que é uma estatística.\nESTIMADORES Um estimador é uma estatística calculada a partir da amostra que é usada para estimar um parâmetro desconhecido da população. Nos permitem fazer inferências sobre os parâmetros com base nos dados amostrais. Por exemplo, a média amostral é um estimador da média populacional, e a proporção amostral é um estimador da proporção populacional."
  },
  {
    "objectID": "descritiva.html#histograma",
    "href": "descritiva.html#histograma",
    "title": "6  Análise Descritiva",
    "section": "6.7 Histograma",
    "text": "6.7 Histograma\n\nlibrary(ggplot2)\n\n\nAnexando pacote: 'ggplot2'\n\n\nOs seguintes objetos são mascarados por 'package:psych':\n\n    %+%, alpha\n\np&lt;-  ggplot(data=final_fem_22, aes(x = feminic_tx, y = after_stat(density))) + \n  geom_histogram(bins=10, col=\"darkblue\",fill=I(\"steelblue\"))+\n  geom_vline(aes(xintercept = mean(feminic_tx)),  color = \"lightsalmon3\", linewidth = 1) +\n  geom_density(color = \"darkgoldenrod\", linewidth = 2)\n\np + labs(title=\"Distribuição da taxa de Feminicídio nos Estados\", x=\"Taxa de Feminicídio\", y=\"Densidade\")"
  },
  {
    "objectID": "descritiva.html#teste-de-hipotese-parâmetros.",
    "href": "descritiva.html#teste-de-hipotese-parâmetros.",
    "title": "6  Análise Descritiva",
    "section": "6.5 Teste de Hipotese (Parâmetros).",
    "text": "6.5 Teste de Hipotese (Parâmetros).\n\n6.5.1 Introdução ao Teste de Hipótese de Duas Populações (de Médias)\nO teste de hipótese é uma técnica estatística fundamental usada para tomar decisões baseadas em evidências amostrais. O teste de hipótese de duas populações é aplicado quando queremos comparar as médias de duas populações distintas e determinar se existe uma diferença estatisticamente significativa entre elas. Vamos explorar os principais conceitos deste teste:\nFormulação das Hipóteses\nNo teste de hipótese de duas populações, formulamos duas hipóteses:\n\nHipótese Nula (\\(H_0\\)): Esta é a hipótese inicial que assume que não há diferença entre as médias das duas populações. Geralmente, é representada como\n\n\\[H_0: \\mu_1 = \\mu_2\\],\nonde \\(\\mu_1\\) e \\(\\mu_2\\) são as médias das duas populações.\n\nHipótese Alternativa (\\(H_a\\) ou \\(H_1\\)): Esta é a hipótese que queremos testar, indicando que há uma diferença significativa entre as médias das duas populações. Pode ser definida como: \\[H_a: \\mu_1 &gt; \\mu_2\\] ou \\[H_a: \\mu_1 &lt; \\mu_2\\] ou\n\n\\[H_a: \\mu_1 \\neq \\mu_2\\].\nEstatística do Teste\nO teste de hipótese de duas populações geralmente envolve o cálculo de uma estatística de teste específica para comparar as médias das amostras das duas populações. Uma das estatísticas comuns é o teste t de Student, especialmente quando as variâncias populacionais são desconhecidas e podem ser diferentes entre as populações.\nDecisão do Teste\nApós calcular a estatística de teste, comparamos o valor observado da estatística com um valor crítico ou calculamos um valor p associado. O valor p é a probabilidade de obter uma estatística de teste tão extrema quanto a observada, assumindo que a hipótese nula seja verdadeira. Com base no valor p (geralmente comparado com um nível de significância pré-definido, como 0,05), tomamos uma decisão de rejeitar ou não rejeitar a hipótese nula.\nConclusão do Teste\nA conclusão do teste de hipótese de duas populações nos permite determinar se há evidências estatísticas suficientes para rejeitar a hipótese nula em favor da hipótese alternativa. Essa decisão tem implicações importantes em áreas como pesquisa científica, análise de dados e tomada de decisões em negócios e saúde."
  },
  {
    "objectID": "outrosmodelos.html#outros-modelos",
    "href": "outrosmodelos.html#outros-modelos",
    "title": "8  Modelos Avançados",
    "section": "8.1 Outros Modelos",
    "text": "8.1 Outros Modelos\nEm construção……"
  },
  {
    "objectID": "lineares.html#unidade-de-medida-e-forma-funcional",
    "href": "lineares.html#unidade-de-medida-e-forma-funcional",
    "title": "7  Modelos Lineares",
    "section": "7.5 Unidade de Medida e Forma Funcional",
    "text": "7.5 Unidade de Medida e Forma Funcional\n\n7.5.1 Unidade de Medida\nVejamos o efeito de mudanças na unidade de medida das variáveis na nossa regressão.\n1. Se a variável dependente (\\(Y\\)) é multiplicada por uma constante \\(c\\), então as estimativas do intercepto e da inclinação também serão multiplicadas por \\(c\\). Vamos multiplicar por 10 e ver o que acontece:\n\nlibrary(dplyr)\ndados &lt;- dados |&gt; \n  mutate(feminic_tx10 =feminic_tx*10 )\n\nmodelo1 &lt;- lm(data = dados, feminic_tx10 ~ homic_tx)\n\nsummary(modelo)$coefficients\n\n            Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 1.146731 0.28607061 4.008560 0.0004846694\nhomic_tx    0.105805 0.05503129 1.922633 0.0659903845\n\nsummary(modelo1)$coefficients\n\n            Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 11.46731  2.8607061 4.008560 0.0004846694\nhomic_tx     1.05805  0.5503129 1.922633 0.0659903845\n\n\n2. Se a variável explicativa (\\(X\\)) é multiplicada por uma contante \\(c\\), então o coeficiente de inclinação será dívido por \\(c\\). Nada acontece com o intercepto. Vamos multiplicar agora a taxa de homicídio por 10\n\ndados &lt;- dados |&gt; \n  mutate(homic_tx10 =homic_tx*10 )\n\nmodelo2 &lt;- lm(data = dados, feminic_tx ~ homic_tx10)\n\nsummary(modelo)$coefficients\n\n            Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 1.146731 0.28607061 4.008560 0.0004846694\nhomic_tx    0.105805 0.05503129 1.922633 0.0659903845\n\nsummary(modelo2)$coefficients\n\n             Estimate  Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 1.1467311 0.286070605 4.008560 0.0004846694\nhomic_tx10  0.0105805 0.005503129 1.922633 0.0659903845\n\n\n\nSe a variável explicativa (\\(X\\)) é dividida por uma constante \\(c\\), então o coeficiente de inclinação é multiplicado por \\(c\\). Nada acontece com a constante.\n\n\ndados &lt;- dados |&gt; \n  mutate(homic_tx_10 =homic_tx/10 )\n\nmodelo3 &lt;- lm(data = dados, feminic_tx ~ homic_tx_10)\n\nsummary(modelo)$coefficients\n\n            Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 1.146731 0.28607061 4.008560 0.0004846694\nhomic_tx    0.105805 0.05503129 1.922633 0.0659903845\n\nsummary(modelo3)$coefficients\n\n            Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 1.146731  0.2860706 4.008560 0.0004846694\nhomic_tx_10 1.058050  0.5503129 1.922633 0.0659903845\n\n\n\n\n\n\n\n\nImportante\n\n\n\nO \\(R^2\\) e os testes de hipótese não depende das unidades de nossas variáveis."
  },
  {
    "objectID": "lineares.html#incorporando-não-linearidades-nas-variáveis",
    "href": "lineares.html#incorporando-não-linearidades-nas-variáveis",
    "title": "7  Modelos Lineares",
    "section": "7.6 Incorporando não linearidades (nas variáveis!)",
    "text": "7.6 Incorporando não linearidades (nas variáveis!)\nVamos agora incorporar a não linearidade nas variáveis e ver como fica a sua interpretação. Abaixo tem-se uma tabela para interpretar os coeficientes e será explicada nos exemplos mais abaixo.\n\n\n\n\n\n\n\n\n\nModelo\nDependente\nExplicativa\nInterpretação de \\(\\beta_1\\)\n\n\n\n\nNivel-nível\n\\(y\\)\n\\(x\\)\n\\(\\beta_1 \\Delta x\\)\n\n\nNível-Log\n\\(y\\)\n\\(ln(x)\\)\n\\((\\beta_1/100)\\%\\) \\(\\Delta x\\)\n\n\nLog-Nível\n\\(ln(y)\\)\n\\(x\\)\n\\(\\% \\Delta y = (100 \\beta_1) \\Delta x\\)\n\n\nLog_log\n\\(ln(y)\\)\n\\(ln(x)\\)\n\\(\\% \\Delta y = \\beta_1\\% \\Delta x\\)\n\n\n\n\n7.6.1 Modelo Nível-Nível\nEsse é o modelo que fizemos anteriormente e nos diz que uma variação absoluta em \\(X\\) terá um efeito de \\(\\beta\\) em Y.\n\nmodelo_nn&lt;- lm(data=dados, dados$feminic_tx ~ dados$homic_tx)\nsummary(modelo_nn)$coefficients\n\n               Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept)    1.146731 0.28607061 4.008560 0.0004846694\ndados$homic_tx 0.105805 0.05503129 1.922633 0.0659903845\n\n\nO aumento de uma unidade na taxa de homicídio aumenta em 0,1058 a taxa de feminicídio.\n\n\n7.6.2 Modelo Nível-log\nPrimeiramente vamos criar as variáveis em ln:\n\ndados$Lnfeminic_tx &lt;- log(dados$feminic_tx)\ndados$Lnhomic_tx &lt;- log(dados$homic_tx)\n\nO modelo Nível-Log considerá \\(Y\\) no nível e \\(X\\) no log. As variações relativas de \\(X\\) implicam em variações absolutas constantes em \\(Y\\).\n\nmodelo_nl&lt;- lm(data=dados, dados$feminic_tx ~ dados$Lnhomic_tx)\nsummary(modelo_nl)$coefficients\n\n                  Estimate Std. Error  t value   Pr(&gt;|t|)\n(Intercept)      0.7246404  0.4453288 1.627203 0.11623380\ndados$Lnhomic_tx 0.6238311  0.2900917 2.150462 0.04138118\n\n\nA variação relativa de 1% na taxa de homicídio (\\(X\\)), aumenta a taxa de feminicídio em 0,00623 \\((\\beta_1/100)\\)\n\n\n7.6.3 Modelo Log-Nível\nNesse modelo \\(Y\\) está em log e \\(X\\) em nível. Variações absolutas em \\(X\\) implicam em variações exponenciais de \\(Y\\).\n\nmodelo_ln&lt;- lm(data=dados, dados$Lnfeminic_tx~ dados$homic_tx)\nsummary(modelo_ln)$coefficients\n\n                 Estimate Std. Error  t value  Pr(&gt;|t|)\n(Intercept)    0.21824231 0.18282873 1.193698 0.2438007\ndados$homic_tx 0.04525001 0.03517069 1.286583 0.2100267\n\n\nPara cada incremento aicional da taxa de homicídio, tem-se um incremento de 4,5% na taxa de feminicídio \\(\\% \\Delta y = (100 \\beta_1) \\Delta x\\).\n\n\n7.6.4 Modelo Log-Log\nNesse modelo tanto \\(X\\) como \\(Y\\) estão em log. Variações relativas em \\(X\\) implicam em variações relativas em \\(Y\\)\n\nmodelo_ll &lt;- lm(data=dados, dados$Lnfeminic_tx~ dados$Lnhomic_tx)\nsummary(modelo_ll)$coefficients\n\n                     Estimate Std. Error     t value  Pr(&gt;|t|)\n(Intercept)      0.0009590929   0.284865 0.003366832 0.9973404\ndados$Lnhomic_tx 0.2915325798   0.185564 1.571062163 0.1287399\n\n\nUm aumento de 1% percentual nos homicídios aumenta em 0,29% a taxa de feminicídio nos estados brasileiros."
  },
  {
    "objectID": "dplyr.html#tutorial-sobre-o-uso-do-dplyr-para-manipulação-de-dados-no-r",
    "href": "dplyr.html#tutorial-sobre-o-uso-do-dplyr-para-manipulação-de-dados-no-r",
    "title": "5  O Dplyr",
    "section": "5.1 Tutorial sobre o Uso do dplyr para Manipulação de Dados no R",
    "text": "5.1 Tutorial sobre o Uso do dplyr para Manipulação de Dados no R\nEssa seção é uma criação mesclando o que foi explicado em aula, o Chat GPT e um pouco da nossa organização.\n\n5.1.1 Introdução ao dplyr:\nO dplyr é um poderoso pacote do R projetado para tarefas de manipulação de dados. Ele fornece um conjunto consistente de funções que ajudam a simplificar o processo de manipulação de dados, tornando-o mais intuitivo e eficiente. Neste tutorial, vamos nos aprofundar em cada função fornecida pelo dplyr, juntamente com exemplos.\n\n\n5.1.2 Instalação e Carregamento:\nAntes de mergulharmos no dplyr, assegure-se de tê-lo instalado executando:\n\ninstall.packages(\"dplyr\")\n\nEm seguida, carregue o pacote em sua sessão R:\n\nlibrary(dplyr)\n\n\n\n5.1.3 Visão Geral das Funções:\n\nfilter(): Esta função é usada para filtrar linhas com base em condições específicas. No R: dados_filtrados &lt;- filter(dados, condição).\n\n\nVer também as seleções com escopo filter_all(), filter_if() e filter_at() e as seguintes funções: starts_with(), ends_with(), contains() e matches()\n\n\nselect(): Esta função é usada para selecionar colunas específicas do conjunto de dados. No R: colunas_selecionadas &lt;- select(dados, coluna1, coluna2).\n\n\nVer também select_all(), select_if() and select_at() e as seguintes funções starts_with(), ends_with(), contains(). matches() e num_range()\n\n\narrange(): Esta função é usada para reordenar linhas com base em uma ou mais variáveis.No R: dados_ordenados &lt;- arrange(dados, variável)\nmutate(): Esta função é usada para criar ou modificar colunas dentro do conjunto de dados. No R: dados_modificados &lt;- mutate(dados, nova_coluna = cálculo)\ngroup_by() e summarize(): Essas funções são usadas em conjunto para agrupar dados com base em uma variável e, em seguida, resumi-los. No R: dados_agrupados &lt;- group_by(dados, variável)e resumo &lt;- summarize(dados_agrupados, estatística_resumo = função(variável))\n\n\n\n5.1.4 Operador pipe\nO operador pipe (%&gt;%) é uma ferramenta poderosa em R, especialmente quando combinada com o pacote dplyr. Ele permite encadear várias operações de forma mais legível e eficiente, evitando a necessidade de criar variáveis intermediárias. Vamos explicar o uso do pipe em conjunto com o dplyr.\n1. Encadeamento de Operações:\nSem o pipe, para aplicar várias funções consecutivas a um conjunto de dados, você teria que criar variáveis intermediárias ou aninhar as funções, tornando o código menos legível. Por exemplo, para filtrar dados e depois selecionar colunas usando dplyr, você pode fazer:\n\ndados_filtrados &lt;- filter(dados, condicao)\ncolunas_selecionadas &lt;- select(dados_filtrados, coluna1, coluna2)\n\nCom o pipe, você pode encadear essas operações de forma mais concisa:\n\nresultado &lt;- dados %&gt;%\n  filter(condicao) %&gt;%\n  select(coluna1, coluna2)\n\n2. Melhora a Legibilidade do Código:\nO operador pipe torna o código mais legível e fácil de entender, pois as operações são executadas sequencialmente da esquerda para a direita. Isso facilita a compreensão do fluxo de dados e das transformações aplicadas.\n3. Evita a Criação de Variáveis Intermediárias:\nUsar o pipe evita a necessidade de criar variáveis intermediárias para armazenar resultados parciais, o que economiza espaço na memória e torna o código mais eficiente.\n\n\n5.1.5 Utilizando as funções e o pipe\nContinuaremos a utilizar o mesmo banco de dados sobre feminicídio da seção de manipulação.\n\nfinal_fem_22 &lt;- read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/final_fem_22.csv\", head=T ,sep=\";\")\n\n1. Filtrando Dados:\nUtilizamos os símbolos lógicos para utilizar a função filter:\n\n== Igual a\n!= Não é igual a\n&lt; Menor que\n&lt;= Menor igual que\n&gt; Maior que\n&gt;= Maior igual que\n! NÃO Lógico\n& E Lógico\n| OU Lógico\n%in% Verifica se um valor está em uma matriz de vários valores\nis.na() Checa se um valor e N.A.\n\nVamos filtrar o conjunto de dados para incluir apenas estados que possuem pparticipação da taxa de feminicídio acima de 50% :\n\npart50_mais &lt;- filter(final_fem_22, part_feminic &gt;= 50)\n\nPodemos ter multiplos critérios. Utilizando participação acima de 50 e região norte.\n\npart50_mais_reg &lt;- final_fem_22 |&gt; \n  filter(part_feminic &gt;=50 , regiao==\"N\")\n\nPodemos selecionar os estados da região sul ou da região sudeste para compor o nosso banco selecionado.\n\nregiao1 &lt;- final_fem_22 |&gt; \n  filter(regiao==\"S\" | regiao==\"SD\")\n\n\nregiao2&lt;- final_fem_22 |&gt; \n  filter(regiao %in% c('S', 'SD'))\n\nOu ter um banco sem a região norte\n\nregião3 &lt;- final_fem_22 |&gt; \n  filter(regiao!=\"N\")\n\n2. Selecionando Colunas:\nVamos agora montar um banco apenas as colunas de tx de feminicídio e tx de tentativa de feminicídio:\n\ntx_f &lt;- select(final_fem_22, sigla, feminic_tx, t_feminic_tx)\n\nou\n\ntx_f2 &lt;- final_fem_22 |&gt; \n  select(sigla, feminic_tx, t_feminic_tx)\n\nComo temos a sigla dos estados vamos retirar a coluna com os nomes do estados\n\nsem_nome &lt;- final_fem_22 |&gt; \n  select(-estados)\n\nOu podemos tirar o eatdo indicando a sua posição. Ele está na coluna 2 do banco.\n\nsem_nome1 &lt;- final_fem_22 |&gt; \n  select(-2)\n\nPodemos selecionar renomeando o nome da coluna. Selecionamos feminicídio por estado\n\ntx_f3 &lt;- final_fem_22 |&gt; \n  select(Estados=estados, Taxa_Fem=feminic_tx)\n\n3. Mudando o nome Podemos mudar o nome das variáveis do banco da seguinte forma:\n\nmud_nomes &lt;- final_fem_22 |&gt; \n  select(estados, feminic_tx) |&gt; \n  rename(Estados=estados, Taxa_Fem=feminic_tx)\n\n4. Mudando Posição da Coluna\nPodemos reoarganizar as colunas nos bancos. Vamos deixar asvariáveis de feminicídio todas junta\n\nreord1 &lt;- final_fem_22 |&gt; \n  select(sigla, estados, regiao, feminic_abs, feminic_tx, t_feminic_abs, t_feminic_tx,everything())\n\nOu podemos usar a função relocatepara deixar a participação do feminicídio e da tentativa de feminicídio todas juntas.\n\nreord2 &lt;- final_fem_22 |&gt; \n  relocate(part_feminic,.after=t_feminic_tx)\n\n5. Ordenando Dados:\nVamos ordenar os estado em ordem crescente da taxa de feminicídio:\n\nordenado1 &lt;- arrange(final_fem_22, feminic_tx)\n\nPodemos ordenar o data frame por duas variáveis. Vamos ordenar primeiro por região e depois por taxa de feminicídio.\n\nestado_feminic &lt;- final_fem_22 |&gt; \n  arrange(regiao,feminic_tx)\n\nOu podemos fazer de forma descendente\n\nestado_feminic1 &lt;- final_fem_22 |&gt; \n  arrange(regiao,desc(feminic_tx))\n\n4. Mutando Dados:\nVamos adicionar uma nova coluna ao conjunto de dados representando do total de tentativas de feminicídio, quantas efetivamente terminam em feminicídio. Para isso vamos dividir o feminicídio pelo total de tentativa e feminicídio. :\n\nfinal_fem_22_1 &lt;- final_fem_22 |&gt; \n  mutate(feminic_efetivado =(feminic_abs/(feminic_abs+t_feminic_abs)),  homic_efetivado =(total_abs/(total_abs+t_total_abs)) )\n\nAgora vamos criar uma variável bnária que será igual a 1 se o homicídio efetivado for maior que 0,30.\n\nfinal_fem_22_1 &lt;- final_fem_22_1 |&gt;  \n  mutate(homi_efet_alto = case_when(homic_efetivado &gt;=0.3 ~ 1,\n                             homic_efetivado &lt;0.3 ~ 0))\n\nAbaixo tem-se algumas funções importantes para texto e datas\n\nd4 &lt;- cjpg |&gt; \n  select(processo) |&gt; \n  mutate(seq=str_sub(processo,1,7),\n         digito=str_sub(processo,8,9),\n         ano=str_sub(processo,10,13),\n         segmento=str_sub(processo,14),\n         tribunal=str_sub(processo,15,16),\n         distribuidor=str_sub(processo,17,20))\n\nd5 &lt;- cjpg |&gt;\n  mutate(ano=year(disponibilizacao),\n         mes=month(disponibilizacao,abbr = FALSE,label=TRUE),\n         dia=wday(disponibilizacao,abbr = FALSE,label=TRUE))\n  \nmetadados &lt;- metadados |&gt; \n  mutate(valor_da_acao=tjsp::numero(valor_da_acao))\n\n5. Agrupando e Resumindo Dados:\nVamos agrupar os feminicídios por região e calcular a taxa média por região:\n\nfeminic_agrupado &lt;- final_fem_22 |&gt; \n  group_by(regiao) |&gt; \n summarize(média_feminic = mean(feminic_tx), \n           DP_feminic=sd(feminic_tx,na.rm=TRUE)\n           )\n\nTemos várias estatísticas que podem ser utilizadas:\n\nsumario&lt;- final_fem_22 |&gt; \n  summarize(media=mean(feminic_tx,na.rm=TRUE),\n            soma=sum(feminic_tx,na.rm=TRUE),\n            Desvio_p=sd(feminic_tx,na.rm=TRUE)\n            )\n\nPodemos contar variáveis categóricas ou mesmo binárias. Vamos contar os estados que tiveram taxa de participação do feminicídio acima de 50%.\n\nalta_part &lt;- final_fem_22 |&gt; \n  count(mais_50,sort=TRUE)\n\nContando alta participação do feminicídio por Região\n\nreg_alt_part &lt;- final_fem_22 |&gt; \n  count(regiao, mais_50, sort=FALSE)\n\nEste tutorial forneceu uma visão geral de funções do dplyr. Dominando essas funções, você estará equipado para manipular e analisar conjuntos de dados de forma eficiente no R, facilitando seus fluxos de trabalho de análise de dados. Experimente essas funções em seus próprios conjuntos de dados para explorar seu potencial total."
  },
  {
    "objectID": "lineares.html#regressão-linear-múltipla-rlm",
    "href": "lineares.html#regressão-linear-múltipla-rlm",
    "title": "7  Modelos Lineares",
    "section": "7.7 Regressão Linear Múltipla (RLM)",
    "text": "7.7 Regressão Linear Múltipla (RLM)\nA RLM é uma extensão natural da RLS. Entretanto, ao invés de termos apenas uma variável explicativa podemos ter \\(k\\) variáveis dependentes\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\ldots + \\beta_k x_k + u\\] A hípótese fundamental é a de que:\n\\[E(u|x_1, . . . ,x_k) = 0\\]\nProblemas que façam com que um dos \\(x_1, ...., x_k\\) ser correlacionado com \\(u\\), invalida a hipótese acima. Tal hipótese implica em não viés do MQO.\n\n7.7.1 Exemplos de Regressão Multipla no Contexto Jurídico\n[Determinação de Fatores que Afetam o Valor de Indenizações:] {.underline}\n\nVariável Dependente (\\(Y\\)): Valor da Indenização.\nVariáveis Independentes (\\(X\\)): Idade da Vítima, Gravidade do Dano, Jurisdição.\nObjetivo: Analisar como a idade da vítima, a gravidade do dano e a jurisdição influenciam o valor das indenizações concedidas\n\n\\[Indenização = \\beta_0 + \\beta_1 idade+ \\beta_2 Gravidade + \\beta_2 Jurisdisção + u\\]\nAnálise de Variáveis que Influenciam Taxas de Condenação em Casos Criminais:\n\nVariável Dependente (\\(Y\\)): Taxa de Condenação.\nVariáveis Independentes(\\(X\\)): Idade do Réu, Tipo de Crime, Local do Julgamento.\nObjetivo: Investigar como a idade do réu, o tipo de crime e o local do julgamento afetam a probabilidade de condenação.\n\n\\[Tx.Condenação = \\beta_0 + \\beta_1  idade  +  \\beta_2 Local  + \\beta_3  crime + u\\]\nAnálise de Fatores que Influenciam a Taxa de Feminicídio:\n\nVariável Dependente (\\(Y\\)): Taxa de Feminicídio por 100.000 mulheres\nVariáveis Independentes (\\(X\\)): Taxa de Desemprego, Índice de Educação, Presença de Políticas de Proteção à Mulher.\nObjetivo: Investigar como o desemprego, o nível de educação e a existência de políticas de proteção à mulher estão relacionados à taxa de feminicídio em diferentes regiões.\n\n\\[Tx.feminicidio = \\beta_0 + \\beta_1 desemprego + \\beta_2 educ + \\beta_3 política + u \\]\n\n\n7.7.2 A Interpretação da Equação de Regressão de MQO\nTal qual no modelo de RLS, temos que:\n\\[\\Delta y = \\beta_1 \\Delta x_1 + \\beta_2 \\Delta x_2 + ...+\\beta_k \\Delta x_k\\]\nO coefiente \\(\\beta_j\\), com \\(j=1,...k\\), mede o efeito do incremento de uma unidade de \\(x_j\\) em \\(y\\). Isso continua com a mesma interpretação para modelos que usam o log.\nSuponha que estejamos interessados no impacto de \\(x_1\\). Podemos fazer o seguinte exercício: Tudo o mais constante qual o impacto de \\(x_1\\) em \\(y\\):\n\\[\\frac{\\Delta y}{\\Delta x} = \\beta_1 \\]\nManter outros fatores fixos permite o cientista social, “mimetizar” um experimento, o qual é muito utilizado nas Ciências Naturais. Obviamente, isso não é tão simples assim. Entretanto, manter outros fatores fixos, e supondo que \\[E(u|x_1, . . . ,x_k) = 0\\] , nos aproxíma de afirmações de cunho causal."
  },
  {
    "objectID": "lineares.html#variância-dos-estimadores-de-mqo",
    "href": "lineares.html#variância-dos-estimadores-de-mqo",
    "title": "6  Modelos Lineares",
    "section": "6.11 Variância dos Estimadores de MQO",
    "text": "6.11 Variância dos Estimadores de MQO\nAnalogamente ao que foi feito no caso da regressão simples, para obtermos a variância dos \\(\\hat{\\beta_j}\\) de MQO presisamos recorrer à mais uma hipótese. Tal hipótese é a de homoscedasticidade. Isto é, de que condicionadas as variáveis explicativas, a variância do termo de erro é constante para todas as observações.\n5) Hipótese de Homoscedasticidade: O erro \\(u\\) tem a mesma variâcia, dado qualquer valor das variáveis explicativas:\n\\[Var(u|x_1,...,x_k)=\\sigma^2\\]\nSob as hipóteses 1,2,3,4 e 5, a varincias de \\(\\hat{\\beta_j}\\) e dada por:\n\\[\\text{Var}(\\hat{\\beta}_j) = \\frac{\\hat{\\sigma}^2}{\\sum_{i=1}^{n} (x_{ij} - \\bar{x_j})^2(1-R^2_j)}=\\frac{\\hat\\sigma^2}{\\text{SQT}_j(1-R^2_j)}\\] Onde \\(SQT_j\\) é a a variação amostral de \\(x_j\\)e \\(R^2_j\\) é o R-quadrado da regressão de \\(x_j\\) sobre as outras variáveis explicativas.O termo \\(\\hat{\\sigma}^2\\) é o estimador da variâcia do termo de erro \\(u\\), dado por:\n\\[\\hat{\\sigma}^2=\\frac{\\sum_{i=1}^{n} \\hat{u}_i^2}{n-k-1} = \\frac{\\text{SQR}}{n-k-1}\\] Onde \\(n-k-1\\) são os graus de liberdade do problema de MQO: \\(k\\) variáveis e uma constantante.\n\n6.11.1 Eficiencia de MQO: O Teorema de Gauss-Markov\nTeorema de Gauss-Markov:Sob as hipóteses 1,2,3,4 e 5 os estimadores \\(\\hat{\\beta}_0,\\hat{\\beta}_1,...,\\hat{\\beta}_k\\) são os melhores estimadores lineares não viesados de \\(\\beta_1, \\beta_2,...,\\beta_k\\).\nSe alguma das hipóteses falhar, o teorema não é mais válido.\nÉ o teorema de Gauss-Markov que justifica o uso do MQO para estimar modelos de Regressão Linear Múltipla."
  },
  {
    "objectID": "lineares.html#o-uso-de-dummies-para-categorias-multiplas-e-interação-entre-a-dummy-e-a-variável-dependente",
    "href": "lineares.html#o-uso-de-dummies-para-categorias-multiplas-e-interação-entre-a-dummy-e-a-variável-dependente",
    "title": "6  Modelos Lineares",
    "section": "6.9 O uso de Dummies para categorias multiplas e Interação entre a dummy e a variável dependente",
    "text": "6.9 O uso de Dummies para categorias multiplas e Interação entre a dummy e a variável dependente\nConsidere a equação abaixo\n\\[log(salarioh) = \\beta_0 + \\beta_1  hcasado  +  \\beta_2 mcasadas  + \\beta_3 msolteiras + educ + exper + (exper)^2 u\\] Note que, definimos uma dummy para cada grupo e o o grupo de comparação é o conunto de homens solteiros.As estimativas das dummies acima irão captar a diferença proporcional nos salarios-horas relativamente aos homens solteiros.\n\n###Aplicação de RLM multiplas dummies\n\ndata(wage1, package=\"wooldridge\")\nols.dummy &lt;- lm(log(wage)~ married*female+\n     educ+ exper  +I(exper^2)+tenure+I(tenure^2),\n   data=wage1)\n\nsummary(ols.dummy)\n\n\nCall:\nlm(formula = log(wage) ~ married * female + educ + exper + I(exper^2) + \n    tenure + I(tenure^2), data = wage1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.89697 -0.24060 -0.02689  0.23144  1.09197 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     0.3213781  0.1000090   3.213 0.001393 ** \nmarried         0.2126757  0.0553572   3.842 0.000137 ***\nfemale         -0.1103502  0.0557421  -1.980 0.048272 *  \neduc            0.0789103  0.0066945  11.787  &lt; 2e-16 ***\nexper           0.0268006  0.0052428   5.112 4.50e-07 ***\nI(exper^2)     -0.0005352  0.0001104  -4.847 1.66e-06 ***\ntenure          0.0290875  0.0067620   4.302 2.03e-05 ***\nI(tenure^2)    -0.0005331  0.0002312  -2.306 0.021531 *  \nmarried:female -0.3005931  0.0717669  -4.188 3.30e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3933 on 517 degrees of freedom\nMultiple R-squared:  0.4609,    Adjusted R-squared:  0.4525 \nF-statistic: 55.25 on 8 and 517 DF,  p-value: &lt; 2.2e-16\n\n\nCom base nas estimativas, verificamos que os homens casados ganham cerca de 21,3% mais que os homens solteiros, mantendo fixas educaçao, experiência e permanência. Uma mulher casada, no entanto, ganharia, em média, cerca de 30% menos que um homem solteiro controlando por todas as demais características do banco de dados.\n\n6.9.1 Incorporando Informações Ordinais com o uso de Variáveis Dummy.\n\n#Efeito da Classificação das faculdades de direito sobre salarios iniciais\n\ndata(lawsch85, package=\"wooldridge\")\n\n# Define os pontos de corte para rankear as faculdades\ncutpts &lt;- c(0,10,25,40,60,100,175)\n\n# criando uma varaiavel factor para ranquear as escolas\n lawsch85$rankcat &lt;- cut(lawsch85$rank, cutpts)\n \n# Escolhendo a categoria de referencia\nlawsch85$rankcat &lt;- relevel(lawsch85$rankcat,\"(100,175]\")\n\n\n#rodando a regressão\nres &lt;- lm(log(salary)~rankcat+LSAT+GPA+log(libvol)+log(cost), data=lawsch85)\nsummary(res)\n\n\nCall:\nlm(formula = log(salary) ~ rankcat + LSAT + GPA + log(libvol) + \n    log(cost), data = lawsch85)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.294888 -0.039691 -0.001682  0.043888  0.277497 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     9.1652952  0.4114243  22.277  &lt; 2e-16 ***\nrankcat(0,10]   0.6995659  0.0534919  13.078  &lt; 2e-16 ***\nrankcat(10,25]  0.5935434  0.0394400  15.049  &lt; 2e-16 ***\nrankcat(25,40]  0.3750763  0.0340812  11.005  &lt; 2e-16 ***\nrankcat(40,60]  0.2628191  0.0279621   9.399 3.18e-16 ***\nrankcat(60,100] 0.1315950  0.0210419   6.254 5.71e-09 ***\nLSAT            0.0056908  0.0030630   1.858   0.0655 .  \nGPA             0.0137255  0.0741919   0.185   0.8535    \nlog(libvol)     0.0363619  0.0260165   1.398   0.1647    \nlog(cost)       0.0008412  0.0251360   0.033   0.9734    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.08564 on 126 degrees of freedom\n  (20 observations deleted due to missingness)\nMultiple R-squared:  0.9109,    Adjusted R-squared:  0.9046 \nF-statistic: 143.2 on 9 and 126 DF,  p-value: &lt; 2.2e-16\n\n\nVemos imediatamente que todas as variáveis fictícias que definem as diferentes classificações são estatisticamente significativas. A estimativa de classificação (60.100] significa que, mantendo LSAT, GPA, libvol (volume na biblioteca) e custo fixos, o salário médio em uma faculdade de direito classificada entre 61 e 100 é cerca de 13,2% maior do que em uma faculdade de direito classificada abaixo de 100. A diferença entre uma escola top 10 e uma escola abaixo de 100 é bastante grande."
  },
  {
    "objectID": "googledrive.html#introdução",
    "href": "googledrive.html#introdução",
    "title": "4  Google Drive",
    "section": "4.1 Introdução",
    "text": "4.1 Introdução\nVamos aqui importar os dados de arquivos compartilhados o Google Drive. Vamos usar arquivos que não precisam de autenticação. São aqueles que ” qualquer um com o link” podem acessar. Para isso terá que utilizar o pacote googledrive.\n\n4.1.1 Encontrando o ID\nPrimeiramente precisa ter acesso ao link de compartilhamento. Vejamos o link de compartilhamento do arquivo cjpg.rds\nhttps://drive.google.com/file/d/1vs4hH1xgYl0YzSb2uWeH0gBMh8E5QPL2/view?usp=drive_link\nO ID é a seguinte parte do endereço: 1vs4hH1xgYl0YzSb2uWeH0gBMh8E5QPL2\nCom esse string podemos fazer o download do arquivo\n\n\n4.1.2 Fazendo o download\nPrimeiramente vamos excluir a autenticação com o comando drive_deauth(). Poderá checar a exclusão com o comando drive_user(), ele mostrará que não existe usuário logado ou autenticado.\nDepois indicaremos o caminho do arquivo no google drive e com o caminho indicado ele fará o download na pasta do seu computador indicada na parte superior da aba Console. Depois é só fazer a leitura para transformar o arquivo em .Rdata. Vejamos:\n\nlibrary(googledrive)\n\n             \ndrive_deauth()    # retira a autenticação\ndrive_user()      #verifica se existe usuário logado\ncjpg_public &lt;-  drive_get(as_id(\"1vs4hH1xgYl0YzSb2uWeH0gBMh8E5QPL2\"))   # Obtem o endereço do arquivo\ndrive_download(cjpg_public, overwrite = TRUE)    # faz o download do arquivo na pasta de trabalho\n\n\ncjpg&lt;-readRDS(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/cjpg.rds\")   # faz a leitura do arquivo - colocar o endereço do seu computador\n\nPodemos importar outros arquivos agora:\n\n# IMPORTANTO: final_fem_22\nlibrary(googledrive)\ndrive_deauth()    \ndrive_user()      \n\nfinal_fem_public &lt;-  drive_get(as_id(\"1_GxL3EFsE2JU-39muO_ELoz-kx4-hEpO\"))   \ndrive_download(final_fem_public, overwrite = TRUE)   \n\nfinal_fem_22 &lt;- read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/final_fem_22.csv\", head=T ,sep=\";\")\n\n\n# IMPORTANTO: cpopg_metadados\n\ncpopg_public &lt;-  drive_get(as_id(\"1mtLng43ZAf-sygUjjcaqRaNhuXKC7ol_\"))   \ndrive_download(cpopg_public, overwrite = TRUE)   \n\nlibrary(\"readxl\")\n\ncpopg &lt;- read_excel(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/cpopg_metadados.xlsx\")"
  },
  {
    "objectID": "outrosmodelos.html#modelos-com-variáveis-dependentes-qualitativasmodelo-de-probabilidade-linear-mpm-e-modelo-logit.",
    "href": "outrosmodelos.html#modelos-com-variáveis-dependentes-qualitativasmodelo-de-probabilidade-linear-mpm-e-modelo-logit.",
    "title": "8  Modelos Avançados",
    "section": "8.1 Modelos com Variáveis Dependentes Qualitativas:Modelo de Probabilidade Linear (MPM) e Modelo Logit.",
    "text": "8.1 Modelos com Variáveis Dependentes Qualitativas:Modelo de Probabilidade Linear (MPM) e Modelo Logit.\n\n8.1.1 Variáveis Dependentes Binárias\nExemplos de resultados binários: 1) Um consumidor compra ou não compra um produto. 2) Um juiz acata ou não um determinado pedido. 3) Um indíviduo decide ou não se vai procurar emprego ou não. 4) Um agricultor decide ou não se vai adotar um deterinado método de produção.\nVariável dependente binária: A variável de resultado será, \\(y = 1\\), se o evento de interesse ocorre, caso o contrario \\(y=0\\).\nOs modelos de Variáveis Dependentes Limitadas são bastante difundidos nas análises empiricas nas ciências sociais."
  },
  {
    "objectID": "outrosmodelos.html#variáveis-dependentes-limitadas-no-modelo-de-regressão-múltipla",
    "href": "outrosmodelos.html#variáveis-dependentes-limitadas-no-modelo-de-regressão-múltipla",
    "title": "8  Modelos Avançados",
    "section": "8.2 Variáveis Dependentes Limitadas no Modelo de Regressão Múltipla:",
    "text": "8.2 Variáveis Dependentes Limitadas no Modelo de Regressão Múltipla:\n\n8.2.1 O Modelo de Probabilidade Linear\nO modelo será especificado como \\[y= \\beta_0 + \\beta_1 x_1 + ... +\\beta_kx_k +u\\]\nO modelo acima estima a probabilidade do evento de interesse ocorrer dado as variáveis explicativas.\nEm notação matemática isso representado da seguinte maneira:\n\\[p=pr[y=1]=F(x^´ \\beta)\\]\nNo modelo de probabilidade linear \\[F(x^´ \\beta)= \\beta_0 + \\beta_1 x_1 + ... +\\beta_kx_k \\]\nOs coeficientes \\(\\beta_j\\) estimados indica o impacto na probabilidade de \\(y=1\\). No modelo MPL a estimação dos coeficientes é feita de maneira analoga ao modelo de RLM.\nVejamos um exemplo: Estudamos a probabilidade de uma mulher estar no mercado de trabalho dependendo das características sociodemográficas. O Script abaixo estima um modelo de probabilidade linear usando o conjunto de dados mroz.dta. O coeficiente estimado de educ pode ser interpretado como: um ano adicional de escolaridade aumenta a probabilidade de uma mulher estar na força de trabalho, tudo o mais constante, em 0,038, em média.\n\nlibrary(car)\n\nCarregando pacotes exigidos: carData\n\nlibrary(lmtest)\n\nCarregando pacotes exigidos: zoo\n\n\n\nAnexando pacote: 'zoo'\n\n\nOs seguintes objetos são mascarados por 'package:base':\n\n    as.Date, as.Date.numeric\n\ndata(mroz, package=\"wooldridge\")\n\n# Estimate linear probability model\nlinprob &lt;- lm(inlf~ nwifeinc + educ + exper + I(exper^2) + \n                  age+ kidslt6 + kidsge6,data=mroz)\n\nsummary(linprob)\n\n\nCall:\nlm(formula = inlf ~ nwifeinc + educ + exper + I(exper^2) + age + \n    kidslt6 + kidsge6, data = mroz)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.93432 -0.37526  0.08833  0.34404  0.99417 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.5855192  0.1541780   3.798 0.000158 ***\nnwifeinc    -0.0034052  0.0014485  -2.351 0.018991 *  \neduc         0.0379953  0.0073760   5.151 3.32e-07 ***\nexper        0.0394924  0.0056727   6.962 7.38e-12 ***\nI(exper^2)  -0.0005963  0.0001848  -3.227 0.001306 ** \nage         -0.0160908  0.0024847  -6.476 1.71e-10 ***\nkidslt6     -0.2618105  0.0335058  -7.814 1.89e-14 ***\nkidsge6      0.0130122  0.0131960   0.986 0.324415    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4271 on 745 degrees of freedom\nMultiple R-squared:  0.2642,    Adjusted R-squared:  0.2573 \nF-statistic: 38.22 on 7 and 745 DF,  p-value: &lt; 2.2e-16\n\n\nUm problema com o MPL é que \\(P(y = 1|x)\\) é especificado como uma função linear dos regressores. Por construção, existem combinações (mais ou menos realistas) de valores de regressores que produzem \\(\\hat{y} &lt; 0\\) ou \\(\\hat{y}&gt;0\\). Como são probabilidades, isso realmente não faz sentido.\nVeja que os valores previstos para duas mulheres: A mulher 1 tem 20 anos, não tem experiência profissional, 5 anos de escolaridade, dois filhos menores de 6 anos e renda familiar adicional de 100.000 USD. A mulher 2 tem 52 anos, 30 anos de experiência profissional, 17 anos de estudo, não tem filhos e não tem outra fonte de renda. A “probabilidade” prevista para a mulher 1 é de -41%, a probabilidade para a mulher 2 é de 104%, como também pode ser facilmente verificado com uma calculadora.\n\n#Preção para duas mulheres da base de dados\n\nxpred &lt;- list(nwifeinc=c(100,0),educ=c(5,17),exper=c(0,30),\n age=c(20,52),kidslt6=c(2,0),kidsge6=c(0,0))\n\npredict(linprob,xpred)\n\n         1          2 \n-0.4104582  1.0428084 \n\n\n#Modelo de Regressão Logistica: Logit\nNo modelo Logit a função linear é substituida pela função de distribuição acumulada logistica:\n\\[F(\\mathbf{x}'\\boldsymbol{\\beta}) = \\Lambda(\\mathbf{x}'\\boldsymbol{\\beta}) = \\frac{e^{\\mathbf{x}'\\boldsymbol{\\beta}}}{1 + e^{\\mathbf{x}'\\boldsymbol{\\beta}}} = \\frac{\\exp(\\mathbf{x}'\\boldsymbol{\\beta})}{1 + \\exp(\\mathbf{x}'\\boldsymbol{\\beta})}\n\\ \\]\nEmbora pareça complicada, a funçao logistica garante valores preditos \\(\\hat{y}\\) entre \\(0\\) e \\(1\\). Adcionalmente, diferente do MPL, que preve um efeito marginal constante, os efeitos marginais estimados pelo modelo Logit dependem das variáveis explicativas, \\(x\\).\nNo modelo Logit os efeitos parciais são dados por:\n\\[\\frac{\\partial \\hat{y}}{\\partial x_j} = \\hat{\\beta}_j \\lambda(\\mathbf{x}' \\hat{\\beta})\\] O facto de os efeitos parciais diferirem dado os valores dos regressores torna mais difícil apresentar os resultados de uma forma concisa e significativa. Uma maneira interessante é utilizar o efeito parcial médio:\nEfeito Parcial Médio:\n\\[\\text{APE} = \\frac{1}{n} \\sum_{i=1}^{n} \\hat{\\beta}_j \\cdot g(\\mathbf{x}_i \\hat{\\beta})\\] Outro ponto a ser destacado no modelo Logit é a razão de chances ou risco relativo, \\(p/(1-p)\\), que mede a probabilidade de \\(y=1\\) em relação à probabilidade de \\(y=0\\).\nUma razão de chances de 2 significa que o resultado \\(y=1\\) é duas vezes mais provável que o resultado de \\(y=0\\).\nA razão de chances é dada por:\n\\(\\frac{p}{1 - p} = \\exp(\\mathbf{x}' \\boldsymbol{\\beta})\\)\nVoltemos ao exemplo anterior\n\ndata(mroz, package=\"wooldridge\")\n\n# Estimate logit model\n\nlogitres&lt;-glm(inlf~nwifeinc + educ + exper + I(exper^2) +\n                age + kidslt6 + kidsge6,\n              family=binomial(link=logit), data=mroz)\n\n# Sumario dos resutados:\nsummary(logitres)\n\n\nCall:\nglm(formula = inlf ~ nwifeinc + educ + exper + I(exper^2) + age + \n    kidslt6 + kidsge6, family = binomial(link = logit), data = mroz)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.425452   0.860365   0.495  0.62095    \nnwifeinc    -0.021345   0.008421  -2.535  0.01126 *  \neduc         0.221170   0.043439   5.091 3.55e-07 ***\nexper        0.205870   0.032057   6.422 1.34e-10 ***\nI(exper^2)  -0.003154   0.001016  -3.104  0.00191 ** \nage         -0.088024   0.014573  -6.040 1.54e-09 ***\nkidslt6     -1.443354   0.203583  -7.090 1.34e-12 ***\nkidsge6      0.060112   0.074789   0.804  0.42154    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1029.75  on 752  degrees of freedom\nResidual deviance:  803.53  on 745  degrees of freedom\nAIC: 819.53\n\nNumber of Fisher Scoring iterations: 4\n\n#Calculation os valores preditos individuaiss:\nxb.log &lt;- predict(logitres)\n\n\n# APE factors = media(g(xb))\nfactor.log &lt;- mean( dlogis(xb.log) )\nfactor.log\n\n[1] 0.1785796\n\n#multiplicando pelos coeficientes \nAPE.log &lt;- coef(logitres) * factor.log\nAPE.log\n\n  (Intercept)      nwifeinc          educ         exper    I(exper^2) \n 0.0759771297 -0.0038118135  0.0394965238  0.0367641056 -0.0005632587 \n          age       kidslt6       kidsge6 \n-0.0157193606 -0.2577536551  0.0107348186 \n\n# Calculando a odds ratios \nexp(logitres$coefficients)\n\n(Intercept)    nwifeinc        educ       exper  I(exper^2)         age \n  1.5302825   0.9788810   1.2475360   1.2285929   0.9968509   0.9157386 \n    kidslt6     kidsge6 \n  0.2361344   1.0619557 \n\n\nOs valores são os efeitos marginais médios na probabilidade de uma mulher participar da força de trabalho. Na média, um ano adicional de estudo contribui cerca de 4% na probabilidade da mulher participar da força de trabalho."
  },
  {
    "objectID": "outrosmodelos.html#dados-de-contagem",
    "href": "outrosmodelos.html#dados-de-contagem",
    "title": "8  Modelos Avançados",
    "section": "8.2 Dados de Contagem:",
    "text": "8.2 Dados de Contagem:\n\n8.2.1 Modelo de Regressão de Poisson\nEm vez de apenas dados binários codificados em \\(0/1\\), os dados de contagem podem assumir qualquer número inteiro não negativo $0,1,2,. . $. Se considerarem números muito grandes (como o número de alunos numa escola), podem ser aproximados razoavelmente bem como variáveis contínuas em modelos lineares e estimados utilizando MQO. Se os números forem relativamente pequenos (como o número de filhos de uma mãe), esta aproximação pode não funcionar bem. Por exemplo, os valores previstos podem tornar-se negativos.\nO modelo de regressão de Poisson é o modelo mais básico e conveniente projetado explicitamente para dados de contagem. A probabilidade de y assumir qualquer valor \\(h \\in \\{0,1,2,..\\}\\)este modelo pode ser escrito como\n\\[P(y = h \\mid x) = \\frac{e^{-e^{\\mathbf{x} \\boldsymbol{\\beta}}} (e^{\\mathbf{x} \\boldsymbol{\\beta}})^h}{h!}\\]\nOs parâmetros do modelo de Poisson são muito mais fáceis de interpretar do que os de um modelo probit ou logit. Neste modelo, a média condicional de y é\n\\[E(y \\mid x) = e^{\\mathbf{x} \\boldsymbol{\\beta}}\\] então cada parâmetro de inclinação \\(\\beta_j\\) tem a interpretação de uma semielasticidade:\n\\[\\frac{\\partial E(y \\mid x)}{\\partial x_j} = \\beta_j \\cdot e^{\\mathbf{x} \\boldsymbol{\\beta}} = \\beta_j \\cdot E(y \\mid x)\\] Logo,\n\\[\\beta_j = \\frac{1}{E(y \\mid x)} \\cdot \\frac{\\partial E(y \\mid x)}{\\partial x_j}\\]\nSe \\(x_j\\) aumentar em uma unidade (e os outros regressores permanecerem os mesmos), \\(E(y|x)\\) aumentará aproximadamente em \\(100 \\cdot \\beta_j\\) por cento (o valor exato é novamente \\(100 \\cdot (e^{\\beta_j} - 1)\\)).\nEstimar modelos de regressão de Poisson em R é simples. Eles também pertencem à classe dos modelos lineares generalizados (GLM) e podem ser estimados usando glm. A opção para especificar um modelo de Poisson é family=poisson.\nVejamos um exemplo que analisa o número de prisões masculinas em 1986.\n\ndata(crime1, package=\"wooldridge\")\n\n#Estimando o modelo de Poisson\nPoisson.res &lt;- glm(narr86~pcnv+avgsen+tottime+ptime86+qemp86+inc86+\nblack+hispan+born60, data=crime1, family=poisson)\n\nlibrary(stargazer)\n\n\nPlease cite as: \n\n\n Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n\n\n R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n\nstargazer(Poisson.res,type=\"text\",keep.stat=\"n\")\n\n\n========================================\n                 Dependent variable:    \n             ---------------------------\n                       narr86           \n----------------------------------------\npcnv                  -0.402***         \n                       (0.085)          \n                                        \navgsen                 -0.024           \n                       (0.020)          \n                                        \ntottime                0.024*           \n                       (0.015)          \n                                        \nptime86               -0.099***         \n                       (0.021)          \n                                        \nqemp86                 -0.038           \n                       (0.029)          \n                                        \ninc86                 -0.008***         \n                       (0.001)          \n                                        \nblack                 0.661***          \n                       (0.074)          \n                                        \nhispan                0.500***          \n                       (0.074)          \n                                        \nborn60                 -0.051           \n                       (0.064)          \n                                        \nConstant              -0.600***         \n                       (0.067)          \n                                        \n----------------------------------------\nObservations            2,725           \n========================================\nNote:        *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01"
  },
  {
    "objectID": "outrosmodelos.html#modelo-com-dados-em-painel",
    "href": "outrosmodelos.html#modelo-com-dados-em-painel",
    "title": "8  Modelos Avançados",
    "section": "8.3 Modelo com Dados em Painel:",
    "text": "8.3 Modelo com Dados em Painel:\n\n8.3.1 Modelos de Efeitos Fixos\nDados em painel são extremamente importantes na análise econométrica porque permitem o estudo de variáveis ao longo do tempo e entre diferentes indivíduos ou entidades, como empresas ou países. Esse tipo de dados oferece mais informações, variabilidade e eficiência do que séries temporais ou dados cross-section isoladamente, permitindo uma melhor compreensão das dinâmicas subjacentes e das relações causais.\nO estimador de efeitos fixos é uma técnica crucial para lidar com o viés de heterogeneidade, que surge quando características não observáveis e invariantes no tempo influenciam as variáveis de interesse. Ao considerar apenas as variações dentro de cada indivíduo ao longo do tempo, o estimador de efeitos fixos controla essas características não observáveis, eliminando seu impacto sobre os estimadores dos coeficientes. Dessa forma, permite uma estimativa não enviesada dos efeitos das variáveis explicativas, proporcionando resultados mais robustos e confiáveis.\nConsidere o modelo mais simples de T períodos.\n\\(y_{it} = \\beta_0 + \\beta_1 x_{it1} + \\beta_2 x_{it2} + \\cdots + \\beta_k x_{itk} + a_i + u_{it}\\)\nNote que temos agora 3 subscritos, \\(i\\),\\(t\\) e \\(k\\). O subscrito \\(i\\) é a unidade de corte transversal, \\(t\\) representa o periodo dessa variável, e \\(k\\) a variável que estamos obversando. Nessa equação temos um termo \\(a_i\\). Esse termo \\(a_i\\) é denominado efeito fixo, pois é invariante no tempo. Ele capta fatores uma série de fatores individuais não observados que impactam \\(y\\) mas que são invariantes no tempo. Se aplicarmos o método de MQO na equação acima, termeos estimadores viesados e inconsistentes. Logo, precisamos remover esse efeito fixo. Uma forma de resolver isso é subtrair a média de cada variável para cada individuo ao longo do tempo. É então aplicar o MQO. Como \\(a_i\\) é invariante sua média também é \\(a_i\\), e ao realizarmos a subtração removeremos o efeito fixo.\n\\(\\bar{y_i} = \\beta_0 + \\beta_1 \\bar{x}_{i1} + \\cdots + \\beta_k \\bar{x}_{ik} + a_i + \\bar{u}_i\\)\nO modelo transfromado é dado por:\n\\[\\ddot{y}_{it} = y_{it} - \\bar{y}_i = \\beta_1 \\ddot{x}_{it1} + \\cdots + \\beta_k \\ddot{x}_{itk} + \\ddot{u}_{it}\\]\nModelo simples de 2 períodos.No exemplo abaixo utilizaremos dados de criminalidade e desemprego para 46 cidades americanas, etre 1982 e 1987.\n\nlibrary(plm)\ndata(crime2, package=\"wooldridge\")\ncrime2.p &lt;- pdata.frame(crime2, index=46 )\n\n##Estimando o modelo\nPainel&lt;- plm(crmrte~unem + d87, data=crime2.p, model=\"within\")\nsummary(Painel)\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = crmrte ~ unem + d87, data = crime2.p, model = \"within\")\n\nBalanced Panel: n = 46, T = 2, N = 92\n\nResiduals:\n   Min. 1st Qu.  Median 3rd Qu.    Max. \n-26.458  -6.384   0.000   6.384  26.458 \n\nCoefficients:\n     Estimate Std. Error t-value Pr(&gt;|t|)   \nunem  2.21800    0.87787  2.5266  0.01519 * \nd87  15.40220    4.70212  3.2756  0.00206 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    11002\nResidual Sum of Squares: 8844.8\nR-Squared:      0.19606\nAdj. R-Squared: -0.66269\nF-statistic: 5.36528 on 2 and 44 DF, p-value: 0.0082206\n\n\nVejamos um exemplo:\nTemos 545 indivíduos ao longo de 8 anos (1981 - 1987). Queremos verificar se o retorno da educação mudou ao longo do tempo. Como a educação \\(educ\\) não muda ao longo do tempo, não podemos estimar seu impacto geral. No entanto, podemos interagir ela com variáveis dummy de tempo para ver como o impacto muda ao longo do tempo.\n\nlibrary(plm)\n\n data(wagepan, package=\"wooldridge\")\n \n # Generate pdata.frame:\nwagepan.p &lt;- pdata.frame(wagepan, index=c(\"nr\",\"year\") )\n pdim(wagepan.p)\n\nBalanced Panel: n = 545, T = 8, N = 4360\n\n # Estimate FE model\nPainel2 &lt;- plm(lwage~married+union+factor(year)*educ,\n data=wagepan.p, model=\"within\") \n\nsummary(Painel2)\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = lwage ~ married + union + factor(year) * educ, \n    data = wagepan.p, model = \"within\")\n\nBalanced Panel: n = 545, T = 8, N = 4360\n\nResiduals:\n     Min.   1st Qu.    Median   3rd Qu.      Max. \n-4.152111 -0.125630  0.010897  0.160800  1.483401 \n\nCoefficients:\n                        Estimate Std. Error t-value  Pr(&gt;|t|)    \nmarried                0.0548205  0.0184126  2.9773  0.002926 ** \nunion                  0.0829785  0.0194461  4.2671 2.029e-05 ***\nfactor(year)1981      -0.0224158  0.1458885 -0.1537  0.877893    \nfactor(year)1982      -0.0057611  0.1458558 -0.0395  0.968495    \nfactor(year)1983       0.0104297  0.1458579  0.0715  0.942999    \nfactor(year)1984       0.0843743  0.1458518  0.5785  0.562965    \nfactor(year)1985       0.0497253  0.1458602  0.3409  0.733190    \nfactor(year)1986       0.0656064  0.1458917  0.4497  0.652958    \nfactor(year)1987       0.0904448  0.1458505  0.6201  0.535216    \nfactor(year)1981:educ  0.0115854  0.0122625  0.9448  0.344827    \nfactor(year)1982:educ  0.0147905  0.0122635  1.2061  0.227872    \nfactor(year)1983:educ  0.0171182  0.0122633  1.3959  0.162830    \nfactor(year)1984:educ  0.0165839  0.0122657  1.3521  0.176437    \nfactor(year)1985:educ  0.0237085  0.0122738  1.9316  0.053479 .  \nfactor(year)1986:educ  0.0274123  0.0122740  2.2334  0.025583 *  \nfactor(year)1987:educ  0.0304332  0.0122723  2.4798  0.013188 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    572.05\nResidual Sum of Squares: 474.35\nR-Squared:      0.1708\nAdj. R-Squared: 0.048567\nF-statistic: 48.9069 on 16 and 3799 DF, p-value: &lt; 2.22e-16"
  },
  {
    "objectID": "outrosmodelos.html#modelos-com-variáveis-dependentes-qualitativas",
    "href": "outrosmodelos.html#modelos-com-variáveis-dependentes-qualitativas",
    "title": "8  Modelos Avançados",
    "section": "8.1 Modelos com Variáveis Dependentes Qualitativas",
    "text": "8.1 Modelos com Variáveis Dependentes Qualitativas\n\n8.1.1 Variáveis Dependentes Binárias\nExemplos de resultados binários:\n\nUm consumidor compra ou não compra um produto.\nUm juiz acata ou não um determinado pedido.\nUm indíviduo decide ou não se vai procurar emprego.\nUm homicídio feminino é classificado como feminicídio ou não.\n\nVariável dependente binária:\nA variável de resultado será, \\(y = 1\\), se o evento de interesse ocorre, caso o contrario \\(y=0\\). Os modelos de Variáveis Dependentes Limitadas são bastante difundidos nas análises empíricas nas ciências sociais.\n\n\n8.1.2 O Modelo de Probabilidade Linear\nO modelo será especificado como:\n\\[y= \\beta_0 + \\beta_1 x_1 + ... +\\beta_kx_k +u\\]\nO modelo acima estima a probabilidade do evento de interesse ocorrer dado as variáveis explicativas. Em notação matemática pode ser representado da seguinte maneira:\n\\[p=Pr(Y=1)=F(\\mathbf{x}'\\boldsymbol{\\beta})\\]\nNo modelo de probabilidade linear:\n\\[p=Pr(Y=1)=F(\\mathbf{x}'\\boldsymbol{\\beta})= \\beta_0 + \\beta_1 x_1 + ... +\\beta_kx_k \\]\nOs coeficientes \\(\\beta_j\\) estimados indicam o impacto na probabilidade de \\(Y=1\\). No modelo MPL a estimação dos coeficientes são feitas de maneira análoga ao modelo de RLM.\nVejamos um exemplo:\n\nEstudamos a probabilidade de uma mulher estar no mercado de trabalho \\(P(inlf=1)\\)\n\n\\[P(\\text{inlf}=1)= \\beta_0 + \\beta_1 \\text{nwifeinc} + \\beta_2 \\text{edu} +\\beta_3 \\text{exp}+\\] \\[\\beta_4 \\text{exp}^2+\\beta_5 \\text{age}+\\beta_6 \\text{kidslt6}+\\beta_7 \\text{kidsge6} +\\epsilon\\]\n\nDependendo da renda familiar adicional (nwifeinc), da educação (educ), da experiência (exper e exper^2), da sua idade (age), do número de crianças menores de 6 anos (kidslt6) e do número de crianças maiores do que 6 anos (kidsge6).\n\nO Script abaixo estima um modelo de probabilidade linear usando o conjunto de dados mroz.dta, da mesma forma que fizemos anteriormente (usando o lm). Vejamos:\n\nif(!require(wooldridge)){\n    install.packages(\"wooldridge\")\n    library(wooldridge)}\n\nlibrary(car)\nlibrary(lmtest)\n\ndata(mroz, package=\"wooldridge\")\n\n# Estimate linear probability model\nlinprob &lt;- lm(inlf~ nwifeinc + educ + exper + I(exper^2) + \n                  age+ kidslt6 + kidsge6 ,data=mroz)\n\nsummary(linprob)\n\n\nCall:\nlm(formula = inlf ~ nwifeinc + educ + exper + I(exper^2) + age + \n    kidslt6 + kidsge6, data = mroz)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.93432 -0.37526  0.08833  0.34404  0.99417 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.5855192  0.1541780   3.798 0.000158 ***\nnwifeinc    -0.0034052  0.0014485  -2.351 0.018991 *  \neduc         0.0379953  0.0073760   5.151 3.32e-07 ***\nexper        0.0394924  0.0056727   6.962 7.38e-12 ***\nI(exper^2)  -0.0005963  0.0001848  -3.227 0.001306 ** \nage         -0.0160908  0.0024847  -6.476 1.71e-10 ***\nkidslt6     -0.2618105  0.0335058  -7.814 1.89e-14 ***\nkidsge6      0.0130122  0.0131960   0.986 0.324415    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4271 on 745 degrees of freedom\nMultiple R-squared:  0.2642,    Adjusted R-squared:  0.2573 \nF-statistic: 38.22 on 7 and 745 DF,  p-value: &lt; 2.2e-16\n\n\nInterpretação\nO coeficiente estimado da educação (educ) pode ser interpretado como: um ano adicional de escolaridade aumenta a probabilidade de uma mulher estar na força de trabalho, tudo o mais constante, em 0,038, em média.\nO Problema\nUm problema com o MPL é que \\(P(y = 1|x)\\) é especificado como uma função linear dos regressores. Por construção, existem combinações (mais ou menos realistas) de valores de regressores que produzem \\(\\hat{y} &lt; 0\\) ou \\(\\hat{y}&gt;0\\). Como são probabilidades, isso realmente não faz sentido.\nVeja que os valores previstos para duas mulheres:\n\nMULHER 1: renda familiar adicional de 50 mil ano, 7 anos de escolaridade, não tem experiência, com 25 anos e possui 2 filhos menores de 6 anos. A probabilidade de estar na força de trabalho estimada é -24%….não faz sentido.\n\n\n# Podemos calcular assim a probabilidade \n\n0.5855192 - 0.0034052*50  + 0.0379953*7  + 0.0394924*0  -0.0005963*0  - 0.0160908*25  -0.2618105*2  + 0.0130122*0\n\n[1] -0.2446647\n\n# Ou assim: \n\nxpred &lt;- list(nwifeinc=c(50),educ=c(7),exper=c(0), \"I(exper^2)\"=c(0),\n age=c(25),kidslt6=c(2),kidsge6=c(0))\n\npredict(linprob,xpred)\n\n         1 \n-0.2446632 \n\n\n\nMULHER 2: Não tem renda adicional, 17 anos de escolaridade, 30 anos de experiência, com 52 anos e não possui filhos. A probabilidade de estar na força de trabalho estimada é 104%….não faz sentido. Veja os cálculos abaixo:\n\n\n# Podemos calcular assim a probabilidade \n\n0.5855192 - 0.0034052*0  + 0.0379953*17  + 0.0394924*30  -0.0005963*900  - 0.0160908*52  -0.2618105*0  + 0.0130122*0\n\n[1] 1.04282\n\n#Preção para duas mulheres da base de dados\n\nxpred1 &lt;- list(nwifeinc=c(0),educ=c(17), exper=c(30), \"I(exper^2)\"=c(30),\n age=c(52),kidslt6=c(0),kidsge6=c(0))\n\npredict(linprob,xpred1)\n\n       1 \n1.042808 \n\n\n\n\n8.1.3 Modelo de Regressão Logistica: Logit\nNo modelo Logit a função linear é substituida pela função de distribuição acumulada logistica:\n\\[ Pr(Y_i=1)=F(\\mathbf{x}'\\boldsymbol{\\beta})=\\text{Logit}^{-1}(\\mathbf{x}'\\boldsymbol{\\beta})\\]\nOu\n\\[\\text{Logit}^{-1}(\\mathbf{x}'\\boldsymbol{\\beta}) = \\frac{\\exp(\\mathbf{x}'\\boldsymbol{\\beta})}{1 + \\exp(\\mathbf{x}'\\boldsymbol{\\beta})}\n\\ \\]\nAssumindo que:\n\\[log \\left( \\frac{P_t}{1-P_t}\\right)=\\mathbf{X}`\\beta\\]\nResolvendo para \\(P_t\\), tem-se que:\n\\[ Pr(Y_i=1)=F(\\mathbf{x}'\\boldsymbol{\\beta}) = \\frac{\\exp(\\mathbf{x}'\\boldsymbol{\\beta})}{1 + \\exp(\\mathbf{x}'\\boldsymbol{\\beta})}\\]\nPortanto, o resultado do modelo logístico fornece o efeito da variação de uma unidade em \\(X\\) no log da razão de chances entre as probabilidades \\(Y=1\\) e \\(Y=0\\). Infelizmente a interpretação direta não nos traz uma leitura significativa do que está acontecendo nessa população.\nDuas maneiras para analisarmos o resultados são:\nRazão de Chance\nA razão de chances ou risco relativo, \\(p/(1-p)\\), mede a probabilidade de \\(y=1\\) em relação à probabilidade de \\(y=0\\).\nUma razão de chances de 2 significa que o resultado \\(y=1\\) (de ganhar uma aposta, por exemplo) é duas vezes mais provável que o resultado de \\(y=0\\) (de perder uma aposta).\nA razão de chances é dada por:\n\\[\\frac{p}{1 - p} = \\exp(\\mathbf{x}' \\boldsymbol{\\beta})\\]\nEfeito Marginal:\nOutra maneira é encontrar o efeito marginal do estimador, que irá fornecer a seguinte interpretação, um aumento em \\(X\\) aumenta(diminui) em \\(\\beta\\) pontos percentuais a probabilidade de ser \\(Y=1\\). Vejamos os exemplos abaixo para ficar um pouco mais claro.\n\n8.1.3.1 Exemplo e interpretação\nPrimeiramente vamos estimar o modelo logit. Usamos a mesma base que indica se a mulher está na força de trabalho \\((Y=1)\\) ou se a mulher está fora da força de trabalho \\((Y=0)\\), variável inlf.\n\ndata(mroz, package=\"wooldridge\")\n\n#Modelo logit, familia da binomial = logit\nlogit &lt;- glm(inlf~ nwifeinc + educ + exper + I(exper^2) + \n                  age+ kidslt6 + kidsge6 , family=binomial(link=\"logit\"), data=mroz)\nsummary(logit)\n\n\nCall:\nglm(formula = inlf ~ nwifeinc + educ + exper + I(exper^2) + age + \n    kidslt6 + kidsge6, family = binomial(link = \"logit\"), data = mroz)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.425452   0.860365   0.495  0.62095    \nnwifeinc    -0.021345   0.008421  -2.535  0.01126 *  \neduc         0.221170   0.043439   5.091 3.55e-07 ***\nexper        0.205870   0.032057   6.422 1.34e-10 ***\nI(exper^2)  -0.003154   0.001016  -3.104  0.00191 ** \nage         -0.088024   0.014573  -6.040 1.54e-09 ***\nkidslt6     -1.443354   0.203583  -7.090 1.34e-12 ***\nkidsge6      0.060112   0.074789   0.804  0.42154    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1029.75  on 752  degrees of freedom\nResidual deviance:  803.53  on 745  degrees of freedom\nAIC: 819.53\n\nNumber of Fisher Scoring iterations: 4\n\n\nA coluna Estimate mostra os coeficientes na forma de log da razão de chance. Quando a educação da mulher aumenta em uma unidade, a mudança esperada no log da razão de chance é de 0,22. Pode-se interpretar se os efeitos são positivos ou negativos, mas sua análise não é significativa. Aqui sabe-se que a educação tem efeito positivo na participação da mulher no mercado de trabalho, mas não sabemos de quanto!\nRazão de Chance\nVamos agora calcular a razão de chance. Utilizaremos o pacote mfx\n\n# Usando o pacote mfx\nif(!require(mfx)){\n    install.packages(\"mfx\")\n    library(mfx)}\n\n\nlogitor(inlf~ nwifeinc + educ + exper + I(exper^2) + \n                  age+ kidslt6 + kidsge6, data=mroz)\n\nCall:\nlogitor(formula = inlf ~ nwifeinc + educ + exper + I(exper^2) + \n    age + kidslt6 + kidsge6, data = mroz)\n\nOdds Ratio:\n           OddsRatio Std. Err.       z     P&gt;|z|    \nnwifeinc   0.9788810 0.0082435 -2.5346  0.011256 *  \neduc       1.2475360 0.0541921  5.0915 3.553e-07 ***\nexper      1.2285929 0.0393847  6.4220 1.345e-10 ***\nI(exper^2) 0.9968509 0.0010129 -3.1041  0.001909 ** \nage        0.9157386 0.0133450 -6.0403 1.538e-09 ***\nkidslt6    0.2361344 0.0480729 -7.0898 1.343e-12 ***\nkidsge6    1.0619557 0.0794229  0.8038  0.421539    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# OU\n\nlogit.or=exp(coef(logit))\nlogit.or\n\n(Intercept)    nwifeinc        educ       exper  I(exper^2)         age \n  1.5302825   0.9788810   1.2475360   1.2285929   0.9968509   0.9157386 \n    kidslt6     kidsge6 \n  0.2361344   1.0619557 \n\n\nInterpretação\nQuando a educação da mulher aumenta em uma unidade, as chances de y = 1 (dela participar do mercado de trabalho) aumentam em 24% ((1,247-1)*100). Ou a probabilidade de participar do mercado de trabalho (y = 1) é 1,24 vezes maior quando a educação aumenta em uma unidade (mantendo todas as outras variáveis constante).\nEfeito Marginal\nUtilizando o mesmo pacote anterior mfx, tem-se:\n\nlogitmfx(inlf~ nwifeinc + educ + exper + I(exper^2) + \n                  age+ kidslt6 + kidsge6, data=mroz)\n\nCall:\nlogitmfx(formula = inlf ~ nwifeinc + educ + exper + I(exper^2) + \n    age + kidslt6 + kidsge6, data = mroz)\n\nMarginal Effects:\n                 dF/dx   Std. Err.       z     P&gt;|z|    \nnwifeinc   -0.00519005  0.00204820 -2.5340  0.011278 *  \neduc        0.05377731  0.01056074  5.0922 3.539e-07 ***\nexper       0.05005693  0.00782462  6.3974 1.581e-10 ***\nI(exper^2) -0.00076692  0.00024768 -3.0965  0.001959 ** \nage        -0.02140302  0.00353973 -6.0465 1.480e-09 ***\nkidslt6    -0.35094982  0.04963897 -7.0700 1.549e-12 ***\nkidsge6     0.01461621  0.01818832  0.8036  0.421625    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nInterpretação\nOs efeitos marginais mostram a mudança na probabilidade quando \\(X\\) aumenta em uma unidade. No nosso caso o aumento de 1 ano na educação da mulher aumenta em 0.053 pontos percentuais a probabilidade de a mulher participar do mercado de trabalho, \\(Pr(Y=1)\\). A probabilidade aqui é um valor entre 0 e 1.\nCalculando a Probabilidade\nVamos calcular a probabilidade de uma mulher participar do mercado de trabalho. Predizendo a probabilidade:\n\nlogit &lt;- glm(inlf~ nwifeinc + educ + exper + expersq + \n                  age+ kidslt6 + kidsge6, family=binomial(link=\"logit\"), data=mroz)\n\n# temos que fazer o inverso do modelo logit\n\ninvlogit=function (x) {1/(1+exp(-x))}\ninvlogit(coef(logit)[1]+\n           coef(logit)[2]*mean(mroz$nwifeinc)+\n           coef(logit)[3]*mean(mroz$educ)+\n           coef(logit)[4]*mean(mroz$exper)+\n           coef(logit)[5]*mean(mroz$expersq)+\n           coef(logit)[6]*mean(mroz$age)+\n           coef(logit)[7]*mean(mroz$kidslt6)+\n           coef(logit)[8]*mean(mroz$kidsge6))\n\n(Intercept) \n   0.582772 \n\n\nEm média 58% das mulheres participam do mercado de trabalho. Vejamos agora para o caso das duas mulheres que haviamos feito anteriormente:\n\nMULHER 1: renda familiar adicional de 50 mil ano, 7 anos de escolaridade, não tem experiência, com 25 anos e possui 2 filhos menores de 6 anos.\n\n\n# Mulher 1\ninvlogit=function (x) {1/(1+exp(-x))}\ninvlogit(coef(logit)[1]+\n           coef(logit)[2]*50+\n           coef(logit)[3]*7+\n           coef(logit)[4]*0+\n           coef(logit)[5]*0+\n           coef(logit)[6]*25+\n           coef(logit)[7]*2+\n           coef(logit)[8]*0)\n\n(Intercept) \n 0.01505417 \n\n\nA chance da mulher descrita acima participar do mercado de trabalho é de 1,5%.\n\nMULHER 2: Não tem renda adicional, 17 anos de escolaridade, 30 anos de experiência, com 52 anos e não possui filhos.\n\n\n# Mulher 1\ninvlogit=function (x) {1/(1+exp(-x))}\ninvlogit(coef(logit)[1]+\n           coef(logit)[2]*0+\n           coef(logit)[3]*17+\n           coef(logit)[4]*30+\n           coef(logit)[5]*900+\n           coef(logit)[6]*52+\n           coef(logit)[7]*0+\n           coef(logit)[8]*0)\n\n(Intercept) \n  0.9500491 \n\n\nA chance da Mulher 2 participar do mercado de trabalho é de 95% .\n\n\n8.1.3.2 Probit\nUma alternativa ao modelo logit seria o uso do modelo probit. Que ao invés da função logística utiliza-se a função distribuição normal padrão. Vejamos os resultados:\n\ndata(mroz, package=\"wooldridge\")\n\n#Modelo logit, familia da binomial = logit\nprobit &lt;- glm(inlf~ nwifeinc + educ + exper + I(exper^2) + \n                  age+ kidslt6 + kidsge6 , family=binomial(link=\"probit\"), data=mroz)\nsummary(logit)\n\n\nCall:\nglm(formula = inlf ~ nwifeinc + educ + exper + expersq + age + \n    kidslt6 + kidsge6, family = binomial(link = \"logit\"), data = mroz)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.425452   0.860365   0.495  0.62095    \nnwifeinc    -0.021345   0.008421  -2.535  0.01126 *  \neduc         0.221170   0.043439   5.091 3.55e-07 ***\nexper        0.205870   0.032057   6.422 1.34e-10 ***\nexpersq     -0.003154   0.001016  -3.104  0.00191 ** \nage         -0.088024   0.014573  -6.040 1.54e-09 ***\nkidslt6     -1.443354   0.203583  -7.090 1.34e-12 ***\nkidsge6      0.060112   0.074789   0.804  0.42154    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1029.75  on 752  degrees of freedom\nResidual deviance:  803.53  on 745  degrees of freedom\nAIC: 819.53\n\nNumber of Fisher Scoring iterations: 4\n\nsummary(probit)\n\n\nCall:\nglm(formula = inlf ~ nwifeinc + educ + exper + I(exper^2) + age + \n    kidslt6 + kidsge6, family = binomial(link = \"probit\"), data = mroz)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.2700736  0.5080782   0.532  0.59503    \nnwifeinc    -0.0120236  0.0049392  -2.434  0.01492 *  \neduc         0.1309040  0.0253987   5.154 2.55e-07 ***\nexper        0.1233472  0.0187587   6.575 4.85e-11 ***\nI(exper^2)  -0.0018871  0.0005999  -3.145  0.00166 ** \nage         -0.0528524  0.0084624  -6.246 4.22e-10 ***\nkidslt6     -0.8683247  0.1183773  -7.335 2.21e-13 ***\nkidsge6      0.0360056  0.0440303   0.818  0.41350    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1029.7  on 752  degrees of freedom\nResidual deviance:  802.6  on 745  degrees of freedom\nAIC: 818.6\n\nNumber of Fisher Scoring iterations: 4\n\n\nObserve que sinal e significância estão em acordo entre os dois modelos. Vejamos agora os efeitos marginais para podermos comparar.\n\nlogitmfx(inlf~ nwifeinc + educ + exper + I(exper^2) + \n                  age+ kidslt6 + kidsge6, data=mroz)\n\nCall:\nlogitmfx(formula = inlf ~ nwifeinc + educ + exper + I(exper^2) + \n    age + kidslt6 + kidsge6, data = mroz)\n\nMarginal Effects:\n                 dF/dx   Std. Err.       z     P&gt;|z|    \nnwifeinc   -0.00519005  0.00204820 -2.5340  0.011278 *  \neduc        0.05377731  0.01056074  5.0922 3.539e-07 ***\nexper       0.05005693  0.00782462  6.3974 1.581e-10 ***\nI(exper^2) -0.00076692  0.00024768 -3.0965  0.001959 ** \nage        -0.02140302  0.00353973 -6.0465 1.480e-09 ***\nkidslt6    -0.35094982  0.04963897 -7.0700 1.549e-12 ***\nkidsge6     0.01461621  0.01818832  0.8036  0.421625    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nprobitmfx(inlf~ nwifeinc + educ + exper + I(exper^2) + \n                  age+ kidslt6 + kidsge6, data=mroz)\n\nCall:\nprobitmfx(formula = inlf ~ nwifeinc + educ + exper + I(exper^2) + \n    age + kidslt6 + kidsge6, data = mroz)\n\nMarginal Effects:\n                 dF/dx   Std. Err.       z     P&gt;|z|    \nnwifeinc   -0.00469619  0.00192965 -2.4337  0.014945 *  \neduc        0.05112843  0.00992310  5.1525 2.571e-07 ***\nexper       0.04817690  0.00734505  6.5591 5.413e-11 ***\nI(exper^2) -0.00073705  0.00023464 -3.1412  0.001683 ** \nage        -0.02064309  0.00330485 -6.2463 4.203e-10 ***\nkidslt6    -0.33914996  0.04634765 -7.3175 2.526e-13 ***\nkidsge6     0.01406306  0.01719895  0.8177  0.413546    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nO aumento de 1 ano na educação da mulher aumenta em 0.053 pontos percentuais a probabilidade de a mulher participar do mercado de trabalho, \\(Pr(Y=1)\\), no modelo logit e 0.051 no modelo probit. As diferenças são pequenas entre os dois modelos."
  }
]