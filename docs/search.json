[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jurimetria",
    "section": "",
    "text": "1 Prefácio"
  },
  {
    "objectID": "index.html#nossa-motivação",
    "href": "index.html#nossa-motivação",
    "title": "Jurimetria",
    "section": "1.1 Nossa Motivação:",
    "text": "1.1 Nossa Motivação:\nEsse curso foi criado pensando em profissionais com formação em direito, estatística, tecnologia da informação e demais profissionais que atuam tanto no judiciário quanto em tribunais administrativos. A ideia é colocar juntas diversas visões sobre um mesmo problema para buscarmos soluções mais criativas e eficicientes para as desigualdades nacionais."
  },
  {
    "objectID": "index.html#nosso-objetivo",
    "href": "index.html#nosso-objetivo",
    "title": "Jurimetria",
    "section": "1.2 Nosso Objetivo:",
    "text": "1.2 Nosso Objetivo:\nÉ oferecer aos participantes uma abordagem probabilística do direito aplicado, tendo como foco os casos práticos e discutindo questões relativas ao direito e desigualdades. Especificamente, objetiva-se ensinar um conjunto de métodos quantitativos e oferecer ferramentas para coleta, transformação e análise de dados jurídicos disponibilizados nas páginas dos tribunais de justiça."
  },
  {
    "objectID": "index.html#nosso-problema",
    "href": "index.html#nosso-problema",
    "title": "Jurimetria",
    "section": "1.3 Nosso Problema:",
    "text": "1.3 Nosso Problema:\nTeremos como tema de fundo nesse curso os processos de homicídio feminino. Especificamente queremos compreender qual o perfil e os determinantes do feminicidio no Estado de São Paulo."
  },
  {
    "objectID": "summary.html#resumo",
    "href": "summary.html#resumo",
    "title": "2  Sumário do Curso",
    "section": "2.1 Resumo:",
    "text": "2.1 Resumo:\nA pesquisa no direito e a ciência de dados: introdução, relevância e experiências; Coleta, transformação e estruturação de dados processuais com R; Estatística descritiva; Aprendizado estatístico (regressão linear, regressão logística); Aprendizado estatístico (machine learning); Interpretação dos resultados e elaboração de relatório."
  },
  {
    "objectID": "summary.html#plano-detalhado-das-aulas",
    "href": "summary.html#plano-detalhado-das-aulas",
    "title": "2  Sumário do Curso",
    "section": "2.2 Plano detalhado das aulas:",
    "text": "2.2 Plano detalhado das aulas:\n\nA pesquisa no direito e a ciência de dados: introdução, relevância e experiências - 25/04\nColeta, transformação e estruturação de dados processuais com R - 02/05\nColeta, transformação e estruturação de dados processuais com R - 09/05\nAnálise descritiva e visualização de dados processuais - 16/05\nModelos lineares aplicados a pesquisa em direito – regressão linear - 23/05\nModelos para diferentes tipos de estrutura de dados e variáveis. - 06/06\nAprendizado estatístico (machine learning) - 13/06\nAprendizado estatístico (machine learning) - 20/06\nInterpretação dos resultados e elaboração do relatório - 27/06"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introdução ao Feminicídio",
    "section": "",
    "text": "Nessa seção pensei em falarmos um pouco no no caso referências etc…."
  },
  {
    "objectID": "lineares.html",
    "href": "lineares.html",
    "title": "6  Modelos Lineares",
    "section": "",
    "text": "7 Regressão Linear Simples - RLS\nVamos iniciar o estudo de modelos lineares começando pela Regresão Linear Simples (RLS). Mais específicamente, vamos estudar a RLS no contexto de dados de corte transversal. Tal abordagem, segmentada por tipos de dados, facilíta o entendimento das hipóteses do modelo.\nEntender como funciona o modelo RLS é a base para entender como funciona outras extensões desse tipo de modelo, tal como o modelo de regressão linear multipla (RLM), amplamente utilizado em trabalhos empíricos.\nOs conceitos estatísticos aplicados no estudo de RLS são os mesmos apresentados na seção anterior.\nO matérial desta seção é baseado na 4ed do livro de Jeffrey Wooldridge, Introdução à Econometria: Uma Abordagem Moderna, de 2013. Embora o título do livro remeta à econometria, os modelos apresentados no livro são aplicaveis à diversas Ciências Sociais, tais como o Direito, Ciência Política, Sociologia, Pscologia Empírica etc…\nA análise de Regressão é um instrumento poderoso para os centistas sociais. Grosso modo, como veremos abaixo, ela nos permite simular, ao menos parcialmente, aplicações de caráter quase experimental. Podemos verificar como determinadas variáveis importantes nas ciencias sociais interagem com outras variáveis, as vezes em uma relação de causa e efeito.\nA RLM é uma extensão natural da RLS. Entretanto, ao invés de termos apenas uma variável explicativa podemos ter \\(k\\) variáveis dependentes\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\ldots + \\beta_k x_k + u\\] A hípótese fundamental é a de que:\n\\[E(u|x_1, . . . ,x_k) = 0\\]\nQualquer problema que faça qualquer um dos \\(x_1, ...., x_k\\) ser correlacionado com \\(u\\) invalida a hipótese acima. Tal hipótese implica em não viés do MQO."
  },
  {
    "objectID": "lineares.html#introdução",
    "href": "lineares.html#introdução",
    "title": "5  Modelos Lineares",
    "section": "5.1 Introdução",
    "text": "5.1 Introdução\nComeçamos com o modelo mais geral da população:\n\\[y = \\beta_0 + \\beta_1x + u \\]\nNesta equação, \\(y\\) é a variavel dependente ou também denominada de variável explicativa; \\(x\\) é a variável explicativa e \\(u\\) é o termo de erro. Essa equação é uma equação de regressão linear simples.\nVejamos um exemlo\nGostariamos de explicar a taxa de crimes nos bairros de uma cidade e consideramos que os níveis de desemprego nas localidades são importantes. Nosso modelo de regressão poderia ser específicado da seguinte maneira:\n\\[Crime_i = \\beta_0 + \\beta_1Desemprego_i + u\\]\nO subscrito \\(i\\) se refere a um bairro hipotético da cidade. Note que nesse caso,\\(i\\) é o subscrito que relaciona nossas unidades de observação (bairros). Nossas unidades de observação podem variar a depender do contexto em estudo: países, cidades, bairros, estados, pessoas, processos, varas, tribunais….\nNote que, novamente o termo de erro, \\(u\\), está presente na equação. O termo de erro, não observado, capta tudo aquilo que afeta \\(Crime\\), mas que não estamos controlando, ou seja, que não é explicado pelo \\(Desemprego\\).\nVoltemos a equação básica:\n\\[y = \\beta_0 + \\beta_1x + u \\]\nNa analise de RLS estamos interessados nos parâmetros \\(\\beta_0\\) e sobretudo \\(\\beta_1\\). A razão primordial para isso é que, tudo o mais constante, a relação acima aponta que\n\\[\\Delta y = \\beta_1 \\Delta x \\] , se \\[\\Delta u = 0\\]\nIsto é, se tudo o mais que afeta \\(y\\) permanecer inalterado, uma variáção em \\(x\\), \\(\\Delta x\\), terá um impacto de \\(\\beta_1 \\Delta x\\) em \\(y\\). No exemplo da criminalidade, teremos que:\n\\[\\Delta crime = \\beta_1 \\Delta desemprego \\]\nAssim, o aumento o de 1 ponto no desemprego irá ter o efeito de \\(\\beta_1\\) unidades de crimes em média. Por isso, quando conseguimos estimar os parêmetros \\(\\beta\\) estamos mais próximos de entender as relações entre \\(x\\) e \\(y\\) em nossas aplicações.\nCabe destacar algo bastante importante.As relações acima não encerram a questão da causalidade. Como podemos inferir um impacto causal do desemprego na criminalidade se estamos ignorando todos os demais fatores que ficaram de fora do modelo - fatores que são captados em \\(u\\) não observados.\n\n5.1.1 Alguns Exemplos de Regressão Aplicados ao Contexto Jurídico:\nConsidere os seguintes exemplos de RLS aplicadas ao contexto do Direito\nPrevisão de Sentenças com Base na Gravidade do Crime: Onde, a variável dependente e tamanho da pena, e a variável independente é a Gravidade do Crime, \\(\\beta_0\\)é o intercepto da regressão. \\(\\beta_1\\) é o coeficiente de regressão que representa como a gravidade do crime influência o tamanho da pena, \\(u\\) é o termo de erro.\n\\[Dpena = \\beta_0 + \\beta_1{\\text{Gravidade}} + u\\]\nAnálise de Fatores que Influenciam o Tempo de Julgamento: Variável Independente (\\(x\\)), Tipo de Processo (por exemplo, criminal, civil, administrativo). Variável Dependente (\\(y\\)), Tempo de Duração do Processo. Objetivo: Identificar se o tipo de processo tem impacto no tempo que um caso leva para ser concluído.\n\\[Tempo = \\beta_0 + \\beta_1  Processo  + u\\]\nPrevisão de Probabilidade de Recurso com Base em Decisões Anteriores: Variável Independente (\\(x\\)): Resultado da Decisão Anterior (por exemplo, deferimento ou negação do recurso). Variável Dependente (\\(y\\)): Probabilidade de Entrada com Recurso. Objetivo: Determinar a probabilidade de um recurso ser apresentado com base no resultado de decisões passadas.\n\\[Resultado = \\beta_0 + \\beta_1 Resultado_{-1} + u \\]\nAnálise de Relação entre Número de Testemunhas e Veredito: Variável Independente (\\(x\\)): Número de Testemunhas. Variável Dependente (\\(y\\)): Veredito (por exemplo, culpado ou inocente). Objetivo: Investigar se o número de testemunhas influencia o veredito\n\\[ Veredito = \\beta_0 + \\beta_1 Testemunhas + u \\]"
  },
  {
    "objectID": "lineares.html#hipóteses-sobre-o-comportamento-do-termo-de-erro",
    "href": "lineares.html#hipóteses-sobre-o-comportamento-do-termo-de-erro",
    "title": "5  Modelos Lineares",
    "section": "5.2 Hipóteses sobre o comportamento do Termo de Erro",
    "text": "5.2 Hipóteses sobre o comportamento do Termo de Erro\nSe especificamos o modelo com \\(\\beta_0\\), podemos assumir que \\(u\\), tem média igual a zero. Em notação de esperança matematica essa hipotese equivale a:\n\\[E(u) = 0\\]\nPodemos definir uma segunda hipotese sobre \\(u\\). Uma hipótese forte, é a de que \\(u\\) e \\(x\\) são independentes. Tal hípótese é a hipótese crucial do modelo de RLS:\n\\[E(u|x) = 0\\]\nJustas as hipóteses de \\(E(u) = 0\\) e \\(E(u|x) = 0\\) são denominadas de hipotese de média condicional zero.\nDessa forma, no nosso modelo inicial:\n\\[y = \\beta_0 + \\beta_1x + u\\]\nAplicando o operador \\(E( \\cdot |x )\\), obetmos\n\\[ E( y |x ) = \\beta_0 + \\beta_1x \\]\nAssim, na equação acima, temos um aumento de uma unidade em \\(x\\), implica em um aumento no valor esperado (ou em média) de \\(y\\) na magnitude de \\(\\beta_1\\).\nA equação acima, é caracterizada como função de regressão populacional. Essa função nos fornece a elação entre os diferentes níveis de\\(x\\) é o nível médio de \\(y\\), isto é \\(E( y |x )\\).\n\n\n\nFunção de Regressão Populacional\n\n\nAgora, podemos voltar a nossa equação base e verificarmos o progresso feito no entendimento do modelo:\n\\[y = \\beta_0 + \\beta_1x + u \\]\n\\[y = E( y |x ) + u \\]\nNa equação acima, \\(E( y |x )\\) é chamada de parte sistematica de \\(y\\). Isto é, a parte sistematicamente explicada por \\(x\\). Já o termo de erro não observado, \\(u\\) é a parte não sistematica de \\(y\\), não explicada por \\(x\\)."
  },
  {
    "objectID": "lineares.html#estimação-dos-parâmetros-da-rls",
    "href": "lineares.html#estimação-dos-parâmetros-da-rls",
    "title": "5  Modelos Lineares",
    "section": "5.3 Estimação dos Parâmetros da RLS",
    "text": "5.3 Estimação dos Parâmetros da RLS\nNão conhecemos \\(\\beta_0\\) e \\(\\beta_1\\) queremos estimadores desses parametros: \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\).\nSuponha que tenhamos uma amostra aleatória da população: \\(\\{(x_i, y_i): i = 1, ..., n\\}\\). Poderia ser uma amostra de crimes e taxa de desemprego por bairros.\nEm nosso modelo base:\n\\[y_i = \\beta_0 + \\beta_1x_i + u_i \\]\nonde \\(u_i\\) é o erro aleatório da \\(i\\)-ésima observação.\nComo estimamos \\(\\beta_0\\) e \\(\\beta_1\\)?\nApós algum esforço algébrico, tem-se:\n\\[\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\\]\ne\n\\[\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\\]\nOnde, \\(\\bar{x}\\) e \\(\\bar{y}\\) são as médias amostrais de \\(x\\) e \\(y\\) respectivamente.\nOs estimadores \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) são chamados de estimadores de Mínimos Quadrados Ordinários (MQO).\nA ideia é que os parâmetros que estimamos, \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\), são os parâmetros que minimizam a soma dos quadrados das diferenças entre nossos \\(y_i\\) obversados e seus valores preditos definidos como\n\\[y_i- \\hat{y}_i =y_i -  \\hat{\\beta}_0 + \\hat{\\beta}_1x_i=u_i\\] Queremos minimizar o quadrado dessa diferença. Vejamos graficamente:\n\n\n\nValores Ajustados e Resíduos de MQO\n\n\nAntes de passarmos para o proxímo tópico de RLS, cabe mencionar uma nota sobre terminologia: quando estimamos equações de RLS do tipo \\(y = \\beta_0 + \\beta_1 x + u\\), dizemos que “rodamos a regressão de \\(y\\) sobre \\(x\\) !”\n\n5.3.1 Aplicação - Estimando uma Regressão Linear Simples\nVamos utilizar aqui o nosso banco de dados anterior sobre feminicídio. É um banco com poucas obserações e possui fim didátco, apesar de serem dados reais.\nUma questão incial é entender quem será \\(Y\\) e quem será \\(X\\). Estamos querendo entender a taxa de feminicídio. A questão é, quais são seus determinantes? Aqui precisamos de alguma teoria…mas or hora, vamos ter como hipótese inicial que quanto maior a taxa de homícídio espera-se que em média a taxa de feminicídio aumente. :\n\\[Feminc_{tx} = \\beta_0 + \\beta_1 Homici_{tx} + u\\]\nApesar de parecer “muito complicado” na teoria, na prática o r estima uma RLS em segundos. A função para estimar é alm, ou linear model.\n\n### Aplicação da RLS - Método dos Mínimos Quadrados Ordinários\n\n#carregando o pacote para ler arquivos em excel\nload(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/final_fem_22.Rdata\")\n\n#Vamos chamar a partir de agora nosso banco de dados\ndados&lt;- final_fem_22 \n\n##Função para rodar a regressão\nmodelo &lt;- lm(data = dados, feminic_tx ~ homic_tx)\n\n\n#Essa função resume a regressão, ja testar a hipótese sobre o coeficiente e da outras estatisticas que abordaremos a seguir.\nsummary(modelo)\n\n\nCall:\nlm(formula = feminic_tx ~ homic_tx, data = dados)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.28942 -0.30169  0.03482  0.30070  1.18192 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.14673    0.28607   4.009 0.000485 ***\nhomic_tx     0.10580    0.05503   1.923 0.065990 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5882 on 25 degrees of freedom\nMultiple R-squared:  0.1288,    Adjusted R-squared:  0.09397 \nF-statistic: 3.697 on 1 and 25 DF,  p-value: 0.06599\n\n\n\n5.3.1.1 Entendendo os Resultados\n1) Resíduos Residuals: apresenta a distribuição dos resíduos, observa-se que amediana dos resíduos está próxima a zero.\n2)Coeficientes Em seguida, abaixo de Coefficients temos 5 colunas.\nColuna 1: Nome da variável\nColuna 2: Coeficiente estimado \\(\\hat{\\beta_0}\\) o intercepto e \\(\\hat{\\beta_1}\\) do termo da variável homicídio\nColuna 3: É o desvio padrão da estimativas de \\(\\beta\\)\nColuna 4: É a estatistica t utilizada para fazer o teste de hipótese e neste caso, tem-se: \\[H_0:\\beta_0=0\\] e \\[H_0:\\beta_1=0\\]\nColuna 5: É o p-valor, a probabilidade de encontrarmos valores mais extremos da estatística t. Os asteriscos indicam *** signicante a 0,1% ** a 1% * a 5% e \\(.\\) a 10%.\nInterpretando o Coeficiente\nO coeficiente do intercepto nos diz que quando a taxa de homicídio for 0, ainda existira uma taxa de feminicídio de 1,4 pontos, \\(\\beta_0\\), significante a 0,1%. E cada 1 ponto de aumento na taxa de homicídio, aumenta em 0,10 \\(\\beta_1\\) pontos a taxa de feminicídio, significante a 10%.\n3) \\(R^2\\): Em seguida temos o \\(R^2\\) e \\(R^2\\) ajustado. Essas estatísticas calculam quanto da variância da taxa de feminicídio pode ser explicada pela variância da taxa de homicídio. Quando estão próximos a 1 explicam muito, quanto estão próximos a 0 explicam pouco. No caso o nosso \\(R^2\\) ficou baixo e portanto boa parte da variabilidade do feminicídio, não foi explicada pela taxa de homicídio.\n4) Estaística F: E por fim a estatística F mostra o grau de ajustamento do modelo. Se ela for significativa diz que o modelo é bem ajustados aos dados. As variáveis explicativas incluídas são importantes para a explicação da taxa de feminicídio.\nVISUALMENTE\nAbaixo tem-se os dados utilizados e a nossa reta de regressão estimada acima. Veja como ela se ajusta a nuve de pontos.\n\n# Ajustando a reta de regessão.\n plot(dados$homic_tx, dados$feminic_tx,\n     main = \"Taxa de Feminicídio vs.Tx de homicidio\",\n     xlab = \"Taxa de Homicidio\",\n     ylab = \"Taxa de Feminicídio\",\n     col = \"steelblue\",          # Cor dos pontos\n     pch = 16,              # Forma dos pontos (círculos sólidos)\n     cex = 1.0,         # Tamanho dos pontos\n     abline(modelo, col = \"lightsalmon3\", lwd = 3))"
  },
  {
    "objectID": "lineares.html#caracteristicas-do-método-dos-mínimos-quadrados-ordinários-em-determinadas-amostras-de-dados",
    "href": "lineares.html#caracteristicas-do-método-dos-mínimos-quadrados-ordinários-em-determinadas-amostras-de-dados",
    "title": "5  Modelos Lineares",
    "section": "5.4 Caracteristicas do Método dos Mínimos Quadrados Ordinários em Determinadas Amostras de Dados",
    "text": "5.4 Caracteristicas do Método dos Mínimos Quadrados Ordinários em Determinadas Amostras de Dados\n\n5.4.1 Valores estimados e Resíduos\nUma vez estimados \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) temos os valores ajustados ou também denominados de valores preditos ou fitted values.\nPara uma observação qualquer \\(i\\), seu valor estimado é:\n\\[\\hat{y}_i= \\hat{\\beta}_0 + \\hat{\\beta}_1x_i\\]\nTodos os valores \\(\\hat{y}\\) estarão sobre a reta de regressão.\nO resíduo, tal qual definido anteriormente, será a diferença entre o valor ajustado \\(\\hat{y}\\) e o verdadeiro \\(y\\) em nosso banco de dados:\n\\[\\hat{u}_i = y_i - \\hat{y}_i\\]\nSe \\(\\hat{u_i} &gt; 0\\) a regressaõ subestima \\(y_i\\). Se \\(\\hat{u_i} &lt; 0\\) a reta superestima \\(y_i\\). O cenário ideal é quando \\(\\hat{u}_i= 0\\), algo que quase nunca acontece.\n\n##Obtendo os residuos da regressão\nresid &lt;- residuals(modelo)\n k &lt;- density(resid)\n  plot(k, xlab=\"Erro\",main=\"Densidade de Kernel para o erro\")\n  polygon(k, col=\"burlywood3\", border=\"burlywood4\")\n\n\n\n\n\n\n5.4.2 Propriedades Algébricas do MQO\n\nA Soma dos Resíduos é zero:\n\n\\[\\sum_{i=1}^{n} \\hat{u}_i = 0\\]\n\n###Soma dos resíduos\nsum(resid)\n\n[1] 8.881784e-16\n\n#note que é um número praticamente igual a zero\n\n\nA covariancia amostral entre a variavel explicativa e os resíduos é zero:\n\n\\[\\sum_{i=1}^{n} x_i \\hat{u}_i = 0\\]\n\n#obtendo a variável x\nx &lt;- dados$homic_tx\n\n#somando com os residuos\nsum(x*resid)\n\n[1] 1.298961e-14\n\n\n\nO ponto \\((\\bar{x},\\bar{y})\\) sempre estará sob a reta de regressão.\nA média dos valores estimados, \\(\\bar{\\hat{y}}\\) é igual a média dos valores observados \\(\\bar{y}\\).\n\n\n#y dos dados \ny &lt;- dados$feminic_tx\nmean(y)\n\n[1] 1.651852\n\n#y estimado\ny_hat &lt;- fitted.values(modelo)\nmean(y_hat)\n\n[1] 1.651852\n\nmean(y)==mean(y_hat)\n\n[1] TRUE\n\n\n\nNote que as estimatvas de MQO decompõe \\(y\\) em 2 partes: 1) os valores ajustados \\(\\hat{y}\\) e os resíduos \\(\\hat{u}\\).\nOs valores de \\(\\hat{y}\\) e \\(\\hat{u}\\) são não correlacionados na amostra!\n\n\n\n5.4.3 Qualidade do Ajuste\nNesta seção vamos responder a seguinte questão: “Quão bem \\(x\\) explica \\(y\\) ?”\nConsidere as seguintes definições\nSoma dos Quadrado Totais (SQT):\n\\[\\text{SQT} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\\]\n\n# Calcular a média da variável dependente (feminic_tx)\nmedia_feminic_tx &lt;- mean(dados$feminic_tx)\n\n# Calcular a Soma dos Quadrados Totais (SQT)\nsqt &lt;- sum((dados$feminic_tx - media_feminic_tx)^2)\nsqt\n\n[1] 9.927407\n\n\nSoma dos Quadrados Explicados (SQE):\n\\[\\text{SQE} = \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2\\]\n\n# Calcular a Soma dos Quadrados Explicados (SQE)\nsqe &lt;- sum((y_hat - media_feminic_tx)^2)\nsqe\n\n[1] 1.27879\n\n\nSoma dos Quadrados dos Resíduos (SQR):\n\\[\\text{SQR} = \\sum_{i=1}^{n} \\hat{u}_i^2\\]\n\nresiduos_quadrados &lt;- residuals(modelo)^2\nsqr &lt;- sum(residuos_quadrados)\nsqr\n\n[1] 8.648617\n\n\nO resultado mais importante é o seguinte:\n\\[SQT =  SQE + SQR\\]\nÉ apartir dessa iguadade que podemos mostrar algo sobre o ajuste dos MQO.\nDívidindo ambos os lados por \\(SQT\\) teremos\n\\[1 = \\frac{\\text{SQE}}{\\text{SQT}}  + \\frac{\\text{SQR}}{\\text{SQT}}\\]\nRearranjando os termos\n\\[R^2 = \\frac{\\text{SQE}}{\\text{SQT}} = 1 - \\frac{\\text{SQR}}{\\text{SQT}}\\]\n\n#r-quadrado do modelo\nr_quadrado &lt;- 1 - (sqr/sqt)\nr_quadrado\n\n[1] 0.1288141\n\n\nNovamente, o \\(R^2\\) é a porcentagem da variação de y que é explicada por \\(x\\). O valor de \\(R^2\\) sempre estará na RLS entre \\(0\\) e \\(1\\)."
  },
  {
    "objectID": "lineares.html#ausência-de-viés-e-variância-dos-estimadores-de-mqo",
    "href": "lineares.html#ausência-de-viés-e-variância-dos-estimadores-de-mqo",
    "title": "6  Modelos Lineares",
    "section": "7.5 Ausência de Viés e Variância dos Estimadores de MQO",
    "text": "7.5 Ausência de Viés e Variância dos Estimadores de MQO\n\n7.5.1 Ausencia de Viés em MQO\nUm estimador não viésado (ou não tendêncioso) por definição, um estimador que em média “acerta” o verdadeiro valor do parâmetro estimado.\nConsidere um estimador arbitrario \\(\\hat{\\theta}\\). Quando dezemos que \\(\\hat{\\theta}\\) é não viesado, queremos dizer que\n\\[E(\\hat{\\theta}) = \\theta\\]\nSerá que os \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) estimados pelo método do MQO são não viésados?\nPara responder a essa pergunta precisamos, mais uma vez, recorrer a novas hipoteses sobre os dados. Esse novo conjunto de hipoteses irão nos permitir verificarmos algumas propriedades estatísticas do método de MQO. A depender das hipóteses, umas mais fracas que outras, as propriedades podem mudar.\nA garantia da ausência de viés, em dados de corte transversal, requer quatro hipóteses:\n1) Linearidade dos Parametros: No modelo Populacional a variavel dependente \\(y\\) está relacionada a variável dependente \\(x\\) e ao termo de erro \\(u\\) como:\n\\[y = \\beta_0 + \\beta_1x + u \\] Por exemplo no modelo \\(y= \\beta_0 + e^{\\beta_1} + u\\), não é linear no parametro \\(\\beta_1\\).\n2) Amostragem Aleatória: Usamos uma amostra aleatória de tamanho \\(n\\), \\(\\{(x_i, y_i): i = 1, 2, ..., n\\}\\) proveniente de um modelo populacional.\n3) Existe Variação Amostral em \\(x\\): Isto é, os valores de nossa variável explicativa não são todos iguais.\n4) Independencia da Média: O termo de erro \\(u\\) tem um valor esperado de zero, dado qualquer valor da variável explicativa.\\[E(u|x) = 0\\]\nDadas as hipóteses 1, 2, 3 e 4:\n\\[E(\\hat{\\beta_1}) = \\beta_1\\]\ne\n\\[E(\\hat{\\beta_0}) = \\beta_0\\]\nPortantos nossoa estimadores de MQO, são não viésados.\n\n\n7.5.2 Variância dos estimadores de MQO\nQuão distantes em média \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\) estão dos verdadeiros parâmetros? Saber disso nos permite escolher o melhor estimador entre todos os etimadores não viesados - ou ao menos entre uma ampla classe deles.\nPara obetermos expressões tratáveis das variâncias do MQO recorremos a mais uma hipótese.\n5) Hipótese de Homoscedasticidade: O erro \\(u\\) tem a mesma variâcia, dado qualquer valor da variável explicativa. Isto é,\n\\[Var(u|x)=\\sigma^2\\]\nA variância de \\(u\\) pode ser reescrita em termos de esperança:\n\\[Var(u|x)= \\sigma^2 = E(u^2|x) - [E(u|x)]^2\\]\nMas como temos por hipótese que \\([E(u|x)]=0\\), a hipótese de homoscedasticidade as vezes é representada como\n\\[ E(u^2|x) = \\sigma^2\\]\nNote também, que como \\(E(u)=0\\), a variancia do erro, não condicional a \\(x\\), será dada por:\n\\[\\sigma^2=E(u^2)=Var(u)\\] Por isso chamamos \\(\\sigma^2\\) de variância do erro.\nPodemos “vizualizar” a hipótese de homoscedasticidade na figura abaixo:\n\n\n\nModelo de Regressão Sob Homoscedasticidade\n\n\nApartir das hiopóteses 1,2,3,4 e 5 podemos progredir no entendimento dos MQO. Sob as hipoteses 1 - 5, as variancias de \\(\\hat{\\beta_1}\\) e \\(\\hat{\\beta_0}\\) são dadas por:\n\\[\\text{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}=\\frac{\\sigma^2}{\\text{SST}_x}\\] e\n\\[\\text{Var}(\\hat{\\beta}_0) = \\frac{\\sigma^2n^{-1}\\sum_{i=1}^{n} x_i^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\\]\nUma extenção da variância dos estimadores de MQO são seus desvios padrão definidos simplismente pela raiz quadrada da variância:\n\\[ep(\\hat{\\beta}_0) = \\sqrt{Var(\\hat{\\beta_0})}\\]\ne\n\\[ep(\\hat{\\beta}_1) = \\sqrt{Var(\\hat{\\beta_1})} = \\frac{\\sigma}{\\sqrt{SQT_x}}\\]\n\n\n7.5.3 Estimação da Variância do erro\nNote que, nas formulas das variâncias e dos desvios-padrão, o que aparece explicitamente é o parâmetro populacional, \\(\\sigma^2\\) e \\(\\sigma\\). Raramente conhecemos esses valores, logo as formulas derivadas acima terão pouca utilidade. Não obstante, caso encontremos um estimador para \\(\\sigma^2\\) e \\(\\sigma\\) podemos usar esse estimador.\nPodemos utilizar os resíduos para construir um estimador da variância dos erros. Lembre que o resíduos da \\(i\\)-ésima observação do modelo é dado por:\n\\[\\hat{u_i} = y_i - \\hat{y_i}\\] Pode-se demostrar que, um estimador não viesado de \\(\\sigma^2\\) será dado por:\n\\[\\hat{\\sigma}^2=\\frac{\\sum_{i=1}^{n} \\hat{u}_i^2}{n-2} = \\frac{\\text{SQR}}{n-2}\\]\nCom \\(\\hat{\\sigma}^2\\) em mãos, podemos reescrever os erros padrão dos estimadores de MQO:\n\\[ep(\\hat{\\beta}_1) = \\sqrt{Var(\\hat{\\beta_1})} = \\frac{\\hat{\\sigma}^2}{\\sqrt{SQT_x}}\\]\nOs erros padrão são utilizados para calcularmos as estatísticas de teste e Intervalos de Confiança para as Estimativas. Mais a frente iremos nos concentar nessas questões."
  },
  {
    "objectID": "lineares.html#aplicação-de-rls---foco-no-erro-padrão-do-parametro-b1",
    "href": "lineares.html#aplicação-de-rls---foco-no-erro-padrão-do-parametro-b1",
    "title": "6  Modelos Lineares",
    "section": "7.6 Aplicação de RLS - Foco no erro padrão do parametro b1",
    "text": "7.6 Aplicação de RLS - Foco no erro padrão do parametro b1\n\n### Aplicação do de RLS - Foco no erro padrão"
  },
  {
    "objectID": "lineares.html#exemplos-de-regressão-multipla-no-contexto-jurídico",
    "href": "lineares.html#exemplos-de-regressão-multipla-no-contexto-jurídico",
    "title": "6  Modelos Lineares",
    "section": "8.1 Exemplos de Regressão Multipla no Contexto Jurídico",
    "text": "8.1 Exemplos de Regressão Multipla no Contexto Jurídico\nDeterminação de Fatores que Afetam o Valor de Indenizações: Variáveis Independentes: Idade da Vítima, Gravidade do Dano, Jurisdição. Variável Dependente: Valor da Indenização.Objetivo: Analisar como a idade da vítima, a gravidade do dano e a jurisdição influenciam o valor das indenizações concedidas\n\\[Indenização = \\beta_0 + \\beta_1 idade+ \\beta_2 Gravidade + \\beta_2 Jurisdisção + u\\]\nAnálise de Variáveis que Influenciam Taxas de Condenação em Casos Criminais: Variáveis Independentes: Idade do Réu, Tipo de Crime, Local do Julgamento. Variável Dependente: Taxa de Condenação.Objetivo: Investigar como a idade do réu, o tipo de crime e o local do julgamento afetam a probabilidade de condenação.\n\\[Tx.Condenação = \\beta_0 + \\beta_1  idade  +  \\beta_2 Local  + \\beta_3  crime + u\\]\nnálise de Fatores que Influenciam a Taxa de Feminicídio: Variáveis Independentes (X): Taxa de Desemprego, Índice de Educação, Presença de Políticas de Proteção à Mulher. Variável Dependente (Y): Taxa de Feminicídio por 100.000 mulheres. Objetivo: Investigar como o desemprego, o nível de educação e a existência de políticas de proteção à mulher estão relacionados à taxa de feminicídio em diferentes regiões.\n\\[Tx.feminicidio = \\beta_0 + \\beta_1 desemprego + \\beta_2 educ + \\beta_3 política + u \\]"
  },
  {
    "objectID": "lineares.html#a-interpretação-da-equação-de-regressão-de-mqo",
    "href": "lineares.html#a-interpretação-da-equação-de-regressão-de-mqo",
    "title": "6  Modelos Lineares",
    "section": "8.2 A Interpretação da Equação de Regressão de MQO",
    "text": "8.2 A Interpretação da Equação de Regressão de MQO\nTal qual no modelo de RLS, temos que:\n\\[\\Delta y = \\beta_1 \\Delta x_1 + \\beta_2 \\Delta x_2 + ...+\\beta_k \\Delta x_k\\]\nO coefiente \\(\\beta_j\\), com \\(j=1,...k\\), mede o efeito do incremento de uma unidade de \\(x_j\\) em \\(y\\).\nSuponha que estejamos interessados no impacto de \\(x_1\\). Podemos fazer o seguinte exercício: Tudo o mais constante qual o impacto de \\(x_1\\) em \\(y\\):\n\\[\\frac{\\Delta y}{\\Delta x} = \\beta_1  \\]\nManter outros fatores fixos permite o cientista social, “mimetizar” um experimento, tal qual nas Ciências Naturasi. Obviamente, isso não tão simples assim. Entretanto, mater outros fatores fixos, e supondo que \\[E(u|x_1, . . . ,x_k) = 0\\] , nos aproxíma de afirmações de cunho causal."
  },
  {
    "objectID": "lineares.html#estimação-dos-k-parametros-na-rlm",
    "href": "lineares.html#estimação-dos-k-parametros-na-rlm",
    "title": "6  Modelos Lineares",
    "section": "8.3 Estimação dos k parametros na RLM",
    "text": "8.3 Estimação dos k parametros na RLM\n\n8.3.1 Estimativas de MQO\nA mecânica para conseguirmos estimativas de \\(\\beta_j\\), fica uma pouco mais complicada. Felizmente, os softwares, tais como o R, fornecem essas estimativas com muita facilidade. Não obstante, convêm apresentar uma abordagem para o calculo desses parâmetros. Utilizaremos álgebra de matrizes para mostrar um “algoritmo” para calcular esses \\(\\beta_j\\). Em verdade, esse é o algoritmo utilizado pela função lm() do R no computo dos estimadores.\nConsidere o modelo para a \\(i\\)-ésima observação\n\\[y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_{i2} x_2 + \\beta_{i3} x_3 + \\ldots + \\beta_k x_{ik} + u\\]\ncomo temos \\(n\\) observações (tamanho de nossa amostra), podemos organizar esses valores em vetores e matrizes.\nPara os valores de \\(y\\) teremos\n\\[\n\\mathbf{y} = \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\n\\]\nOs valores das variáves independentes \\(X\\) podem ser organizados da seguinte maneira:\n\\[\\mathbf{X} = \\begin{bmatrix}\n1 & x_{11} & \\cdots & x_{1k} \\\\\n1 & x_{21} & \\cdots & x_{2k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{n1} & \\cdots & x_{nk}\n\\end{bmatrix}\\]\nOs \\(\\beta_j\\) são organizados da seguinte maneira:\n\\[\\boldsymbol{\\beta} = \\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix}\\]\nOs erros \\(u_i\\) serão armazenados da em um vetor coluna tambêm:\n\\[\\mathbf{u} = \\begin{bmatrix}\nu_1 \\\\\nu_2 \\\\\n\\vdots \\\\\nu_n\n\\end{bmatrix}\\]\nApartir disso representamos o modelo de RLM da seguinte maneira:\n\\[\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{u}\\]\nQueremos encontrar um estimador de \\(\\boldsymbol{\\beta}\\), que chamaremos de \\(\\boldsymbol{\\hat{\\beta}}\\). Esse estimador sera dado por:\n\\[\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\\]\nOnde \\(\\mathbf{X}^T\\) é a matriz transposta de \\(\\mathbf{X}\\), e \\((\\mathbf{X}^T \\mathbf{X})^{-1}\\) é a matriz inversa da seguinte multiplicação de matrizes, \\((\\mathbf{X}^T \\mathbf{X})\\)\nEsse vetor de estimativas irá nos fornecer os valores para os \\(\\beta_j\\),com \\(j=1,...,k\\). Assim temos que:\n\\[ \\hat{\\boldsymbol{\\beta}} = \\begin{bmatrix}\n\\hat{\\beta}_0 \\\\\n\\hat{\\beta}_1 \\\\\n\\hat{\\beta}_2 \\\\\n\\vdots \\\\\n\\hat{\\beta}_k\n\\end{bmatrix}\\]\nAntes, de prosseguirmos cabe destacar que, embora não precisamos saber as formulas explicitas para dos \\(\\hat{\\beta_j}\\), as vezes isso nos ajuda a entender o funcionamento da regressão multipla e os efeitos parciais que os \\(\\beta_j\\) exercem sobre \\(y\\).\nPor exemplo, \\(\\hat{\\beta_1}\\) pode ser representado da seguinte maneira no contexto da RLM:\n\\[\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n \\hat{r_{i1}} y_i}{\\sum_{i=1}^n \\hat{r_{i1}}^2}\\]\nOnde \\(r_{i1}\\) são os resíduos da regressão de \\(x_1\\) sobre todas as demais variáveis do modelo \\(x_2,...,x_k\\). Nesse caso, podemos entender que $_1 $ mede o efeito de \\(x_1\\) sobre \\(y\\) após terem sido parcializados ou descontados os impactos de \\(x_2,...,x_k\\).\nPara um \\(\\beta_j\\) qualquer a interpretação é análoga.\n\\[\\hat{\\beta}_j = \\frac{\\sum_{i=1}^n \\hat{r_{ij}} y_i}{\\sum_{i=1}^n \\hat{r_{ij}}^2}\\]"
  },
  {
    "objectID": "lineares.html#qualidade-do-ajuste-na-regressão-linear-multipla",
    "href": "lineares.html#qualidade-do-ajuste-na-regressão-linear-multipla",
    "title": "6  Modelos Lineares",
    "section": "8.4 Qualidade do Ajuste na Regressão Linear Multipla",
    "text": "8.4 Qualidade do Ajuste na Regressão Linear Multipla\nTal qual na regressão linear simples, são válidas as seguintes relações:\nSoma dos Quadrado Totais (SQT):\n\\[\\text{SQT} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\\]\nSoma dos Quadrados Explicados (SQE):\n\\[\\text{SQE} = \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2\\]\nSoma dos Quadrados dos Resíduos (SQR):\n\\[\\text{SQR} = \\sum_{i=1}^{n} \\hat{u}_i^2\\] Novamente podemos definir a qualidade do ajuste, medido pelo \\(R^2\\), como sendo igual à\n\\[R^2 = \\frac{\\text{SQE}}{\\text{SQT}} = 1 - \\frac{\\text{SQR}}{\\text{SQT}}\\]\nExplicitamente podemos escrever o \\(R^2\\) tal como:\n\\[R^2 =  \\frac{[\\sum_{i=1}^n (y_i - \\bar{y}) ( \\hat{y}_i - \\bar{\\hat{y}} )]^2}{[\\sum_{i=1}^n (y_i - \\bar{y})^2][\\sum_{i=1}^n(\\hat{y}-\\bar{\\hat{y}})^2]}\\]\nUm fato importante sobre \\(R^2\\) é que ele nunca diminui ao incluirmos variáveis no modelo. Isso decorre de propriedades algébricas desse indicador.Por isso, os softwares geralmente reportam uma outra estatística de ajuste o R-quadrado ajustado,\\(\\bar{R}^2\\):\n\\[\\bar{R}^2 = 1 - \\frac{(1 - R^2)(n - 1)}{n - k - 1}\\] O \\(\\bar{R}^2\\), tal como expresso acima conta com a presença do \\(R^2\\) original, mas note que, no denominador estamos dividindo por \\(n-k-1\\), onde \\(n\\) é o tamanho da amostra em mãos, e \\(k-1\\) se referem ao fato de termos \\(k\\) variáveis explicativas e uma constante. Portanto, o \\(\\bar{R}^2\\), impões uma penalidade à inclusão de variáveis independentes em um modelo de regressão.\nCabe destacar que, diferente do \\(R^2\\), \\(\\bar{R}^2\\) pode ser negativo, indicando um ajuste bastante pobre do modelo.\nNão obstante, cabe destacar que um \\(R^2\\) baixo não é definitivamente uma evidencia definitiva contra nosso modelo. Em ciências sociais em geral é bastante comum verificarmos \\(R^2\\) relatvamente pequenos. Isso significa que, embora coletovamente as variáveis explicativas não expliquem muito das variações de \\(y\\), é possível que as estimativas de MQO sejam estimativas confiaveis dos efeitos parciais - tudo o mais constante - de cada \\(x_j\\) sobre \\(y\\)."
  },
  {
    "objectID": "lineares.html#valor-espererado-dos-estimadores-de-mqo",
    "href": "lineares.html#valor-espererado-dos-estimadores-de-mqo",
    "title": "6  Modelos Lineares",
    "section": "8.5 Valor Espererado dos Estimadores de MQO",
    "text": "8.5 Valor Espererado dos Estimadores de MQO\nQuando analisamos a ausencia de viés nos estimadores do modelo de RLS, um invocamos um conjunto de hipóteses. Felizmente, na nalises de RLM tais hipoteses se mantém, bastando apenas algumas modificações para o contexto de mais variáveis explicativas. Abaixo vamos enunciar essas hipoteses que garantem o não viés dos \\(\\beta_j\\) estimados.\n1) Linearidade dos Parametros: No modelo Populacional a variavel dependente \\(y\\) está relacionada as variáveis independentes e ao termo de erro \\(u\\) como:\n\\[y = \\beta_0 + \\beta_1x_1 + ...+\\beta_kx_k+u \\]\n2) Amostragem Aleatória: Usamos uma amostra aleatória de tamanho \\(n\\), \\(\\{(x_{i1},...,x_{ik}, y_i): i = 1, 2, ..., n\\}\\) proveniente de um modelo populacional.\n3) Colinearidade não Perfeita: Na amostra, e portanto na população, nehuma das variáveis explicativas são constantes e não há relações lineares extas entre as variáveis.Isto é, tais variáveis não são perfeitamente correlacionadas.\n***4) Independencia da Média:** O termo de erro \\(u\\) tem um valor esperado de zero, dado qualquer valor da variável explicativa.\n\\[E(u|x_1,...,x_k) = 0\\]\nEssa é a propriedade mais importante. Tal hipótese é violada quando a forma funciinal das variáveis explicativas e da variável dependente está incorreta ou mal especificada.\nQundo a hipótese se mantém, dizemos que as variáveis explicativas são exógenas.\nDadas as hipóteses 1, 2, 3 e 4:\n\\[E(\\hat{\\beta_j}) = \\beta_j\\] Para \\(j = 1,2,...,k\\). Isto é, \\(\\hat{\\beta_j}\\) são não viesados"
  },
  {
    "objectID": "lineares.html#variância-dos-estimadores-de-mqo-1",
    "href": "lineares.html#variância-dos-estimadores-de-mqo-1",
    "title": "6  Modelos Lineares",
    "section": "8.6 Variância dos Estimadores de MQO",
    "text": "8.6 Variância dos Estimadores de MQO\nAnalogamente ao que foi feito no caso da regressão simples, para obtermos a variância dos \\(\\hat{\\beta_j}\\) de MQO presisamos recorrer à mais uma hipótese. Tal hipótese é a de homoscedasticidade. Isto é, de que condicionadas as variáveis explicativas, a variância do termo de erro é constante para todas as observações.\n5) Hipótese de Homoscedasticidade: O erro \\(u\\) tem a mesma variâcia, dado qualquer valor das variáveis explicativas:\n\\[Var(u|x_1,...,x_k)=\\sigma^2\\]\nSob as hipóteses 1,2,3,4 e 5, a varincias de \\(\\hat{\\beta_j}\\) e dada por:\n\\[\\text{Var}(\\hat{\\beta}_j) = \\frac{\\hat{\\sigma}^2}{\\sum_{i=1}^{n} (x_{ij} - \\bar{x_j})^2(1-R^2_j)}=\\frac{\\hat\\sigma^2}{\\text{SQT}_j(1-R^2_j)}\\] Onde \\(SQT_j\\) é a a variação amostral de \\(x_j\\)e \\(R^2_j\\) é o R-quadrado da regressão de \\(x_j\\) sobre as outras variáveis explicativas.O termo \\(\\hat{\\sigma}^2\\) é o estimador da variâcia do termo de erro \\(u\\), dado por:\n\\[\\hat{\\sigma}^2=\\frac{\\sum_{i=1}^{n} \\hat{u}_i^2}{n-k-1} = \\frac{\\text{SQR}}{n-k-1}\\] Onde \\(n-k-1\\) são os graus de liberdade do problema de MQO: \\(k\\) variáveis e uma constantante.\n\n8.6.1 Eficiencia de MQO: O Teorema de Gauss-Markov\nTeorema de Gauss-Markov:Sob as hipóteses 1,2,3,4 e 5 os estimadores \\(\\hat{\\beta}_0,\\hat{\\beta}_1,...,\\hat{\\beta}_k\\) são os melhores estimadores lineares não viesados de \\(\\beta_1, \\beta_2,...,\\beta_k\\).\nSe alguma das hipóteses falhar, o teorema não é mais válido.\nÉ o teorema de Gauss-Markov que justifica o uso do MQO para estimar modelos de Regressão Linear Múltipla."
  },
  {
    "objectID": "lineares.html#uso-de-variáveis-qualitativas-na-análise-de-rlm",
    "href": "lineares.html#uso-de-variáveis-qualitativas-na-análise-de-rlm",
    "title": "6  Modelos Lineares",
    "section": "8.7 Uso de Variáveis Qualitativas na Análise de RLM",
    "text": "8.7 Uso de Variáveis Qualitativas na Análise de RLM\nConsidere os exemplos mencionados anteriormente.\nDeterminação de Fatores que Afetam o Valor de Indenizações: Variáveis Independentes: Idade da Vítima, Gravidade do Dano, Jurisdição. Variável Dependente: Valor da Indenização.Objetivo: Analisar como a idade da vítima, a gravidade do dano e a jurisdição influenciam o valor das indenizações concedidas\n\\[Indenização = \\beta_0 + \\beta_1 idade+ \\beta_2 Gravidade + \\beta_2 Jurisdisção + u\\]\nAnálise de Variáveis que Influenciam Taxas de Condenação em Casos Criminais: Variáveis Independentes: Idade do Réu, Tipo de Crime, Local do Julgamento. Variável Dependente: Taxa de Condenação.Objetivo: Investigar como a idade do réu, o tipo de crime e o local do julgamento afetam a probabilidade de condenação.\n\\[Tx.Condenação = \\beta_0 + \\beta_1  idade  +  \\beta_2 Local  + \\beta_3  crime + u\\]\nnálise de Fatores que Influenciam a Taxa de Feminicídio: Variáveis Independentes (X): Taxa de Desemprego, Índice de Educação, Presença de Políticas de Proteção à Mulher. Variável Dependente (Y): Taxa de Feminicídio por 100.000 mulheres. Objetivo: Investigar como o desemprego, o nível de educação e a existência de políticas de proteção à mulher estão relacionados à taxa de feminicídio em diferentes regiões.\n\\[Tx.feminicidio = \\beta_0 + \\beta_1 desemprego + \\beta_2 educ + \\beta_3 política + u \\]\nEm todos esses exemplos temos o denominamos de variáveis qualitativas. No primeiro exemplo, gravidade e jurisdição não são quantificaveis. No segundo exemplo, o tipo de crime, e a localidade também não. Por fim, no último exemplo, a variável que indica ou não a presença de uma política pública de proteção a mulher também é qualitativa.\nFelizmente, isso não traz problemas adcionais a estimação de MQO. Pelo menos quando tais variáveis aparecem como variáveis explicativas. Mais a frente veremos o que acontece quando a variável dependente é do tipo qualitativa.\nDuas coisas mudam quando temos as variáveis qualitativas como regressores. Em primeiro lugar temos que organizar essas informações no banco de dados de modo coerente. Em sugundo lugar, a introdução de variáveis qualitativas muda a interpretação dos resultados.\nFatores qualitativos geralmente aparecem na forma de informações binários, também denominadas,dummy.\nVariável Binária ou Dummy: É uma variável que assume o valor 1 se a “condição occorre” e 0 caso o contrario.\nExemplos: O crime de feminicio ocorreu na região central? se sim, ela recebe o valor 1, se não recebe o valor 0. Podemos ter uma coluna em nosso banco de dados denominada centro, nas quais a linha recebe o valor 1 caso o crime tenha ocorrido, por exemplo, no centro e 0 caso o contrário.\nO crime foi considerado grave? Se sim, recebe o valor 1 se não recebe o valor 0.\nSuponha que queiramos investigar descriminação de gênero no mercado de trabalho. Se tivermos uma base de dados com informçoes sobre diversos individuos como anos de estudo, experiencia no mercado de trabalho. Podemos ter também uma variavel binaria que assume o valor 1 caso o individuo na amostra for do sexo feminino ou 0 caso o contrario.\nO mesmo pode acontecer com etnia. Podemos ter uma dummy que assuma o valor 1, caso o individuo seja autodeclarado não-branco e 0, caso o contrario.\nAs observações que tiveram 1 como valor serão comparadas com aquelas observações que ficaram com o valor 0. Essas observações seriam nosso “grupo de comparação/grupo base”.\nTrabalhar com variáveis qualitativas é muito comum. Na maioria das vezes cabe ao pesquisador o julgamento de trabalhar com uma variável desse tipo.\nUtilizae 1 ou 0 é, de fato, um criterio arbitrario. Todavia, essa escolha reside justamente na vantagem de se capturar informações importantes que tornam a interpretação dos resultados mais simples.\n\n8.7.1 Uma única Variável Dummy Independente\nA forma mais simples de incorporar uma variável qualitativa e simplismente adcionarmos ela na equação de regressão.\nConsidere o exemplo prático. Queremos relacionar anos de estudo e salários. Obviamente, o exemplo é bastante simples, mas será útil para avaliarmos a questão.\n\\[salario = \\beta_0 + \\delta_0 feminino + \\beta_1 educ + \\beta_3 experiencia + u \\] Nesse exemplo, estamos controlando educação e experiência. A variável feminino assume o valor 1, se o individuo for do sexo feminino e 0, caso o contrário, isto é, o indivíduo é um homem. Na equação \\(\\delta_0\\) mede a diferença no salario entre homems e mulheres, dado os mesmos anos de estudos e de experiencia, e evidentemente o mesmo \\(u\\).\nAssim, um indicio de discriminação de genero no mercado de trabalho, seria se encontracemos uma relação do tipo \\(\\delta_0 &lt; 0\\).\nIsso deveria ser interpretado como a diferença da média condicional aos níveis de educação e experiencia, entre homens e mulheres.\nO uso de variáveis dummy pode ser interessante no contexto da análise de políticas públicas.\nConsidere que tenhamos uma base de dados municipal com uma serie dados sobre crimes contra as mulheres. Suponha hipoteticamente que alguns bairros dessa cidade hipotética tenham alguma iniciativa ou política pública local de combate e prevenção desses crimes. Em um primeiro momento suponha que queremos avaliar se nesses bairros a taxa de crimes contra as mulheres é menor. Considere que temos dados sobre o nível educacional médio da população do bairro, a taxa de desemprego nesses bairros, e uma variável que assume o valor 1 se no bairro em questão existe alguma política pública como a mencionada.\nConsidere a equação:\n\\[Tx.feminicidio = \\beta_0 + \\beta_1 desemprego + \\beta_2 educ + \\beta_3 política + u \\] Nesse exemplo, se estimarmos um \\(\\beta_3 &lt; 0\\) teriamos evidências de que em bairros onde há a política pública em questão, a taxa de crimes contra as mulheres é menor. Claramente, estamos supondo que todas as hipoteses mencinadas anteriormente são validadas, de modo que temos estimadores não viesados. Se existir alguma variável omitida em \\(u\\) ou correlação entre \\(u\\) e as variáveis explicativas, sobretudo entre \\(u\\) e nossa dummy de interesse, teremos um estimador viésado de \\(\\beta_3\\) e provavelmente dos demais coeficientes.\n\n\n8.7.2 O uso de Dummies para categorias multiplas.\nConsidere a equação abaixo\n\\[Tx.Condenação = \\beta_0 + \\beta_1  idade  +  \\beta_2 Local  + \\beta_3  crime + u\\] Suponha que nossas unidades de observação sejam indivíduos na cidade de São Paulo. Suponha que o local, seja o local do crime e represente as cinco zonas da cidade de São Paulo. Da forma como esta na regressão teriamos de escolher apenas uma Zona para avaliar (assumindo o valor 1), e as demais seriam as categorias bases. Pode ser interessante, caso nosso interresse resida na região em questão. Não obstante, podemos avaliar mais categorias.\nTemos 5 zonas na cidade de São Paulo. Nesse caso, precisamos utilizar uma delas como grupo base. Supoha que tal zona seja o Centro. Nosso modelo fica da seguinte maneira\n\\[Tx.Condenação = \\beta_0 + \\beta_1  idade  +  \\beta_2 Leste+  \\beta_3 Sul +  \\beta_4 Oeste   + \\beta_5 Norte + \\beta_6  crime + u\\]\nO mesmo deve ocorrer no tipo de crime. Suponha que por algum motivo razoavel classificamos os crimes em 3 categorias 1, 2 e 3, e queremos utilizar a categoria 2 como grupo base. Nesse caso, apenas rodamos a regressão com os crimes do tipo 1 e 2 :\n\\[Tx.Condenação = \\beta_0 + \\beta_1  idade  +  \\beta_2 Leste+  \\beta_3 Sul +  \\beta_3 Oeste   + \\beta_5 Norte + \\beta_6  crime1 + \\beta_7  crime3 u\\]\nO coeficiente estimado de \\(\\beta_3\\), por exemplo, captaria a diferença média da taxa de condenação entre crimes que ocorrem na região Sul e o Centro da cidade de São Paulo, controlado para o mesmo tipo de crime e idade do indivíduo. Ja o coeficiente \\(\\beta_6\\) mediria a diferença de media entre a taxa de condenação para crimes do 1 e crimes do tipo 2, controlados pela localidade e idade do indivíduo.\n\n\n8.7.3 Incorporando Informações Ordinais com o uso de Variáveis Dummy.\nDeterminação de Fatores que Afetam o Valor de Indenizações: Variáveis Independentes: Idade da Vítima e Gravidade do Dano . Variável Dependente: Valor da Indenização.Objetivo: Analisar como a idade da vítima, a gravidade do dano influenciam o valor das indenizações concedidas.\n\\[Indenização = \\beta_0 + \\beta_1 idade+ \\beta_2 Gravidade  + u\\] Suponha que a gravidade varie em uma escala de 0 a 4. Uma posibilidade seria estimar a equação acima, tal qual específicada.\nInfelizmente, seria muito dificil interpretar um aumento de uma unidade na gravidade. Uma vez que a gravidade de um crime é medida de maneira ordinal. Por exemplo uma Gravidade de um crime classificada como 4 é maior que a Gravidade de um crime classificada como 3.\nUtilizando o que já aprendemos, podemos utilizar a categoria de gravidade=0 (não grave) como base de comparação. Nesse caso estimariamos a seguinte regressão:\n\\[Indenização = \\beta_0 + \\beta_1 idade+ \\beta_2 Grav1  ++ \\beta_3 Grav2  ++ \\beta_4 Grav3  ++ \\beta_5 Grav4 + u\\] onde \\(\\beta_2\\) por exemplo, capta a diferença na indenização de uma crime de gravidade 1 em comparação de um crime com gravidade igual a 0."
  },
  {
    "objectID": "lineares.html#alguns-problemas-que-podem-surgir-na-análise-de-regressão",
    "href": "lineares.html#alguns-problemas-que-podem-surgir-na-análise-de-regressão",
    "title": "7  Modelos Lineares",
    "section": "9.8 Alguns Problemas que podem surgir na análise de regressão",
    "text": "9.8 Alguns Problemas que podem surgir na análise de regressão\n\n9.8.1 Viés de Variável Omitida\n\n\n9.8.2 Multicolinearidade\n\n\n9.8.3 Heteroscedasticidade"
  },
  {
    "objectID": "lineares.html#hipótese-de-normalidade",
    "href": "lineares.html#hipótese-de-normalidade",
    "title": "6  Modelos Lineares",
    "section": "9.1 Hipótese de Normalidade",
    "text": "9.1 Hipótese de Normalidade"
  },
  {
    "objectID": "lineares.html#teste-de-hipotese-sob-um-unico-parametro",
    "href": "lineares.html#teste-de-hipotese-sob-um-unico-parametro",
    "title": "7  Modelos Lineares",
    "section": "10.2 Teste de Hipotese sob um unico Parametro",
    "text": "10.2 Teste de Hipotese sob um unico Parametro\n\n10.2.1 Teste contra Hipoteses Alternativas Unilaterais\n\n\n10.2.2 Teste contra Hipoteses Alternativas Bilaterais\n\n\n10.2.3 Cálculos dos p-valores dos Testes t\n\n\n10.2.4 Teste de Restrições de Lineares Múltiplas: O teste F"
  },
  {
    "objectID": "lineares.html#teste-de-hipótese-sob-um-único-parametro",
    "href": "lineares.html#teste-de-hipótese-sob-um-único-parametro",
    "title": "6  Modelos Lineares",
    "section": "9.2 Teste de Hipótese sob um Único Parametro",
    "text": "9.2 Teste de Hipótese sob um Único Parametro\n\n9.2.1 Teste contra Hipoteses Alternativas Unilaterais\n\n\n9.2.2 Teste contra Hipoteses Alternativas Bilaterais\n\n\n9.2.3 Cálculos dos p-valores dos Testes t\n\n\n9.2.4 Teste de Restrições de Lineares Múltiplas: O teste F"
  },
  {
    "objectID": "lineares.html#multicolinearidade-pefeita",
    "href": "lineares.html#multicolinearidade-pefeita",
    "title": "6  Modelos Lineares",
    "section": "10.1 5.1 - Multicolinearidade Pefeita",
    "text": "10.1 5.1 - Multicolinearidade Pefeita\nA multicolinearidade é uma violação da hipótese 3. Nesse caso as variáveis ou alguma das variáveis podem ser escritas como uma combinação linear das demais. Esse é um caso extremo e que, no limite, não aparece com frequência nas aplicaçoes empíricas. Não obstante, uma multicolinearidade alta pode aparecer. Na presença de Multicolinearidade, nossos estimadores continuam sendo não viésados. Entretanto, a variância de \\(\\hat{\\beta_j}\\) pode ficar muito elevada, prejudicando os procedimentos de inferência.\nPodemos ver isso ao avaliarmos a formula da variância de uma dado \\(\\hat{\\beta_j}\\) estimado:\n\\[\\text{Var}(\\hat{\\beta}_j) = \\frac{\\hat{\\sigma}^2}{\\sum_{i=1}^{n} (x_{ij} - \\bar{x_j})^2(1-R^2_j)}=\\frac{\\hat\\sigma^2}{\\text{SQT}_j(1-R^2_j)}\\]\nNote que, se a relação linear entre os \\(x_1,...,x_k\\) forem elevadas, o \\(R^2_j\\) será alto. No limite, um \\(R^2_j\\) proximo de faz o denominador da divisão acima ficar muito pequeno. Com um denominador pequeno a \\(\\text{Var}(\\hat{\\beta}_j)\\) fica muito alta. No caso em que há multicolinearidade perfeita, o \\(R^2_j =1\\). logo, a \\(Var(\\hat{\\beta_j})\\) não estará nem mesmo definida (haverá um divisão por zero!).\nNa prática o problema da multicolinearidade não é uma unanimidade entre os autores. Muitos livros textos dedicam capítulos interios para tratar do problema, ao passo que outros autores a enxergam como uma mal menor.\nA razão de se enchergar a multicolinearidade como uma mal menor é o fato de que ao olharmos novamente para o denominador da variância de \\(\\beta_j\\), veremos que a variância de \\(\\hat{\\beta_j}\\) pode diminuir ao aumentarmos a Soma dos Quadrados dos Totais de \\(x_j\\), \\(SQT_j\\). Isso pode ser feito aumentando o tamanho da amostra, e por conseguinte a variabilidade dos valores de \\(x_j\\). Por isso alguns autores se referem de maneira satírica ao problema da multicolinearidade como o problema da micronumerosidade. A razão disso é que, muitas vezes, nossa variância é alta porque nossa amostra é muito pequena."
  },
  {
    "objectID": "lineares.html#heteroscedasticidade",
    "href": "lineares.html#heteroscedasticidade",
    "title": "6  Modelos Lineares",
    "section": "10.2 Heteroscedasticidade",
    "text": "10.2 Heteroscedasticidade\nA heteroscedasticidade é a violação da hipótese de homoscedasticidade. Nesse caso, a variância do termo de erro \\(u\\) deixa de ser constante. Logo cada observação passa a ter sua própria variância.\nNão entraremos nos detalhes técnicos de como resolver o problema. Felizmente, a heterocesdasticidade pode ser detectada e corrigida sem grandes problemas.\nA heteroscedasticidade, embora não interfira no viés das estimativas de MQO, interfere na variância. Quando ela esta presente nossos estimadores de MQO não serão mais eficientes. Isto é, MQO deixa de ter variância mínima. Com isso os erros padrão reportados pelo software estátistico serão problemáticos e todo nosso procedimento de inferência poderá estar comprometido.\nUma saída é computar erros-padrão robustos para nossos estimadores. Tais erros padrão robustos à heteroscedasticidade são maiores que os erros padrão convencionais. Não obstante, podemos nos resguardar do problema da heteroscedasticidade.\nVamos verificar isso com um exemplo:\n\n### Aplicação: Erros Padrão Robustos à Heteroscedasticidade\n\nPara detectar formalmente a heteroscedasticidade, podemos utilizar os seguintes testes: teste de Breusch-Pagan (BP) e o Teste de White.\n\n####Teste de Breusch-Pagan para Heteroscedasticidade\n\n\n\n#####Teste de White para a detecção de Heteroscedasticidade"
  },
  {
    "objectID": "lineares.html#viés-de-variável-omitida-e-a-correlação-entre-as-variáveis-explicativas-e-o-termo-de-erro.",
    "href": "lineares.html#viés-de-variável-omitida-e-a-correlação-entre-as-variáveis-explicativas-e-o-termo-de-erro.",
    "title": "6  Modelos Lineares",
    "section": "10.3 Viés de Variável Omitida e a Correlação entre as variáveis explicativas e o termo de Erro.",
    "text": "10.3 Viés de Variável Omitida e a Correlação entre as variáveis explicativas e o termo de Erro."
  },
  {
    "objectID": "descritiva.html",
    "href": "descritiva.html",
    "title": "6  Análise Descritiva",
    "section": "",
    "text": "7 Conceitos Básicos de Probabilidade e Estatística"
  },
  {
    "objectID": "descritiva.html#probabilidade-conceitos-básicos",
    "href": "descritiva.html#probabilidade-conceitos-básicos",
    "title": "6  Análise Descritiva",
    "section": "7.1 Probabilidade Conceitos Básicos",
    "text": "7.1 Probabilidade Conceitos Básicos"
  },
  {
    "objectID": "descritiva.html#medidas-de-tendência-central",
    "href": "descritiva.html#medidas-de-tendência-central",
    "title": "6  Análise Descritiva",
    "section": "6.3 Medidas de Tendência Central",
    "text": "6.3 Medidas de Tendência Central"
  },
  {
    "objectID": "descritiva.html#variáveis-aleatórias-e-esperança-matématica",
    "href": "descritiva.html#variáveis-aleatórias-e-esperança-matématica",
    "title": "6  Análise Descritiva",
    "section": "6.4 Variáveis Aleatórias e Esperança Matématica",
    "text": "6.4 Variáveis Aleatórias e Esperança Matématica\n\n6.4.1 Uma Breve Introdução as Variáveis Aleatórias Conjuntamente Distribuídas"
  },
  {
    "objectID": "descritiva.html#conceitos-básicos-inferência-estatística",
    "href": "descritiva.html#conceitos-básicos-inferência-estatística",
    "title": "4  Análise Descritiva",
    "section": "4.3 Conceitos Básicos Inferência Estatística",
    "text": "4.3 Conceitos Básicos Inferência Estatística\nDado a nossa pergunta ou problema, gostariamos de saber as carcateística de uma população.\nEntretantom um processo de levantamento de informações é em geral caro e em muitas situações é destrutivo. Em ciências sociais estamos interessados em características de pessoas, empresas, municípios, estados, países etc. Não é destrutivo mas é uma coleta cara. Por exemplo, o Censo demográfico de 2010 custou R$ 1,3 bilhões, ou aproximadamente R$ 2,2 bi em reais de 2020. O valor é de aproximadamente R$ 35,00 por domicílio.\nDessa forma nosso objetivo aqui é:\n\n\n\n\n\n\nObjetivo\n\n\n\nA partir de uma amostra da população realizar inferência sobre toda a população\n\n\n\n4.3.1 Exemplos do príncipio no dia a dia\nPense nessas situações:\n\nPara medir a glicose muitos pacientes usam uma gota de sangue e um pequeno aparelho. A partir dele sabem quanto tem no corpo todo, basta uma gota para termos boa certeza de quanto é taxa de glicose!\nPara saber se a quantidade de sal está adequada em uma grande panela de arroz, basta uma pequena colher de chá para termos uma boa certeza!\nAbacaxis às vezes são vendidos em caminhões na rua. Quando paramos provamos e são doces. Compramos 4 por 10. Qual a certeza que esses que vc está levando estejam também doces? É diferente das situações anteriores?\n\nCom certeza vc deve ter pensado que essas situações tem grau de certeza variáveis. A diferença está em quão homogênea é a característica na população, o sal no arroz e a glicose no sangue devem ser muito bem distribuidas, ou seja, bem homogêneas. Já a doçura no abacaxi deve ter distribuição maior e provar apenas um abacaxi não nos dá uma ideia do todo.\nEsse é um erro muito comum, a partir de uma ou poucas observações dizer que o todo se comporta da mesma maneira, esse erro se agrava quando maior é a heterogeneidade!!!\n\n\n4.3.2 População, Amostra, Parâmetros e Estimadores\n\n\n4.3.3 População e amostra\n\n\n\n\nflowchart LR\n  A[POPULAÇÃO] --&gt; B[Totalidade das observações sob Investigação]\n  A --&gt; C[AMOSTRA]\n  C --&gt; D[Subconjunto da População]\n\n\n\n\n\nA definição da população depende da pergunta de pesquisa ou análise. Se queremos saber qual o salário médio dos empregados do setor industrial no estado de São Paulo para determinado ano, nossa população são todos os funcionários das indústrias instaladas no estado de São Paulo para esse ano. Se queremos os determinantes do desempenho escolar dos alunos do ensino fundamental no Brasil em 2019, nossa população será esse grupo de alunos nesse ano. Se quisermos avaliar o gasto municipal no ano anterior as eleições no Brasil, temos nossa população formada pelos municípios para o ano de análise.\n\n\n\n\n\n\nPopulação\n\n\n\nQuem define a população é o objetivo do seu trabalho!! Ou seja, seu problema de pesquisa\n\n\n\n\n4.3.4 Amostragem Aleatória Simples\nExistem várias maneiras de fazer uma análise aleatória, uma delas é a simples. Vejamos primeiro um processo de amostragem não aleatório e que possui tendenciosidade. A figura abaixo mostra esse processo[^7]:\n\n\n\nUm processo de amostragem viesádo. Fonte:Data Basecamp\n\n\nObserva-se que existe uma supervalorização do vermelho e uma subvalorização do azul. Chegariamos a conclusão, caso isso fosse uma pesquisa eleitoral, que o candidato vermelho, segunda amostra teria mais chance de ganhar e o azul quase nenhuma chance. O que não condiz com a população. Dizemos que temos uma amostra viesada ou tendenciosa.\nUm processo de amostragem aleatório requer que as características presentes na população estejam presentes na amostras e estejam balanceadas, ou seja, que a sua leitura represente bem o todo."
  },
  {
    "objectID": "manipulacao.html#criando-um-projeto",
    "href": "manipulacao.html#criando-um-projeto",
    "title": "5  Manipulação de Dados",
    "section": "5.1 Criando um projeto",
    "text": "5.1 Criando um projeto\nPrimeiramente precisamos criar um projeto. Clique no icone +R crie um projeto chamado feminicídio em uma nova pasta"
  },
  {
    "objectID": "manipulacao.html#instalando-os-packages-necessários",
    "href": "manipulacao.html#instalando-os-packages-necessários",
    "title": "5  Manipulação de Dados",
    "section": "5.2 Instalando os Packages Necessários",
    "text": "5.2 Instalando os Packages Necessários"
  },
  {
    "objectID": "manipulacao.html#regressão-linear-simples---rls",
    "href": "manipulacao.html#regressão-linear-simples---rls",
    "title": "5  Maipulando os Dados",
    "section": "5.1 Regressão Linear Simples - RLS",
    "text": "5.1 Regressão Linear Simples - RLS\nVamos iniciar o estudo de modelos lineares começando pela Regresão Linear Simples (RLS). Mais específicamente, vamos estudar a RLS no contexto de dados de corte transversal. Tal abordagem, segmentada por tipos de dados, facilíta o entendimento das hipóteses do modelo."
  },
  {
    "objectID": "manipulacao.html",
    "href": "manipulacao.html",
    "title": "5  Maipulando os Dados",
    "section": "",
    "text": "6 O R-project e as Boas Práticas"
  },
  {
    "objectID": "manipulacao.html#o-software-r",
    "href": "manipulacao.html#o-software-r",
    "title": "5  Maipulando os Dados",
    "section": "6.1 O software R",
    "text": "6.1 O software R\nO R é uma linguagem e ambiente de desenvolvimento de Estatística e gráficos. É uma ferramenta poderosa, fornecendo ao seu usuário maior integração e qualidade gráfica e de análise. Alguns motivos para utilizar o R:\n\nÉ Gratuito: é um projeto open-source. Pode ser utilizado em qualquer sistema operacional e tem aberto seus códigos e pactos para poder ser inspecionado.\nR é uma Linguagem:Requer que seja escrito um script ao invés de clicar. A primeira vista uma característica negativa, entretanto, permite maior exploração, organização, memória da atividade, maior integração entre processos etc.\nGráficos e Visualizações: É sem sombra de dúvida o pacote estatístico com melhor e mais poderosa ferramenta de elaboração de gráficos e visualização.\nPacotes Estatísticos:Já possui muitas rotinas de análises já programadas nos diversos pacotes desenvolvidos, sendo muito bem documentados. Já possui muitas rotinas para regressão, regressão com séries temporais, regressão em painel, finanças, modelos de causalidade etc.\nFronteira do Conhecimento: Os principais desenvolvimentos teóricos em Econometria tem sua aplicação demonstrada e desenvolvida utilizando o R. Isso é valido para todas as subáreas do conhecimento em econometria, séries temporais, painel, finanças, etc.\nRecursos de Ajuda: Há uma comunidade muito grande disponível para solucionar dúvidas e uma vasta documentação disponível para consulta na rede.\nConexão com Outros Pacotes: O R integra com outros pacotes que automatizam o nosso trabalho cotidiano. Pode se conectar com o Python, Java, SQL, Latex etc."
  },
  {
    "objectID": "manipulacao.html#utilizando-interface-gráfica---o-rstudio",
    "href": "manipulacao.html#utilizando-interface-gráfica---o-rstudio",
    "title": "5  Maipulando os Dados",
    "section": "6.2 Utilizando Interface Gráfica - O Rstudio",
    "text": "6.2 Utilizando Interface Gráfica - O Rstudio\nPode-se realizar seu script diretamente no console do R. Ele irá realizar um comando por vez. O R é uma interface leve e com poucos recursos gráficos.\nUma alternativa ao uso do R diretamente é o Rstudio, o qual é um editor de código ou um ambiente de desenvolvimento integrado. Ele possui quatro janelas, sendo a primeira a janela de script (superior esquerda) onde escrevemos os comandos em R.\nA segunda janela é o console (inferior esquerda) similar ao que temos no R e onde os resultados são apresentados. Pode-se digitar comando diretamente no console do RStudio.\nA terceira é a janela de ambiente e história (superior direita) ela armazena seus dados, valores e funções e a aba história possui a memoria dos comandos realizados.\nPor fim a quarta janela (inferior direita) apresenta os pacotes, os gráficos, os arquivos gerados e ajuda. Essa janela facilita a instalação de pacotes, carregamento de bibliotecas, visualização de gráficos e o caminho dos arquivos."
  },
  {
    "objectID": "manipulacao.html#ajuda",
    "href": "manipulacao.html#ajuda",
    "title": "5  Maipulando os Dados",
    "section": "6.3 Ajuda",
    "text": "6.3 Ajuda\nPara abrir a ajuda geral o seguinte abaixo pode ser utilizado e abrirá uma janela no seu navegador.\n\nhelp.start()\n\nSuponha que queiramos saber de uma função específica, assim pode-se utilizar o seguinte comando:\n\nhelp(summary)\n\nou\n\n?summary\n\nInclusive pode pedir um exemplo de como utilizar a função que está buscando\n\nexample(summary)"
  },
  {
    "objectID": "manipulacao.html#boas-práticas",
    "href": "manipulacao.html#boas-práticas",
    "title": "5  Maipulando os Dados",
    "section": "6.4 Boas Práticas",
    "text": "6.4 Boas Práticas\nÉ fundamental que o usuário seja organizado. Forma é muito importante! Assim o usuário deve adotar padrões que auxiliem na organização do seu script ou programa.\nCase Sensitivy: O R diferencia letras minúsculas e maiúscula. Ou seja, m é diferente de M. Por exemplo, considere as três formas de escrever a palavra idade.\n\nidade ou Idade ou IDADE\n\nCada uma delas representa variáveis diferentes.\n\n\n\n\n\n\nDICA\n\n\n\nSempre utilize as suas variáveis em minúsculo. Adote isso como regra geral.\n\n\nCriando Bons Nomes: Vamos supor que queiramos criar uma variável que indique a idade que se formou na Universidade. Temos algumas opções:\n\nid: Ruim, pois não tem significado claro e pode confundir com a variável de identificação\nidade_formou_na_universidade: Ruim, pois o nome da variável é muito grande, difícil de escrever e de visualizar no banco de dados.\nidade_form: Bom nome, significativo, minúsculo e pequeno separa os dois nomes por underline\nidadeForm :Bom nome, significativo, minúsculo e pequeno separa os dois nomes por uma letra maiúscula.\n\n\n\n\n\n\n\nDICA\n\n\n\nAdote uma regra de criação para você e evite mudar. Crie nomes pequenos e significativos. Nunca inicie uma variável com número."
  },
  {
    "objectID": "manipulacao.html#criando-projeto-no-r",
    "href": "manipulacao.html#criando-projeto-no-r",
    "title": "5  Maipulando os Dados",
    "section": "6.5 Criando projeto no R",
    "text": "6.5 Criando projeto no R\nPara saber em qual diretório o R está utilizando para salvar seu espaço de trabalho utilize o seguinte comando:\n\ngetwd() \n\nNo RStudio, sempre prefira a criação de um projeto para a organização de seus dados, com isso, ao mudar de máquina (ou estrutura de diretórios) seu código continuará funcionando normalmente.\n\n  File -&gt; New Project"
  },
  {
    "objectID": "manipulacao.html#identação-é-importante",
    "href": "manipulacao.html#identação-é-importante",
    "title": "5  Maipulando os Dados",
    "section": "6.6 Identação é Importante",
    "text": "6.6 Identação é Importante\nIdentar é o recuo no texto em relação a margem. É importante que esse recuo exista para linhas do seu programa que são hierarquicamente conectadas. Vejamos dois exemplos com e sem identação:\nSem Identação\n\nx=c()\nx[1] = 3\nfor (i in 2:9) { \nx[i]=2*x[i-1]\n}\n\nNote que a quarta linha desse programa está hierarquicamente conectada a linha 3 do “for”, ou seja, é uma continuação do comando e portanto deve ser identado para demonstrar essa relação de dependência. Vejamos\nCom Identação\n\nx=c()\nx[1] = 3\nfor (i in 2:9) { \n  x[i]=2*x[i-1]\n}"
  },
  {
    "objectID": "manipulacao.html#tipos-de-variáveis",
    "href": "manipulacao.html#tipos-de-variáveis",
    "title": "5  Maipulando os Dados",
    "section": "7.1 Tipos de Variáveis",
    "text": "7.1 Tipos de Variáveis\nO R possui diversos tipos de variáveis. Alguns desses tipos são:\nVetores: Vamos inserir os dados denúmero de homicídios de mulheres nos diversos Estados brasileiros para o ano de 2022.No primeiro elemento teremos um erro, ao invés de 22 colocaremos 2.E não colocamos o valor do Distrito Federal e nem Tocantins\n\nhomic &lt;- c(2,  73,  22,  88,  406,  264,    95,  137,  127,  101,  75,  309,  200,  86,  256,  219,  70,  283,  60,  281,  88,  33,  101,  423,  37)\nhomic\n\n [1]   2  73  22  88 406 264  95 137 127 101  75 309 200  86 256 219  70 283  60\n[20] 281  88  33 101 423  37\n\n\nPodemos inserir vetores de texto, por exemplo, iremos inserir os estados brasileiros na mesma ordem do homicídio acima.\n\n\n [1] \"Acre\"                \"Alagoas\"             \"Amapá\"              \n [4] \"Amazonas\"            \"Bahia\"               \"Ceará\"              \n [7] \"Distrito Federal \"   \"Espírito Santo\"      \"Goiás\"              \n[10] \"Maranhão\"            \"Mato Grosso\"         \"Mato Grosso do Sul\" \n[13] \"Minas Gerais\"        \"Pará\"                \"Paraíba\"            \n[16] \"Paraná\"              \"Pernambuco\"          \"Piauí\"              \n[19] \"Rio de Janeiro\"      \"Rio Grande do Norte\" \"Rio Grande do Sul\"  \n[22] \"Rondônia\"            \"Roraima\"             \"Santa Catarina\"     \n[25] \"São Paulo\"           \"Sergipe\"             \"Tocantins\"          \n\n\nAlgumas manipulações importantes que podemos fazer com os vetores. Renomeando e removendo o vetor antigo:\nTrocando o primeiro elemento do vetor e dando o print do novo resultado:\n\nhomic_abs[1]=22\nhomic_abs\n\n [1]  22  73  22  88 406 264  95 137 127 101  75 309 200  86 256 219  70 283  60\n[20] 281  88  33 101 423  37\n\n\nAlgumas maneiras de pedir o print do vetor de homicídios femininos. Somente o estado 7, todos menos o estado 7, Estado de 1 até 7 etc:\n\nhomic_abs[7] \n\n[1] 95\n\nhomic_abs[-7] \n\n [1]  22  73  22  88 406 264 137 127 101  75 309 200  86 256 219  70 283  60 281\n[20]  88  33 101 423  37\n\nhomic_abs[1:7]\n\n[1]  22  73  22  88 406 264  95\n\n\nPodemos incorporar novos dados no nosso vetor de homicídio feminino, Vamos incorporar o dado do Tocantins na posição 7 e o valor do Distrito Federal na útima posição - 27. Depois trocaremos os dois estados de posição:\n\n#colcar exemplo de inserir no inicio\n\n#inserir no meio e no final \nhomic_abs &lt;- c(homic_abs[1:6], 36,homic_abs[7:25], 32)\nhomic_abs\n\n [1]  22  73  22  88 406 264  36  95 137 127 101  75 309 200  86 256 219  70 283\n[20]  60 281  88  33 101 423  37  32\n\n#troca de posicoes\ntemp &lt;- homic_abs[27]\nhomic_abs[27] &lt;- homic_abs[7]\nhomic_abs[7] &lt;- temp\nhomic_abs\n\n [1]  22  73  22  88 406 264  32  95 137 127 101  75 309 200  86 256 219  70 283\n[20]  60 281  88  33 101 423  37  36\n\n\nString ou Texto:\nString são as variáveis tipo texto. Esse tipo de variável já apareceu na seção anterior quando apresentamos um vetor com a classificação dos Estados. Vejamos mais uma vez. Podemos criar uma variável que contêm “estado homicidio”. Uma segunda maneira é criar um vetor com dois elementos “estado” e “homicidio”. O comando paste cola a variável texto “estado” e a variável texto “homicidio”, separado por um espaço.\n\na &lt;- \"estado homicidio\"\na\n\n[1] \"estado homicidio\"\n\nb &lt;- c(\"estado\",\"homicidio\")\nb\n\n[1] \"estado\"    \"homicidio\"\n\nb[1]\n\n[1] \"estado\"\n\npaste(b[1],b[2],sep=' ')\n\n[1] \"estado homicidio\"\n\n\nFator:\nFator são variáveis de classe. Fator armazenam os valores inteiros na forma de um vetor com as quantidades das k classes e o vetor string dos valores originais. Vejamos o exemplo de um vetor. Podemos análisar os homicídios por região geográfica do país. Assim, classificaremos os estados por região:\n\nregiao &lt;- c(\"N\",  \"NE\",  \"N\",  \"N\",  \"NE\",  \"NE\",  \"CO\",  \"SD\",  \"CO\",  \"NE\",  \"CO\",  \"CO\",  \"SD\",  \"N\",  \"NE\",  \"S\",  \"NE\",  \"NE\",  \"SD\",  \"NE\",  \"S\",  \"N\",  \"N\",  \"S\",  \"SD\",  \"NE\",  \"N\")\nsummary(regiao)\n\nAgora vamos transformar o vetor anterior em um fator\n\nregiao &lt;- factor(regiao)\nsummary(regiao)\n\nCO  N NE  S SD \n 4  7  9  3  4 \n\nlevels(regiao)\n\n[1] \"CO\" \"N\"  \"NE\" \"S\"  \"SD\"\n\n\nO comando levels fornece as classes existentes, no caso acima temos 5, sendo elas 4, 7, 9, 3 e 4.\nFatores podem ser as características de raça, gênero, status familiar, status de saúde, qualidade do atendimento etc.\n\n7.1.1 Data Frame ou Banco de Dados\nEsse é um tipo mais geral de variável e consegue lidar na mesma estrutura com variaveis de tipos distintos como numérica, texto e fator. Um banco de dados similar aos outros programas estatísticos. Podemos criar essa variável de forma manual. Nosso banco de dados será composto por 4 variáveis, a primeira o estado, a segunda a região, a terceira o número de homicídios femininos e a quarta o número de feminicidios. As três primeiras já foram incluidas acima e vamos criar somente a quarta. O comando typeof mostra qual o tipo de variável.\n\nfeminic_abs=c(11,  31,  8,  21,  107,  28,  19,  33,  56,  69,  47,  40,  171,  49,  26,  77,  72,  24,  111,  16,  110,  24,  3,  56,  195,  19,  14) \ntypeof(feminic_abs)\n\n[1] \"double\"\n\n\nPara criar o banco de dados utilizamos o seguinte comando:\n\ndata_feminic22&lt;-data.frame(estados, regiao, homic_abs, feminic_abs)  \n\nPodemos modificar o nome das variáveis com o comando names. Entretanto, tem que renomear todas\n\nnames(data_feminic22)&lt;-c(\"estado\", \"regioa\", \"homic_abs\", \"feminic_abs\") \ndata_feminic22\n\nOu podemos renomear somente algumas com o comando reshape:\n\nlibrary(reshape)\ndata_feminic22 &lt;- rename(data_feminic22, c(estado=\"estados\", regioa=\"regiao\"))\ndata_feminic22\n\n               estados regiao homic_abs feminic_abs\n1                 Acre      N        22          11\n2              Alagoas     NE        73          31\n3                Amapá      N        22           8\n4             Amazonas      N        88          21\n5                Bahia     NE       406         107\n6                Ceará     NE       264          28\n7    Distrito Federal      CO        32          19\n8       Espírito Santo     SD        95          33\n9                Goiás     CO       137          56\n10            Maranhão     NE       127          69\n11         Mato Grosso     CO       101          47\n12  Mato Grosso do Sul     CO        75          40\n13        Minas Gerais     SD       309         171\n14                Pará      N       200          49\n15             Paraíba     NE        86          26\n16              Paraná      S       256          77\n17          Pernambuco     NE       219          72\n18               Piauí     NE        70          24\n19      Rio de Janeiro     SD       283         111\n20 Rio Grande do Norte     NE        60          16\n21   Rio Grande do Sul      S       281         110\n22            Rondônia      N        88          24\n23             Roraima      N        33           3\n24      Santa Catarina      S       101          56\n25           São Paulo     SD       423         195\n26             Sergipe     NE        37          19\n27           Tocantins      N        36          14\n\n\nPodemos também listar variáveis do banco de dados, por exemplo, listar colunas de 1 a 2 ou listar por nome das variáveis, conforme apresentado abaixo:\n\ndata_feminic22\ndata_feminic22[,2:3]\ndata_feminic22[1:2,2:3]\ndata_feminic22[c(\"regiao\",\"feminic_abs\")]\n\nEntretanto, inserir dados na mão pode ser uma tarefa muito penosa e existem soluções bem mais simples e rápidas para inserção de dados. Nas seções seguintes veremos aprenderemos mais funções úteis para lidar com banco de dados.\n\n\n7.1.2 Trabalhando com as variáveis:\nVamos retomar duas variáveis homic_abs e estado e vamos manipular essas duas variáveis. Primeiramente vejamos o número de elementos, estrutura, classe e nome:\n\nlength(homic_abs) \n\n[1] 27\n\nstr(homic_abs)    \n\n num [1:27] 22 73 22 88 406 264 32 95 137 127 ...\n\nclass(homic_abs)  \n\n[1] \"numeric\"\n\nnames(homic_abs) \n\nNULL\n\n\nObservamos que a variável não possui labels. Vamos colocar os Labels nessa variável, ou seja, os rótulos.\n\nnames(dolar15) &lt;-c(\"cambio15_jan\",\"cambio15_fev\",\"cambio15_mar\",\"cambio15_abr\",\n                   \"cambio15_mai\",\"cambio15_jun\",\"cambio15_jul\",\"cambio15_ago\",\n                   \"cambio15_set\",\"cambio15_out\",\"cambio15_nov\",\"cambio15_dez\") \n\nPodemos combinar as duas variáveis de forma distintas, por exemplo combinar na forma de um vetor, combinar como coluna ou combinar como linha, vejamos a diferença:\n\n#Precisa mudar essa parte de posição está confuso pois falamos de dataframe e aqui de vetor\ncomb1 &lt;- c(homic_abs,estados)      \ncomb2&lt;- cbind(homic_abs,estados)\ncomb3 &lt;-rbind(homic_abs,estados)\ncomb4 &lt;- data.frame(\n              homic_abs,\n              estados\n              ,stringsAsFactors = F)\ncomb1\ncomb2 \ncomb3\ncomb4\n\nVejamos quais objetos temos e vamos pedir para visualizar os objetos que acabamos de criar. Por fim removeremos o vetor comb1.\n\nls()  \ncomb1\ncomb2\ncomb3\nrm(comb1)"
  },
  {
    "objectID": "manipulacao.html#importando-os-dados",
    "href": "manipulacao.html#importando-os-dados",
    "title": "5  Maipulando os Dados",
    "section": "7.2 Importando os Dados",
    "text": "7.2 Importando os Dados\nDisponibilizamos dois banco de dados, um contendo os homicídios e feminicídios por estado e outro com as tentativas. Esses arquivos estão em formato csv (comma separated values).\nPara leitura desse arquivo em csv o seguinte comando é necessário read.csv, indicado que possui cabeçalho e que o separador é “;”\n\ndf_feminic22&lt;-read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/dados_feminic.csv\", head=TRUE,sep=\";\")\n\ndf_t_feminic22&lt;-read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/dados_tent_feminic.csv\", head=TRUE,sep=\";\")\n\nPara leitura de arquivos em Stata terá que utilizar o pacote foreign, conforme exemplo abaixo:\n\nlibrary(foreign)\nstata_feminic &lt;- read.dta(\"~/feminic.dta\")\n\nAlém desses, o R é capaz de trabalhar com SQL, SAS, SPSS, Excel entre outros.\n\n\n\n\n\n\nCuidado com o Ponto\n\n\n\nO R usa o formato americano de separação numérica. Usa ponto ao invés da vírgula para separar a unidade dos decimais. No Brasil usamos a vírgula. Isso sempre gera conflito. No seu csv evite usar acentos nas palavras e use ponto como separados dos decimais e não use separador dos milhares. Exemplo: 12500.97"
  },
  {
    "objectID": "manipulacao.html#exportanto-os-dados",
    "href": "manipulacao.html#exportanto-os-dados",
    "title": "5  Maipulando os Dados",
    "section": "7.3 Exportanto os Dados",
    "text": "7.3 Exportanto os Dados\nPodemos exportar os dados em diferentes formatos. Alguns exemplos são csv, texto delimitado, excel, stata. Vejamos em csv:\n\nwrite.table(df_feminic22, \"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/export_feminic.csv\", sep=\";\")\n\nPara exportar em Stata utilize os seguintes comandos:\n\nlibrary(foreign)\nwrite.dta(df_feminic22, paste(getwd(),\"~/Banco de dados/export_feminic.dta\",sep=''))"
  },
  {
    "objectID": "manipulacao.html#características-dos-dados",
    "href": "manipulacao.html#características-dos-dados",
    "title": "5  Maipulando os Dados",
    "section": "7.4 Características dos Dados",
    "text": "7.4 Características dos Dados\n\n7.4.1 Lidando com Dados Missing\nNão temos informação para as tentativas de feminicidio para os estados de São Paulo e Mato Grosso. Uma maneira de lidar com valores missing seria fazer um subconjunto que veremos mais a frente. Agora seguiremos alguns passos para analisar os valores missing do nosso banco de dados.\nPrimeiramente, analisamos se há valores missing no banco de dados:\n\nis.na(df_t_feminic22)\n\nPodemos desconsiderar os valores missing da análise de interesse, vamos fazer a média do dolar sem considerar os valores missing:\n\nmean(df_t_feminic22$t_feminic_abs) \n\n[1] NA\n\nmean(df_t_feminic22$t_feminic_abs, na.rm=TRUE)\n\n[1] 102.52\n\n\nPodemos criar um novo banco de dados sem os valores missing.\n\ndf_t_feminic22_sem_missing &lt;- na.omit(df_t_feminic22)\nmean(df_t_feminic22_sem_missing$t_feminic_abs)\n\n[1] 102.52\n\nrm(df_t_feminic22_sem_missing)\n\nOutra maneira de excluir os valores missing seria a utilização do comando subset removendo as observações que contenham valor missing. Isso será explicado em seção a frente.\nPode-se também recodificar uma determinada variável para missing. Muito comum nas pesquisas do IBGE os valores missing serem identificados por um número, por exemplo 999999999999. Dessa forma podemos indicar que esse não é número e sim um valor missing da seguinte maneira:\n\ndf_t_feminic22$t_feminic_abs[df_t_feminic22$t_feminic_abs==999999] &lt;- NA\n\nTodos os valores que forem 99 serão exluídos e a celula ficará com um NA\n\n\n\n\n\n\nDados Missing\n\n\n\nDoois pontos importantes, dados missing não é 0 e nunca devem ser substituídos por 0. Pois 0 é um valor e missing é que não sabemos. Outro ponto é que devemos evitar excluir do banco os dados missing, melhor é fazer as contas retirando apensa do cálculo"
  },
  {
    "objectID": "manipulacao.html#criando-uma-nova-variável",
    "href": "manipulacao.html#criando-uma-nova-variável",
    "title": "5  Maipulando os Dados",
    "section": "8.1 Criando uma Nova Variável",
    "text": "8.1 Criando uma Nova Variável\nVamos criar uma variável que seria a soma dos homicídios e feminicídios no estado. Para criar a variável precisamos dizer primeiro qual o banco de dados em que queremos criar e qual o nome da variável, conforme apresentado na expressão abaixo.\n\nlibrary(reshape)\ndf_feminic22 &lt;- rename(df_feminic22, c(feminico_abs=\"feminic_abs\"))\n\n\ndf_t_feminic22$t_total_abs&lt;- df_t_feminic22$t_feminic_abs + df_t_feminic22$t_homic_abs\n\ndf_feminic22$total_abs&lt;- df_feminic22$feminic_abs + df_feminic22$homic_abs\n\nAgora vamos criar uma variável binária que representa como 1 os estados que possuem a taxa de feminicídio em relação ao total de homicídios maior que 50%. Novamente, precisamos indicar o banco de dados e o nome da variável no banco de dados.\n\n#attach(dolar_ipa_total1)\ndf_feminic22$mais_50[df_feminic22$part_feminic &lt; 50] &lt;- 0\ndf_feminic22$mais_50[df_feminic22$part_feminic &gt;= 50] &lt;- 1\n#head(dolar_ipa_total1)\n#detach(dolar_ipa_total1)\ndf_feminic22$mais_50\n\n [1] 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0"
  },
  {
    "objectID": "manipulacao.html#operadores-aritméticos-e-lógicos",
    "href": "manipulacao.html#operadores-aritméticos-e-lógicos",
    "title": "5  Maipulando os Dados",
    "section": "8.2 Operadores Aritméticos e Lógicos",
    "text": "8.2 Operadores Aritméticos e Lógicos"
  },
  {
    "objectID": "manipulacao.html#o-r-project-e-as-boas-práticas",
    "href": "manipulacao.html#o-r-project-e-as-boas-práticas",
    "title": "3  Maipulando os Dados",
    "section": "3.1 O R-project e as Boas Práticas",
    "text": "3.1 O R-project e as Boas Práticas\n\n3.1.1 O software R\nO R é uma linguagem e ambiente de desenvolvimento de Estatística e gráficos. É uma ferramenta poderosa, fornecendo ao seu usuário maior integração e qualidade gráfica e de análise. Alguns motivos para utilizar o R:\n\nÉ Gratuito: é um projeto open-source. Pode ser utilizado em qualquer sistema operacional e tem aberto seus códigos e pactos para poder ser inspecionado.\nR é uma Linguagem:Requer que seja escrito um script ao invés de clicar. A primeira vista uma característica negativa, entretanto, permite maior exploração, organização, memória da atividade, maior integração entre processos etc.\nGráficos e Visualizações: É sem sombra de dúvida o pacote estatístico com melhor e mais poderosa ferramenta de elaboração de gráficos e visualização.\nPacotes Estatísticos:Já possui muitas rotinas de análises já programadas nos diversos pacotes desenvolvidos, sendo muito bem documentados. Já possui muitas rotinas para regressão, regressão com séries temporais, regressão em painel, finanças, modelos de causalidade etc.\nFronteira do Conhecimento: Os principais desenvolvimentos teóricos em Econometria tem sua aplicação demonstrada e desenvolvida utilizando o R. Isso é valido para todas as subáreas do conhecimento em econometria, séries temporais, painel, finanças, etc.\nRecursos de Ajuda: Há uma comunidade muito grande disponível para solucionar dúvidas e uma vasta documentação disponível para consulta na rede.\nConexão com Outros Pacotes: O R integra com outros pacotes que automatizam o nosso trabalho cotidiano. Pode se conectar com o Python, Java, SQL, Latex etc.\n\n\n\n3.1.2 Utilizando Interface Gráfica - O Rstudio\nPode-se realizar seu script diretamente no console do R. Ele irá realizar um comando por vez. O R é uma interface leve e com poucos recursos gráficos.\nUma alternativa ao uso do R diretamente é o Rstudio, o qual é um editor de código ou um ambiente de desenvolvimento integrado. Ele possui quatro janelas, sendo a primeira a janela de script (superior esquerda) onde escrevemos os comandos em R.\nA segunda janela é o console (inferior esquerda) similar ao que temos no R e onde os resultados são apresentados. Pode-se digitar comando diretamente no console do RStudio.\nA terceira é a janela de ambiente e história (superior direita) ela armazena seus dados, valores e funções e a aba história possui a memoria dos comandos realizados.\nPor fim a quarta janela (inferior direita) apresenta os pacotes, os gráficos, os arquivos gerados e ajuda. Essa janela facilita a instalação de pacotes, carregamento de bibliotecas, visualização de gráficos e o caminho dos arquivos.\n\n\n3.1.3 Ajuda\nPara abrir a ajuda geral o seguinte abaixo pode ser utilizado e abrirá uma janela no seu navegador.\n\nhelp.start()\n\nSuponha que queiramos saber de uma função específica, assim pode-se utilizar o seguinte comando:\n\nhelp(summary)\n\nou\n\n?summary\n\nInclusive pode pedir um exemplo de como utilizar a função que está buscando\n\nexample(summary)\n\n\n\n3.1.4 Boas Práticas\nÉ fundamental que o usuário seja organizado. Forma é muito importante! Assim o usuário deve adotar padrões que auxiliem na organização do seu script ou programa.\nCase Sensitivy: O R diferencia letras minúsculas e maiúscula. Ou seja, m é diferente de M. Por exemplo, considere as três formas de escrever a palavra idade.\n\nidade ou Idade ou IDADE\n\nCada uma delas representa variáveis diferentes.\n\n\n\n\n\n\nDICA\n\n\n\nSempre utilize as suas variáveis em minúsculo. Adote isso como regra geral.\n\n\nCriando Bons Nomes: Vamos supor que queiramos criar uma variável que indique a idade que se formou na Universidade. Temos algumas opções:\n\nid: Ruim, pois não tem significado claro e pode confundir com a variável de identificação\nidade_formou_na_universidade: Ruim, pois o nome da variável é muito grande, difícil de escrever e de visualizar no banco de dados.\nidade_form: Bom nome, significativo, minúsculo e pequeno separa os dois nomes por underline\nidadeForm :Bom nome, significativo, minúsculo e pequeno separa os dois nomes por uma letra maiúscula.\n\n\n\n\n\n\n\nDICA\n\n\n\nAdote uma regra de criação para você e evite mudar. Crie nomes pequenos e significativos. Nunca inicie uma variável com número.\n\n\n\n\n3.1.5 Criando projeto no R\nPara saber em qual diretório o R está utilizando para salvar seu espaço de trabalho utilize o seguinte comando:\n\ngetwd() \n\nNo RStudio, sempre prefira a criação de um projeto para a organização de seus dados, com isso, ao mudar de máquina (ou estrutura de diretórios) seu código continuará funcionando normalmente.\n\n  File -&gt; New Project\n\n\n\n3.1.6 Identação é Importante\nIdentar é o recuo no texto em relação a margem. É importante que esse recuo exista para linhas do seu programa que são hierarquicamente conectadas. Vejamos dois exemplos com e sem identação:\nSem Identação\n\nx=c()\nx[1] = 3\nfor (i in 2:9) { \nx[i]=2*x[i-1]\n}\n\nNote que a quarta linha desse programa está hierarquicamente conectada a linha 3 do “for”, ou seja, é uma continuação do comando e portanto deve ser identado para demonstrar essa relação de dependência. Vejamos\nCom Identação\n\nx=c()\nx[1] = 3\nfor (i in 2:9) { \n  x[i]=2*x[i-1]\n}"
  },
  {
    "objectID": "manipulacao.html#inserindo-dados-no-r",
    "href": "manipulacao.html#inserindo-dados-no-r",
    "title": "3  Maipulando os Dados",
    "section": "3.2 Inserindo Dados no R",
    "text": "3.2 Inserindo Dados no R\n\n3.2.1 Tipos de Variáveis\nO R possui diversos tipos de variáveis. Alguns desses tipos são:\nVetores: Vamos inserir os dados denúmero de homicídios de mulheres nos diversos Estados brasileiros para o ano de 2022.No primeiro elemento teremos um erro, ao invés de 22 colocaremos 2.E não colocamos o valor do Distrito Federal e nem Tocantins\n\nhomic &lt;- c(2,  73,  22,  88,  406,  264,    95,  137,  127,  101,  75,  309,  200,  86,  256,  219,  70,  283,  60,  281,  88,  33,  101,  423,  37)\nhomic\n\n [1]   2  73  22  88 406 264  95 137 127 101  75 309 200  86 256 219  70 283  60\n[20] 281  88  33 101 423  37\n\n\nPodemos inserir vetores de texto, por exemplo, iremos inserir os estados brasileiros na mesma ordem do homicídio acima.\n\n\n [1] \"Acre\"                \"Alagoas\"             \"Amapá\"              \n [4] \"Amazonas\"            \"Bahia\"               \"Ceará\"              \n [7] \"Distrito Federal \"   \"Espírito Santo\"      \"Goiás\"              \n[10] \"Maranhão\"            \"Mato Grosso\"         \"Mato Grosso do Sul\" \n[13] \"Minas Gerais\"        \"Pará\"                \"Paraíba\"            \n[16] \"Paraná\"              \"Pernambuco\"          \"Piauí\"              \n[19] \"Rio de Janeiro\"      \"Rio Grande do Norte\" \"Rio Grande do Sul\"  \n[22] \"Rondônia\"            \"Roraima\"             \"Santa Catarina\"     \n[25] \"São Paulo\"           \"Sergipe\"             \"Tocantins\"          \n\n\nAlgumas manipulações importantes que podemos fazer com os vetores. Renomeando e removendo o vetor antigo:\nTrocando o primeiro elemento do vetor e dando o print do novo resultado:\n\nhomic_abs[1]=22\nhomic_abs\n\n [1]  22  73  22  88 406 264  95 137 127 101  75 309 200  86 256 219  70 283  60\n[20] 281  88  33 101 423  37\n\n\nAlgumas maneiras de pedir o print do vetor de homicídios femininos. Somente o estado 7, todos menos o estado 7, Estado de 1 até 7 etc:\n\nhomic_abs[7] \n\n[1] 95\n\nhomic_abs[-7] \n\n [1]  22  73  22  88 406 264 137 127 101  75 309 200  86 256 219  70 283  60 281\n[20]  88  33 101 423  37\n\nhomic_abs[1:7]\n\n[1]  22  73  22  88 406 264  95\n\n\nPodemos incorporar novos dados no nosso vetor de homicídio feminino, Vamos incorporar o dado do Tocantins na posição 7 e o valor do Distrito Federal na útima posição - 27. Depois trocaremos os dois estados de posição:\n\n#colcar exemplo de inserir no inicio\n\n#inserir no meio e no final \nhomic_abs &lt;- c(homic_abs[1:6], 36,homic_abs[7:25], 32)\nhomic_abs\n\n [1]  22  73  22  88 406 264  36  95 137 127 101  75 309 200  86 256 219  70 283\n[20]  60 281  88  33 101 423  37  32\n\n#troca de posicoes\ntemp &lt;- homic_abs[27]\nhomic_abs[27] &lt;- homic_abs[7]\nhomic_abs[7] &lt;- temp\nhomic_abs\n\n [1]  22  73  22  88 406 264  32  95 137 127 101  75 309 200  86 256 219  70 283\n[20]  60 281  88  33 101 423  37  36\n\n\nString ou Texto:\nString são as variáveis tipo texto. Esse tipo de variável já apareceu na seção anterior quando apresentamos um vetor com a classificação dos Estados. Vejamos mais uma vez. Podemos criar uma variável que contêm “estado homicidio”. Uma segunda maneira é criar um vetor com dois elementos “estado” e “homicidio”. O comando paste cola a variável texto “estado” e a variável texto “homicidio”, separado por um espaço.\n\na &lt;- \"estado homicidio\"\na\n\n[1] \"estado homicidio\"\n\nb &lt;- c(\"estado\",\"homicidio\")\nb\n\n[1] \"estado\"    \"homicidio\"\n\nb[1]\n\n[1] \"estado\"\n\npaste(b[1],b[2],sep=' ')\n\n[1] \"estado homicidio\"\n\n\nFator:\nFator são variáveis de classe. Fator armazenam os valores inteiros na forma de um vetor com as quantidades das k classes e o vetor string dos valores originais. Vejamos o exemplo de um vetor. Podemos análisar os homicídios por região geográfica do país. Assim, classificaremos os estados por região:\n\nregiao &lt;- c(\"N\",  \"NE\",  \"N\",  \"N\",  \"NE\",  \"NE\",  \"CO\",  \"SD\",  \"CO\",  \"NE\",  \"CO\",  \"CO\",  \"SD\",  \"N\",  \"NE\",  \"S\",  \"NE\",  \"NE\",  \"SD\",  \"NE\",  \"S\",  \"N\",  \"N\",  \"S\",  \"SD\",  \"NE\",  \"N\")\nsummary(regiao)\n\nAgora vamos transformar o vetor anterior em um fator\n\nregiao &lt;- factor(regiao)\nsummary(regiao)\n\nCO  N NE  S SD \n 4  7  9  3  4 \n\nlevels(regiao)\n\n[1] \"CO\" \"N\"  \"NE\" \"S\"  \"SD\"\n\n\nO comando levels fornece as classes existentes, no caso acima temos 5, sendo elas 4, 7, 9, 3 e 4.\nFatores podem ser as características de raça, gênero, status familiar, status de saúde, qualidade do atendimento etc.\n\n3.2.1.1 Data Frame ou Banco de Dados\nEsse é um tipo mais geral de variável e consegue lidar na mesma estrutura com variaveis de tipos distintos como numérica, texto e fator. Um banco de dados similar aos outros programas estatísticos. Podemos criar essa variável de forma manual. Nosso banco de dados será composto por 4 variáveis, a primeira o estado, a segunda a região, a terceira o número de homicídios femininos e a quarta o número de feminicidios. As três primeiras já foram incluidas acima e vamos criar somente a quarta. O comando typeof mostra qual o tipo de variável.\n\nfeminic_abs=c(11,  31,  8,  21,  107,  28,  19,  33,  56,  69,  47,  40,  171,  49,  26,  77,  72,  24,  111,  16,  110,  24,  3,  56,  195,  19,  14) \ntypeof(feminic_abs)\n\n[1] \"double\"\n\n\nPara criar o banco de dados utilizamos o seguinte comando:\n\ndata_feminic22&lt;-data.frame(estados, regiao, homic_abs, feminic_abs)  \n\nPodemos modificar o nome das variáveis com o comando names. Entretanto, tem que renomear todas\n\nnames(data_feminic22)&lt;-c(\"estado\", \"regioa\", \"homic_abs\", \"feminic_abs\") \ndata_feminic22\n\nOu podemos renomear somente algumas com o comando reshape:\n\nlibrary(reshape)\ndata_feminic22 &lt;- rename(data_feminic22, c(estado=\"estados\", regioa=\"regiao\"))\ndata_feminic22\n\n               estados regiao homic_abs feminic_abs\n1                 Acre      N        22          11\n2              Alagoas     NE        73          31\n3                Amapá      N        22           8\n4             Amazonas      N        88          21\n5                Bahia     NE       406         107\n6                Ceará     NE       264          28\n7    Distrito Federal      CO        32          19\n8       Espírito Santo     SD        95          33\n9                Goiás     CO       137          56\n10            Maranhão     NE       127          69\n11         Mato Grosso     CO       101          47\n12  Mato Grosso do Sul     CO        75          40\n13        Minas Gerais     SD       309         171\n14                Pará      N       200          49\n15             Paraíba     NE        86          26\n16              Paraná      S       256          77\n17          Pernambuco     NE       219          72\n18               Piauí     NE        70          24\n19      Rio de Janeiro     SD       283         111\n20 Rio Grande do Norte     NE        60          16\n21   Rio Grande do Sul      S       281         110\n22            Rondônia      N        88          24\n23             Roraima      N        33           3\n24      Santa Catarina      S       101          56\n25           São Paulo     SD       423         195\n26             Sergipe     NE        37          19\n27           Tocantins      N        36          14\n\n\nPodemos também listar variáveis do banco de dados, por exemplo, listar colunas de 1 a 2 ou listar por nome das variáveis, conforme apresentado abaixo:\n\ndata_feminic22\ndata_feminic22[,2:3]\ndata_feminic22[1:2,2:3]\ndata_feminic22[c(\"regiao\",\"feminic_abs\")]\n\nEntretanto, inserir dados na mão pode ser uma tarefa muito penosa e existem soluções bem mais simples e rápidas para inserção de dados. Nas seções seguintes veremos aprenderemos mais funções úteis para lidar com banco de dados.\n\n\n3.2.1.2 Trabalhando com as variáveis:\nVamos retomar duas variáveis homic_abs e estado e vamos manipular essas duas variáveis. Primeiramente vejamos o número de elementos, estrutura, classe e nome:\n\nlength(homic_abs) \n\n[1] 27\n\nstr(homic_abs)    \n\n num [1:27] 22 73 22 88 406 264 32 95 137 127 ...\n\nclass(homic_abs)  \n\n[1] \"numeric\"\n\nnames(homic_abs) \n\nNULL\n\n\nPodemos combinar as duas variáveis de forma distintas, por exemplo combinar na forma de um vetor, combinar como coluna ou combinar como linha, vejamos a diferença:\n\n#Precisa mudar essa parte de posição está confuso pois falamos de dataframe e aqui de vetor\ncomb1 &lt;- c(homic_abs,estados)      \ncomb2&lt;- cbind(homic_abs,estados)\ncomb3 &lt;-rbind(homic_abs,estados)\ncomb4 &lt;- data.frame(\n              homic_abs,\n              estados\n              ,stringsAsFactors = F)\ncomb1\ncomb2 \ncomb3\ncomb4\n\nVejamos quais objetos temos e vamos pedir para visualizar os objetos que acabamos de criar. Por fim removeremos o vetor comb1.\n\nls()  \ncomb1\ncomb2\ncomb3\nrm(comb1)              \n\n\n\n\n3.2.2 Importando os Dados\nDisponibilizamos dois banco de dados, um contendo os homicídios e feminicídios por estado e outro com as tentativas. Esses arquivos estão em formato csv (comma separated values).\nPara leitura desse arquivo em csv o seguinte comando é necessário read.csv, indicado que possui cabeçalho e que o separador é “;”\n\ndf_feminic22&lt;-read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/dados_feminic.csv\", head=TRUE,sep=\";\")\n\ndf_t_feminic22&lt;-read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/dados_tent_feminic.csv\", head=TRUE,sep=\";\")\n\nPara leitura de arquivos em Stata terá que utilizar o pacote foreign, conforme exemplo abaixo:\n\nlibrary(foreign)\nstata_feminic &lt;- read.dta(\"~/feminic.dta\")\n\nAlém desses, o R é capaz de trabalhar com SQL, SAS, SPSS, Excel entre outros.\n\n\n\n\n\n\nCuidado com o Ponto\n\n\n\nO R usa o formato americano de separação numérica. Usa ponto ao invés da vírgula para separar a unidade dos decimais. No Brasil usamos a vírgula. Isso sempre gera conflito. No seu csv evite usar acentos nas palavras e use ponto como separados dos decimais e não use separador dos milhares. Exemplo: 12500.97\n\n\n\n\n3.2.3 Exportanto os Dados\nPodemos exportar os dados em diferentes formatos. Alguns exemplos são csv, texto delimitado, excel, stata. Vejamos em csv:\n\nwrite.table(df_feminic22, \"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/export_feminic.csv\", sep=\";\")\n\nPara exportar em Stata utilize os seguintes comandos:\n\nlibrary(foreign)\nwrite.dta(df_feminic22, paste(getwd(),\"~/Banco de dados/export_feminic.dta\",sep=''))\n\n\n\n3.2.4 Lidando com Dados Missing\nNão temos informação para as tentativas de feminicidio para os estados de São Paulo e Mato Grosso. Uma maneira de lidar com valores missing seria fazer um subconjunto que veremos mais a frente. Agora seguiremos alguns passos para analisar os valores missing do nosso banco de dados.\nPrimeiramente, analisamos se há valores missing no banco de dados:\n\nis.na(df_t_feminic22)\n\nPodemos desconsiderar os valores missing da análise de interesse, vamos fazer a média do dolar sem considerar os valores missing:\n\nmean(df_t_feminic22$t_feminic_abs) \n\n[1] NA\n\nmean(df_t_feminic22$t_feminic_abs, na.rm=TRUE)\n\n[1] 102.52\n\n\nPodemos criar um novo banco de dados sem os valores missing.\n\ndf_t_feminic22_sem_missing &lt;- na.omit(df_t_feminic22)\nmean(df_t_feminic22_sem_missing$t_feminic_abs)\n\n[1] 102.52\n\nrm(df_t_feminic22_sem_missing)\n\nOutra maneira de excluir os valores missing seria a utilização do comando subset removendo as observações que contenham valor missing. Isso será explicado em seção a frente.\nPode-se também recodificar uma determinada variável para missing. Muito comum nas pesquisas do IBGE os valores missing serem identificados por um número, por exemplo 999999999999. Dessa forma podemos indicar que esse não é número e sim um valor missing da seguinte maneira:\n\ndf_t_feminic22$t_feminic_abs[df_t_feminic22$t_feminic_abs==999999] &lt;- NA\n\nTodos os valores que forem 99 serão exluídos e a celula ficará com um NA\n\n\n\n\n\n\nDados Missing\n\n\n\nDoois pontos importantes, dados missing não é 0 e nunca devem ser substituídos por 0. Pois 0 é um valor e missing é que não sabemos. Outro ponto é que devemos evitar excluir do banco os dados missing, melhor é fazer as contas retirando apensa do cálculo"
  },
  {
    "objectID": "manipulacao.html#operando-o-banco-de-dados",
    "href": "manipulacao.html#operando-o-banco-de-dados",
    "title": "3  Maipulando os Dados",
    "section": "3.3 Operando o Banco de Dados",
    "text": "3.3 Operando o Banco de Dados\n\n3.3.1 Criando uma Nova Variável\nVamos criar uma variável que seria a soma dos homicídios e feminicídios no estado. Para criar a variável precisamos dizer primeiro qual o banco de dados em que queremos criar e qual o nome da variável, conforme apresentado na expressão abaixo.\n\nlibrary(reshape)\ndf_feminic22 &lt;- rename(df_feminic22, c(feminico_abs=\"feminic_abs\"))\n\n\ndf_t_feminic22$t_total_abs&lt;- df_t_feminic22$t_feminic_abs + df_t_feminic22$t_homic_abs\n\ndf_feminic22$total_abs&lt;- df_feminic22$feminic_abs + df_feminic22$homic_abs\n\nAgora vamos criar uma variável binária que representa como 1 os estados que possuem a taxa de feminicídio em relação ao total de homicídios maior que 50%. Novamente, precisamos indicar o banco de dados e o nome da variável no banco de dados.\n\ndf_feminic22$mais_50[df_feminic22$part_feminic &lt; 50] &lt;- 0\ndf_feminic22$mais_50[df_feminic22$part_feminic &gt;= 50] &lt;- 1\n\ndf_feminic22$mais_50\n\n [1] 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n\n\n\n\n3.3.2 Operadores Aritméticos e Lógicos\nUtilizando os vetores criados anteriormente:\n\nfeminic_abs&gt;50\n\n [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE\n[13]  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE\n[25]  TRUE FALSE FALSE\n\nfeminic_abs[feminic_abs&gt;50]\n\n [1] 107  56  69 171  77  72 111 110  56 195\n\nfeminic_abs[feminic_abs &lt; 50 | feminic_abs &gt; 100]\n\n [1]  11  31   8  21 107  28  19  33  47  40 171  49  26  24 111  16 110  24   3\n[20] 195  19  14\n\nfeminic_abs[feminic_abs &gt; 50 & feminic_abs &lt; 100]\n\n[1] 56 69 77 72 56\n\nmean(feminic_abs)\n\n[1] 53.22222\n\nfeminic_M &lt;- (feminic_abs[feminic_abs&lt; 100 & feminic_abs &gt; 50])\nfeminic_M\n\n[1] 56 69 77 72 56\n\n\nA tabela abaixo contém alguns operadaroes lógicos frequentemente utilizados.\n\nOperadores Lógicos no R\n\n\nOperador\nSignificado\n\n\n\n\n&lt;\nMenor que\n\n\n&lt;=\nMenor igual\n\n\n&gt;\nMaior que\n\n\n&gt;=\nMaior igual\n\n\n==\nExatamente igual\n\n\n!=\nDiferente\n\n\n!x\nNão x\n\n\nx | y\nx OU y\n\n\nx & y\nx E y"
  },
  {
    "objectID": "manipulacao.html#algumas-funções-importantes",
    "href": "manipulacao.html#algumas-funções-importantes",
    "title": "3  Maipulando os Dados",
    "section": "3.4 Algumas Funções Importantes",
    "text": "3.4 Algumas Funções Importantes\n\n3.4.1 Ordenando os Dados\nVamos ordenar os estados dos nossos 2 data frames pela participação do feminicídio no total de homicídios de mulheres.\n\ndf_feminic22_ord&lt;-df_feminic22[order(df_feminic22$part_feminic, decreasing = TRUE),] \n\ndf_t_feminic22_ord&lt;-df_t_feminic22[order(df_t_feminic22$part_t_feminic, decreasing = TRUE),] \n\n\n\n3.4.2 Fazendo Merge\nTemos dois data frames um contendo homicídios e feminicídios e outro contendo as tentativas. Vamos agora juntar os dois. Para isso os bancos devem conter uma chave única que identifica cada linha e essa deve estar presente nos dois bancos. Inclusive devem ter o mesmo nome.No caso em questão podemos usar o estado como nossa chave que irá conectar os dois bancos.\n\ndf_final_feminic_22 &lt;- merge(df_feminic22,df_t_feminic22,by=\"sigla\",keep.all=TRUE)\n\nAgora temos um banco único com homicídios e tentativas de homicídios.\n\n\n3.4.3 Agregando\nVamos criar um banco de dados que contenha os valores médios das variáveis. Para isso vamos agregar fazendo a média por região. Poderíamos utilizar outra função, como a soma, para fazer a agregação:\n\nregiao_media &lt;-aggregate(df_final_feminic_22, by=list(df_final_feminic_22$regiao.x), FUN=mean, na.rm=TRUE)\nregiao_media\n\n  Group.1 sigla estado.x regiao.x homic_abs homic_tx feminic_abs feminic_tx\n1      CO    NA       NA       NA  86.25000 4.250000    40.50000   2.100000\n2       N    NA       NA       NA  69.85714 6.785714    18.57143   1.871429\n3      NE    NA       NA       NA 149.11111 4.355556    43.55556   1.422222\n4       S    NA       NA       NA 212.66667 4.000000    81.00000   1.600000\n5      SD    NA       NA       NA 277.50000 3.300000   127.50000   1.375000\n  part_feminic  rendapc total_abs   mais_50 estado.y regiao.y t_homic_abs\n1     50.02500 2011.250 126.75000 0.5000000       NA       NA    258.2500\n2     30.01429 1175.286  88.42857 0.1428571       NA       NA    161.7143\n3     34.36667 1053.222 192.66667 0.2222222       NA       NA    257.7778\n4     41.53333 1983.667 293.66667 0.3333333       NA       NA    450.6667\n5     43.82500 1842.750 405.00000 0.2500000       NA       NA    455.7500\n  t_homic_tx t_feminic_abs t_feminic_tx part_t_feminic t_total_abs\n1  13.375000     126.33333     6.500000       32.67667    387.6667\n2  24.657143      50.28571     5.285714       26.44286    212.0000\n3   9.311111      85.11111     3.044444       25.72444    342.8889\n4   8.966667     169.66667     3.500000       25.98667    620.3333\n5   8.875000     185.66667     3.000000       26.50000    660.3333\n\n\n\n\n3.4.4 Criando Subconjunto\nSelecionando Variáveis:\nPodemos estar interessado em manter somente algumas variáveis no nosso banco de dados, por exemplo, queremos manter estado e a participação do feminicídio no total. Assim:\n\nvar_sel &lt;- c(\"sigla\", \"part_feminic\", \"part_t_feminic\")\nfeminic_sel &lt;- df_final_feminic_22[var_sel]\n\nfeminic_sel1 &lt;- df_final_feminic_22[c(\"sigla\", \"part_feminic\", \"part_t_feminic\")]\n\nOu podemos fazer indicar as colunas que queremos selecionar. Na segunda opção selecionamos até o final do nosso banco\n\nfeminic_sel2 &lt;- df_final_feminic_22[c(1:3,5:6,12:15)]\nfeminic_sel3 &lt;- df_final_feminic_22[c(1:3,10:ncol(df_final_feminic_22))]\n\n:\nAo fazer o merge as variáveis que tinham o mesmo nome nos dois bancos, como estado, foram mantidas e agora possuem os nomes estado.x e estado.y, vamos manter apenas uma e trocar o seu nome. O comando namesajuda a saber a posição da variável no banco\n\nnames(df_final_feminic_22)\n\n [1] \"sigla\"          \"estado.x\"       \"regiao.x\"       \"homic_abs\"     \n [5] \"homic_tx\"       \"feminic_abs\"    \"feminic_tx\"     \"part_feminic\"  \n [9] \"rendapc\"        \"total_abs\"      \"mais_50\"        \"estado.y\"      \n[13] \"regiao.y\"       \"t_homic_abs\"    \"t_homic_tx\"     \"t_feminic_abs\" \n[17] \"t_feminic_tx\"   \"part_t_feminic\" \"t_total_abs\"   \n\nfinal_fem_22 &lt;- df_final_feminic_22[c(-12)]\n\nlibrary(reshape)\nfinal_fem_22 &lt;- rename(final_fem_22, c(estado.x=\"estados\"))\n\n\n\n\n\n\n\nCuidado ao tirar colunas\n\n\n\nSe fizermos o comando de tirar colunas no mesmo data frame, ao rodar novamente ele continuará sempre tirando a coluna indicada. O ideal seria construir outro data frame como fizemos acima.\n\n\nOu podemos especificar a o nome da coluna que será retirada. Vamos agora tirar a região que ficou duplicada\n\nfinal_fem_22$regiao.y &lt;-  NULL\n\nlibrary(reshape)\nfinal_fem_22 &lt;- rename(final_fem_22, c(regiao.x=\"regiao\"))\n\nsave(final_fem_22, file = \"dados.RData\")\nwrite.table(final_fem_22, \"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/final_fem_22.csv\", sep=\";\")\n\nSelecionando Variáveis:\nVamos selecionar as observações dos estados da região Norte e Nordeste:\n\nfem_n_nd &lt;- final_fem_22[ which(final_fem_22$regiao==\"NE\" | final_fem_22$regiao==\"N\"),]\n\nfem_n_nd1 &lt;- final_fem_22[ which((final_fem_22$regiao==\"NE\" | final_fem_22$regiao==\"N\") & final_fem_22$part_feminic&gt;=50),]\n\nOu podemos selecionar as observações em que a participação do feminicídio está entre 30 e 50%:\n\nfem_n_nd2 &lt;- subset(final_fem_22, final_fem_22$part_feminic &gt;= 30 & final_fem_22$part_feminic &lt;= 50 )"
  },
  {
    "objectID": "descritiva.html#porque-estudar-estatística",
    "href": "descritiva.html#porque-estudar-estatística",
    "title": "4  Análise Descritiva",
    "section": "4.1 Porque Estudar Estatística?",
    "text": "4.1 Porque Estudar Estatística?\nPodemos dizer que a existência da estatística e de outras ciências está conectada a existência de problemas. Não somente a ciência mas o nosso trabalho está conectado a superação de problemas cotidianos. Tomar decisão é o dia a dia do gestor.\nSegundo Popper “we study not disciplines, but problems. Often, problems transcend the boundaries of a particular discipline”\nA questão central é: Como solucionamos os problemas? Utilizamos a melhor estratégia? A solução foi boa?\n\n\n\n\nflowchart LR\n  A[PROBLEMA] --&gt; B[Estratégia de Decisão]\n  B --&gt; C{Solução é BOA?}\n\n\n\n\n\n\n4.1.1 Os dois sistemas cognitivos\nOs livros abaixo são boas referências sobre a tomada de decisão.\n\n\n\n\n\n\nRápido e Devagar: Duas Formas de Pensar\n\n\n\n\n \n\n\n\n\n\nProcesso Decisório\n\n\n\n\n\nExistem dois sistemas que utilizamos para tomar decisão. O chamado Sistema 1 e o chamado Sistema 2. Segue uma breve descrição de cada um:\nSistema 1:\n\nIntuitivo, rápido, automático, sem esforço, implícito e emocional\n\nPressa,\nFalta de tempo,\nProblemas menos importante\nMais Falhas/Erros\n\n\nSistema 2\n\nRaciocíonio lento, consciente, esforçado, explícito, lógico\n\nRequer tempo,\nMais recursos\nProblemas mais importante\nMenos Falhas\n\n\nPara o Sistema 1 usamos a nossa intuição que chamamos de Heurística. Vejamos um pouco mais sobre esse sistema.\nHEURÍSTICA\nSão rotinas inconscientes ou atalhos que o nosso cérebro utiliza para lidar com a complexidade.\n\nModelo/Regras Intuitivas.\nPróprio do Sistema 1.\nApesar de processo sofisticado, são passíveis de falhas. Intuição falha\n\nUm Exemplo\nVeja a figura abaixo retirada do livro do Bazerman.Responda rápido.\nQual delas tem o tampo mais quadrado?\n\n\n\nBazerman: Exemplo das mesas\n\n\nSe você achou que é a segunda mesa, você está alinhado com a grande maioria. Nesse caso você usou o seu sistema 1\nVamos repitir a pergunta:\nQual delas tem o tampo mais quadrado?\nAgora use uma régua para medir as mesas. Usamos aqui o sistema 2. Mais tempo e recursos são utlizados. Qual mesa agora você considera mais quadrada? Mudou sua opinião?\nCom a régua vemos que as mesas são iguais. Isso mostra que a nossa intuição FALHA.\nTipos de Heurísticas\n\nHeurística da disponibilidade: Usamos o que está mais próximo na memória para calcular a probabilidade.\nHeurística da representatividade: Buscamos aquilo que reforça o padrão.\nHeurística da hipótese positiva: Assumimos que uma determinada hipótese é verdadeira e não olhamos o contrafactual.\nHeurística do afeto: Decisão considera o emocional. Seu humor afetam as decisões.\n\nPara contornar os problemas da intuição e seus viéses na tomada de decisão o primeiro passo é compreender que eles existem e estarmos alerta. E para problemas maiores o uso do sistema 2 torna-se relevante.\nUma das principais ferramentas do sistema 2 é a Estatística. Com os avanços computacionais essa ciência tem se destacado como um dos elementos centrais do data science. Abaixo a figura resume as diversas áreas de desenvolvimento da análise de dados, obviamente não exaustiva:\n\n\n\nBazerman: mesas\n\n\nNosso objetivo é explorar nessa seção a análise descritiva. Chamado hoje no Business Intelligence, que e uma das áreas do Data Science."
  },
  {
    "objectID": "descritiva.html#conceitos-básicos-de-estatística",
    "href": "descritiva.html#conceitos-básicos-de-estatística",
    "title": "4  Análise Descritiva",
    "section": "4.2 Conceitos Básicos de Estatística",
    "text": "4.2 Conceitos Básicos de Estatística\nNovamente começamos com um problema e esse definirá a nossa análise. Vejamos alguns problemas que poderiam nos interessar…\n\n\n\n\n\n\nProblema 1\n\n\n\nO prefeito de Ribeirão Preto vai lançar uma política que fornece vouchers de alimentação para mulheres que estão em situação de pobreza.\nProblema: Qual o valor que devo reservar ao programa? Quantas mulheres serão atendidas?\n\n\n\n\n\n\n\n\nProblema 2\n\n\n\nO TJSP vai lançar um programa para reduzir o tempo médio em processos de feminicídio.\nProblema: Qual o tempo médio de um processo de feminicídio?\n\n\n\n\n\n\n\n\nProblema 3\n\n\n\nO O governo federal vai lançar um programa para capacitar mulheres que estão fora do mercado de trabalho.\nProblema: Quantas mulheres serão alvos dessa política?\n\n\n\n4.2.1 A Variável Aleatória\nO problema nos define a população que estou interessado. Vamos seguir, a princípio, com o nosso probelma 1 para definirmos alguns conceitos importantes.\nNo problema 1: me interessa compreender a renda das mulheres que moram em Ribeirão Preto em dado ano. Para ficar simples vamos abreviar o que nos interessa\n\\[X=\\text{Renda das mulheres que moram em Ribeirão Preto em determinado ano}\\] Agora posso utilizar o X no lugar do nome. Olhando para a população e pensando que cada nível de renda pode ser representada por uma cor, teremos a seguinte imagem pouco de como a renda se distribui nessa população:\n\n\n\nRenda pc das mulheres de Ribeirão Preto.\n\n\nA questão é: quais cores existem e quantas peças de cada cor temos? Para isso usamos um experimento\nEXPERIMENTO ALEATÓRIO\nO experimento em ciências sociais aplicadas em geral está associada a observação sistemática de pessoas, cidades, empresas ou processos. A ideia é:\n\nSortear pessoas e observar a sua caracteristica de forma indefinida e sempre na mesma condição.\n\nNão consigo dizer o que vai sair no próximo sorteio, apenas consigo descrever os resultados possíveis\nSe repetir o experimento um número grande de vezes uma regularidade aparece.\n\nSe eu conseguir sortear de forma indefinida e na mesma condição as mulheres que moram em Ribeirão Preto e perguntar sobre a sua renda. Eu consigo reorganizar a figura acima da seguinte forma:\n\n\n\nRenda pc das mulheres de Ribeirão Preto.\n\n\nESPAÇO AMOSTRAL\nAgora conseguimos organizar os nossos resultados em um lugar chamado espaço amostral. Nele teremos todas as cores (azul, branca, amarela…) que podem acontecer e o número de peças de cada cor (a chance). Em outras palavras teremos todos os possíveis valores de \\(X\\) e suas probabilidades.\nVARIÁVEL ALEATÓRIA\nQuanto representamos esse espaço amostral em formato de números é o que chamamos de Variável Aleatória (V.A.). A V.A. é a combinação de tudo que pode acontecer, ou seja, todas as rendas que existem associadas a probabilidade de cada uma das rendas acontecerem.\nExistem dois tipos principais de variáveis aleatórias: discretas e contínuas.\nVARIÁVEIS ALEATÓRIAS DISCRETAS\nÉ um tipo de variável que conseguimos colocar em lista, seja finita ou infinita \\(x_1; x_2;...; x_n;...\\) e associa-se a cada um dessses valores uma probabilidade \\(p(x_1); p(x_2);...; p(x_n);...\\)\nPodemos pensar aqui se a pessoa é casada, solteira, divorciada, viúva ou outra condição. Se no processo classificamos como homicídio ou feminicídio, se mora na área urbana ou rural…\nNa figura abaixo iremos coletar de 20 processos de homicídio e gostariamos de saber quando é classificado como feminicídio e quanto é classificado como homicídio (p=0,3).\n\nfeminicidio &lt;- 0:20\n\nplot(feminicidio,dbinom(feminicidio,size=20,prob=.3),\n     type='h',\n     main='Distribuição Binomial (n=20, p=0.3)',\n     ylab='Probabilidade',\n     xlab ='Feminicídio',\n     lwd=3)\n\n\n\n\nDistribuição Normal\n\n\n\n\nVARIÁVEIS ALEATÓRIAS CONTÍNUAS\nPor outro lado, uma variável aleatória contínua pode assumir infinito valores dentro de um intervalo específico. Agora temos infinitas possibilidades de resultados para \\(X\\) e agora associamos uma função \\(f(x)\\) que irá descrever o comportamento da probabilidade.\nPor exemplo, a altura de uma pessoa, a sua renda, a sua idade, o tempo que demora um processo.\nAbaixo temos uma representação de uma distriuição continua da renda das mulheres em Ribeirão Preto, chamada distribuição normal:\n\nrm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.\nx&lt;-seq(700,1300,1)\nfdnorm&lt;-dnorm(x = x, mean = 1000, sd=100)  \nfdanorm&lt;-pnorm(q = x, mean = 1000, sd=100)\ncurve(dnorm(x,1000,100),xlim=c(700,1300),main='',xaxt=\"n\",xlab=\"Renda pc Mulheres\", ylab=\"f(x)\",col=\"darkblue\",cex.axis=0.65, cex.lab=0.8) \naxis(1,at=c(900, 1000, 1100),labels =\n       c(\"-DP(X)\",\"E(x)\",\"DP(x)\"),cex.axis=0.65, cex.lab=0.8) \nlines(x=c(1000,1000),y=c(0,fdnorm[x==1000]),lty=2, col=\"black\") \nlines(x=c(1100,1100),y=c(0,fdnorm[x==1100]),lty=2, col=\"black\")\nlines(x=c(900,900),y=c(0,fdnorm[x==900]),lty=2, col=\"black\")\n\n\n\n\nDistribuição Normal\n\n\n\n\n\n4.2.1.1 Esperança e Variância\nO fomato das distribuições vistas dependem principalmente de dois parâmetros: A esperança que é uma medida de centralidade e a variância que é uma medida de dispersão.\nESPERANÇA - \\(E(X)\\)\nÉ uma medida de centralidade da variável aleatória. É definida como a média ponderada de todos os possíveis resultados de \\(X\\), onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança de \\(X\\), \\(E(X)\\), é calculada como:\n\\[E(X) = \\sum_{x} x \\cdot P(X = x)\\]\npara variáveis discretas.\n\\[E(X) = \\int_{-\\infty}^{\\infty} x \\cdot f(x)\\],\npara variáveis contínuas\nVARIÂNCIA POPULACIONAL - \\(Var(X)\\)\nA variância é uma medida que captura como os dados populacionais se dispersão em relação a sua média (ou esperança).\n\\[Var(X) =\\frac{1}{N} \\sum_{1}^{N} (X_i-E(X))^2\\] Ou podemos assim representar: \\[\\text{Var}(X) = E(X^2) - [E(X)]^2\\].\nDESVIO PADRÃO POPULACIONAL - \\(DP(X)\\)\nA variãncia é uma medida ao quadrado. Se estamos falando da renda seria uma medida da dispersão ao quadrado, ou seja, em \\(R\\$^{2}\\). Para retornar a unidade original usamos o desvio padrão que é:\n\\[DP(X)=\\sqrt{Var(X)}\\]\nVejamos o que acontece quando mudamos a esperança e o desvio padrão. No gráfico em azul temos a esperança igual a 10 e devio padrão de 2,5. No gráfico em vermelho temos esperança de 20 e desvio padrão de 10. E no grafico em verde temos esperança de 10 e desvio padrão de 1. Nota-se que quanto menor o desvio padrão mais concentrados são os valores que podem acontecer.\n\ncurve(dnorm(x,mean=10,sd=sqrt(2.5)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs=\"i\",yaxs=\"i\",ylab=\"\", col=\"darkblue\") \npar(new=T)\ncurve(dnorm(x,mean=20,sd=sqrt(10)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs=\"i\",yaxs=\"i\",ylab=\"\", col=\"darkred\") \npar(new=T)\ncurve(dnorm(x,mean=20,sd=sqrt(1)),xlim=c(0,30),ylim=c(0.0,0.4),xaxs=\"i\",yaxs=\"i\",ylab=\"\", col=\"darkgreen\") \n\n\n\n\nMédias e desvios distintos entre distribuições\n\n\n\n\n\n\n\n4.2.2 Variáveis Aleatórias Bidimensionais\nMuito provavelmente nos interessa observar mais de uma característica de um experimento. Por exemplo, não somente a renda das mulheres em Ribeirão Preto nos interessa, mas o seu consumo alimentar também julgamos importante para o projeto.\nPortanto, queremos observar duas características de forma simultânea das mulheres: sua renda e seu consumo alimentar. Ou seja, duas características simultaneamente do mesmo experimento \\(\\epsilon\\) que foi observar as mulheres no município.\nApesar de termos coletados duas informações, temos na realidade três informações. A informação da renda, a informação do consumo alimentar e a informação de como renda e consumo alimentar interagem.\nVISUALIZAÇÃO GRÁFICA\nVejamos agora um exemplo de variável aleaória bidimensional:\nNormal Bivariada:\nAbaixo tem-se uma variável aleatória \\((X,Y)\\) com distribuição normal bivariada com a esperança de \\(X\\) igual a 1, de \\(Y\\) igual a 0, o desvio-padrões iguais a 3 e 2 respectivamente. Aqui consideremaos a correlação de 1 (veremos mais a frente esse conceito)\n\nlibrary(mnormt)\n\n#Para tornar reproduzível\nset.seed(0)\n\n#cCriando a normal bivariada\nx     &lt;- seq(-3, 3, 0.1) \ny     &lt;- seq(-3, 3, 0.1)\nmu    &lt;- c(1, 0)\nsigma &lt;- matrix(c(3, 1, 1, 2), nrow=2)\nf     &lt;- function(x, y) dmnorm(cbind(x, y), mu, sigma)\nz     &lt;- outer(x, y, f)\n\n#Criando um gráfico de superfície\npersp(x, y, z, theta=-30, phi=25, expand=0.6, ticktype='detailed')\n\n\n\n\nNormal Bivariada\n\n\n\n\nSurge aqui um conceito importante que tenta medir como as características da população se relacionam - uma medida do relacionamento. Assim:\nO que acontece com o consumo de alimentos quando a renda das mulheres sobem?\n\n4.2.2.1 Covariância e Correlação\nDuas medidas que tentam mensurar o “grau de associação” linear entre X e Y são:\nCOVARIÂNCIA\n\\[Cov(X,Y)=E[(X-E(X))(Y-E(Y))]\\]\nEla mede a variabilidade conjunta de uma variável aleátoria multidimensional. Como no caso da variância, ela sofre do efeito das escalas de medidas. Para corrigir dividimos pelos desvios padrões. Surge dessa maneira a medida de correlação.\nCORRELAÇÃO\n\\[\\rho_{X,Y}=\\frac{E[(X-E(X))(Y-E(Y))]}{\\sqrt{Var(X)Var(Y)}}\\]\n\n\n\n\n\n\nCorrelação\n\n\n\nA correlação mede o GRAU DE ASSOCIAÇÃO LINEAR. Associações não lineares não são capturadas pela correlação.\n\n\n\n\n\n\n\n\nLendo a Correlação\n\n\n\nA correlação \\(\\rho_{X,Y}\\) varia de -1 até 1. Sendo que:\n\\(\\rho\\) próximo a 1 e -1 indicam alto grau de linearidade e \\(\\rho\\) próximo a 0 indica ausência de relação linear - mas não diz nada sobre relações não-lineares.\n\n\nVISUALIZAÇÃO GRÁFICA\nVeja no gráfico abaixo que a variável 4 e 5 possuem correlação perfeita, igual a -1. E as variáveis 3 e 1 não possuem grau de associação linear, correlação próxima a 0.\n\n\n\n\n\nGráfico de correlação para variáveis simuladas v1 a v5"
  },
  {
    "objectID": "descritiva.html#problema-1",
    "href": "descritiva.html#problema-1",
    "title": "6  Análise Descritiva",
    "section": "6.3 Problema 1",
    "text": "6.3 Problema 1"
  },
  {
    "objectID": "descritiva.html#problema-3",
    "href": "descritiva.html#problema-3",
    "title": "6  Análise Descritiva",
    "section": "6.3 Problema 3",
    "text": "6.3 Problema 3\nO O governo federal vai lançar um programa para capacitar mulheres que estão fora do mercado de trabalho.\nProblema Quantas mulheres serão alvos dessa política? :::\n\n6.3.1 A Variável Aleatória\nUm experimento aleatório é um processo ou evento cujo resultado não pode ser previsto com certeza, mesmo que as condições iniciais sejam conhecidas. Ele geralmente envolve uma série de possíveis resultados, onde cada resultado tem uma probabilidade associada de ocorrer. Por exemplo, jogar um dado é um experimento aleatório, pois o resultado (o número que aparece no dado) não pode ser determinado com certeza antes do lançamento, embora saibamos que o resultado possível será um dos números de 1 a 6.\nCom base nesse conceito, podemos introduzir variáveis aleatórias, que são utilizadas para descrever e quantificar os resultados possíveis de um experimento aleatório de uma forma mais abstrata e matemática. Existem dois tipos principais de variáveis aleatórias: discretas e contínuas.\nUma variável aleatória discreta é aquela que pode assumir apenas um conjunto específico de valores isolados, geralmente inteiros, com probabilidades associadas a cada valor possível. Por exemplo, o número de caras em cinco lançamentos de uma moeda é uma variável aleatória discreta, pois só pode assumir valores inteiros (0, 1, 2, 3, 4, ou 5) com probabilidades específicas para cada valor.\nPor outro lado, uma variável aleatória contínua pode assumir um intervalo infinito de valores dentro de um intervalo específico. Por exemplo, a altura de uma pessoa é uma variável aleatória contínua, pois pode assumir qualquer valor real dentro de um intervalo específico (por exemplo, entre 1,50 metros e 2,00 metros). Nesse caso, a probabilidade é representada pela área sob a curva da função de densidade de probabilidade ao longo do intervalo de valores possíveis.\nEm resumo, as variáveis aleatórias discretas e contínuas são ferramentas importantes na teoria da probabilidade e estatística para modelar e analisar resultados de experimentos aleatórios. Elas nos permitem quantificar e entender a incerteza associada aos resultados desses experimentos de uma forma matematicamente rigorosa.\nO conceito de esperança matemática \\((E)\\) em probabilidade e estatística representa uma medida de valor médio esperado de uma variável aleatória. Matematicamente, a esperança de uma variável aleatória \\(X\\) é definida como o valor ponderado de todos os possíveis resultados de \\(X\\), onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança matemática de \\(X\\), denotada por \\(E(X)\\). \\(E(X)\\), é calculada como:\nO conceito de esperança matemática (E) em probabilidade e estatística representa uma medida de valor médio esperado de uma variável aleatória. Matematicamente, a esperança de uma variável aleatória X é definida como o valor ponderado de todos os possíveis resultados de X, onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança matemática de X, denotada por X, é calculada como:\n\\[E(X) = \\sum_{x} x \\cdot P(X = x)\\]\npara variáveis discretas.\n\\[E(X) = \\int_{-\\infty}^{\\infty} x \\cdot f(x) \\],\npara variáveis contínuas\nonde \\(x\\) representa os possíveis valores que \\(X\\) pode assumir, \\(P(X = x)\\) é a probabilidade de \\(X\\) ser igual a \\(x\\) (para variáveis discretas), e \\(f(x)\\) é a função de densidade de probabilidade de \\(X\\) (para variáveis contínuas).\nA média \\(mu\\), a variância \\(\\sigma^2\\), e a covariância entre duas variáveis \\(X\\) e \\(Y\\), \\(Cov(X, Y)\\) podem ser expressas em termos de esperança matemática:\nA média de uma variável \\(X\\) é simplesmente a esperança de \\(X\\), ou seja, \\(\\mu = E(X)\\).\nA variância de \\(X\\), denotada por \\(\\sigma^2\\), é calculada como \\[\\text{Var}(X) = E(X^2) - [E(X)]^2\\].\nA covariância entre duas variáveis \\(X\\) e \\(Y\\) é dada por \\[\\text{Cov}(X, Y) = E(XY) - E(X)E(Y)\\], onde \\(\\mu_X\\) e \\(\\mu_Y\\) são as médias de \\(X\\) e \\(Y\\), respectivamente."
  },
  {
    "objectID": "descritiva.html#esperança-e-variância",
    "href": "descritiva.html#esperança-e-variância",
    "title": "6  Análise Descritiva",
    "section": "6.3 Esperança e Variância",
    "text": "6.3 Esperança e Variância\nO conceito de esperança matemática \\((E)\\) em probabilidade e estatística representa uma medida de valor médio esperado de uma variável aleatória. Matematicamente, a esperança de uma variável aleatória \\(X\\) é definida como o valor ponderado de todos os possíveis resultados de \\(X\\), onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança matemática de \\(X\\), denotada por \\(E(X)\\). \\(E(X)\\), é calculada como:\nO conceito de esperança matemática (E) em probabilidade e estatística representa uma medida de valor médio esperado de uma variável aleatória. Matematicamente, a esperança de uma variável aleatória X é definida como o valor ponderado de todos os possíveis resultados de X, onde os pesos são dados pelas probabilidades desses resultados ocorrerem. A esperança matemática de X, denotada por X, é calculada como:\n\\[E(X) = \\sum_{x} x \\cdot P(X = x)\\]\npara variáveis discretas.\n\\[E(X) = \\int_{-\\infty}^{\\infty} x \\cdot f(x)\\],\npara variáveis contínuas\nonde \\(x\\) representa os possíveis valores que \\(X\\) pode assumir, \\(P(X = x)\\) é a probabilidade de \\(X\\) ser igual a \\(x\\) (para variáveis discretas), e \\(f(x)\\) é a função de densidade de probabilidade de \\(X\\) (para variáveis contínuas).\nA média \\(mu\\), a variância \\(\\sigma^2\\), e a covariância entre duas variáveis \\(X\\) e \\(Y\\), \\(Cov(X, Y)\\) podem ser expressas em termos de esperança matemática:\nA média de uma variável \\(X\\) é simplesmente a esperança de \\(X\\), ou seja, \\(\\mu = E(X)\\).\nA variância de \\(X\\), denotada por \\(\\sigma^2\\), é calculada como \\[\\text{Var}(X) = E(X^2) - [E(X)]^2\\].\nA covariância entre duas variáveis \\(X\\) e \\(Y\\) é dada por \\[\\text{Cov}(X, Y) = E(XY) - E(X)E(Y)\\], onde \\(\\mu_X\\) e \\(\\mu_Y\\) são as médias de \\(X\\) e \\(Y\\), respectivamente."
  },
  {
    "objectID": "descritiva.html#correlação",
    "href": "descritiva.html#correlação",
    "title": "6  Análise Descritiva",
    "section": "6.3 Correlação",
    "text": "6.3 Correlação\nA correlação mede o GRAU DE ASSOCIAÇÃO LINEAR. Associações não lineares não são capturadas pela correlação."
  },
  {
    "objectID": "descritiva.html#estatisticas-descritivas-medidas-numéricas-a-partir-da-amostra",
    "href": "descritiva.html#estatisticas-descritivas-medidas-numéricas-a-partir-da-amostra",
    "title": "4  Análise Descritiva",
    "section": "4.6 Estatisticas Descritivas: Medidas Numéricas a partir da amostra",
    "text": "4.6 Estatisticas Descritivas: Medidas Numéricas a partir da amostra\nExistem outros métodos númericos que se constituem como alternativas adcionais para sintetizar os dados. Podemos dividir as medidas numericas em duas, temos as medidas de posíção e as de variabilidade.\nMEDIDAS DE POSIÇÃO:\n\nMédia,\nMediana,\nModa,\nPercentis,\nQuartis.\n\nMEDIDAS DE VARIABILIDADE:\n\nAmplitude,\nAmplitude interquartil,\nVariância,\nDesvio Padrão e\nCoeficiente de Variação.\n\nMEDIDAS DE ASSOCIAÇÃO:\n\nCovariancia e\nCoeficiente de Correlção.\n\nVamos apresentar as fÓrmulas de algumas dessas principais medidas.\n\nfinal_fem_22 &lt;- read.csv(\"C:/Users/Alexandre_Nicolella/Aulas/FEA-RP/Jurimetria/jurimetria/final_fem_22.csv\", head=T ,sep=\";\")\n\n\n4.6.1 Medidas de Posição:\nMÉDIA AMOSTRAL:\n\\[\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]\n\nmean(final_fem_22$feminic_tx)\n\n[1] 1.651852\n\n\n\nlibrary(kableExtra)\n\nmean_1&lt;- aggregate(final_fem_22[4:17], list(final_fem_22$regiao), mean,  na.rm=T)\n\nt(mean_1) %&gt;% \n  kbl(digits = 2) %&gt;%\n     kable_styling()\n\n\n\n\nGroup.1\nCO\nN\nNE\nS\nSD\n\n\nhomic_abs\n86.25000\n69.85714\n149.11111\n212.66667\n277.50000\n\n\nhomic_tx\n4.250000\n6.785714\n4.355556\n4.000000\n3.300000\n\n\nfeminic_abs\n40.50000\n18.57143\n43.55556\n81.00000\n127.50000\n\n\nfeminic_tx\n2.100000\n1.871429\n1.422222\n1.600000\n1.375000\n\n\npart_feminic\n50.02500\n30.01429\n34.36667\n41.53333\n43.82500\n\n\nrendapc\n2011.250\n1175.286\n1053.222\n1983.667\n1842.750\n\n\ntotal_abs\n126.75000\n88.42857\n192.66667\n293.66667\n405.00000\n\n\nmais_50\n0.5000000\n0.1428571\n0.2222222\n0.3333333\n0.2500000\n\n\nt_homic_abs\n258.2500\n161.7143\n257.7778\n450.6667\n455.7500\n\n\nt_homic_tx\n13.375000\n24.657143\n9.311111\n8.966667\n8.875000\n\n\nt_feminic_abs\n126.33333\n50.28571\n85.11111\n169.66667\n185.66667\n\n\nt_feminic_tx\n6.500000\n5.285714\n3.044444\n3.500000\n3.000000\n\n\npart_t_feminic\n32.67667\n26.44286\n25.72444\n25.98667\n26.50000\n\n\nt_total_abs\n387.6667\n212.0000\n342.8889\n620.3333\n660.3333\n\n\n\n\n\n\n\nMEDIANA:\nOrganize os dados em ordem crescente.\n\nPara um numero impar de observações a mediana é o valor que ocupa a posição central.\npara um número par de observações, a mediana é a média dos dois valores centrais.\n\n\nmedian(final_fem_22$feminic_tx)\n\n[1] 1.5\n\n\n\nfun1 &lt;- function(x, na.rm = TRUE) c(media=mean(x, na.rm = TRUE), mediana=median(x, na.rm = TRUE))\n\nmedian_1 &lt;- (sapply(final_fem_22[4:17], fun1))\n\nt(median_1) %&gt;% \n  kbl(digits = 2) %&gt;%\n     kable_styling()\n\n\n\n\n\nmedia\nmediana\n\n\n\n\nhomic_abs\n145.33\n95.00\n\n\nhomic_tx\n4.77\n4.50\n\n\nfeminic_abs\n53.22\n33.00\n\n\nfeminic_tx\n1.65\n1.50\n\n\npart_feminic\n37.76\n38.90\n\n\nrendapc\n1447.15\n1267.00\n\n\ntotal_abs\n198.56\n128.00\n\n\nmais_50\n0.26\n0.00\n\n\nt_homic_abs\n283.70\n264.00\n\n\nt_homic_tx\n13.79\n10.00\n\n\nt_feminic_abs\n102.52\n88.00\n\n\nt_feminic_tx\n4.14\n3.60\n\n\npart_t_feminic\n26.88\n29.73\n\n\nt_total_abs\n383.00\n377.00\n\n\n\n\n\n\n\nMODA:\nModa é o valor que ocorre com mais frequência.\n\nmoda &lt;- function(x, na.rm=T) {\nmodal &lt;- unique(x, na.rm=T)\nmodal[which.max(tabulate(match(x, modal)))]\n}\nmoda(final_fem_22$feminic_tx)\n\n[1] 1.3\n\n\n\nfun1 &lt;- function(x, na.rm = TRUE) c(media=mean(x, na.rm = TRUE), mediana=median(x, na.rm = TRUE), moda=moda(x))\n\nmedian_1 &lt;- (sapply(final_fem_22[4:17], fun1))\n\nt(median_1) %&gt;% \n  kbl(digits = 2) %&gt;%\n     kable_styling()\n\n\n\n\n\nmedia\nmediana\nmoda\n\n\n\n\nhomic_abs\n145.33\n95.00\n22.0\n\n\nhomic_tx\n4.77\n4.50\n4.5\n\n\nfeminic_abs\n53.22\n33.00\n19.0\n\n\nfeminic_tx\n1.65\n1.50\n1.3\n\n\npart_feminic\n37.76\n38.90\n50.0\n\n\nrendapc\n1447.15\n1267.00\n1010.0\n\n\ntotal_abs\n198.56\n128.00\n112.0\n\n\nmais_50\n0.26\n0.00\n0.0\n\n\nt_homic_abs\n283.70\n264.00\n373.0\n\n\nt_homic_tx\n13.79\n10.00\n4.2\n\n\nt_feminic_abs\n102.52\n88.00\n54.0\n\n\nt_feminic_tx\n4.14\n3.60\n2.3\n\n\npart_t_feminic\n26.88\n29.73\nNA\n\n\nt_total_abs\n383.00\n377.00\nNA\n\n\n\n\n\n\n\n\n4.6.1.1 Visualizando as medidas por categorias\nGráfico de Pizza O gráfico de pizza indica as proporções de uma determinada variável de classe. aqui utilizamos a média do número de feminicídios absoluto por região.\n\npie(mean_1$feminic_abs , labels = c(\"CO\",\"N\",\"NE\",\"S\",\"SD\"), border=\"lightgray\")\n\n\n\n\nGráfico de Barra\nEm geral a utilização do gráfico de barras está relacionado ao entendimento da frequência de valores associados a uma determinada categoria. Por exemplo, imagine que temos um banco de dados com as pessoas classificadas como: i)Não trabalha; ii)Trabalha e iii)Desempregado. Teríamos três categorias e a frequência de pessoas em cada categoria. Poderíamos ainda dividir essa categoria entre homens e mulheres. Essa é a utilização mais padrão do gráfico de barras. Vejamos alguns gráficos:\n\nfinal_fem_22&lt;- final_fem_22[order(-final_fem_22$feminic_tx),]\n\nbarplot(final_fem_22$feminic_tx, main=\"Taxa de Feminicídio por Estado\", \n        names.arg=final_fem_22$estados,\n        col=\"salmon2\",border=\"lightsalmon3\",\n        las = 2, \n        cex.names = 0.7,\n        xlab=\"\", ylab=\"Tx. por 100 mil\")\n\n\n\n\n\nfinal_fem_22&lt;- final_fem_22[order(-final_fem_22$part_feminic),]\n\nbarplot(final_fem_22$part_feminic, main=\"Participação da Taxa de Feminicídio no Total por Estado\", \n        names.arg=final_fem_22$estados,\n        col=\"darkblue\",border=\"steelblue\",\n        las = 2, \n        cex.names = 0.7,\n        xlab=\"\", ylab=\"Tx. por 100 mil\")\n\n\n\n\n\ng_b1&lt;- mean_1[c(1,5,13)]\ng_b1$tx_f &lt;- \"Feminicídio (tx)\" \ng_b1$tx_t_f &lt;- \"Tentativa de Fem. (tx)\"\ng_b2&lt;- g_b1[c(1,2,4)]\nnames(g_b2)&lt;-c(\"regiao\", \"taxa\", \"tipo\")\ng_b3&lt;- g_b1[c(1,3,5)]\nnames(g_b3)&lt;-c(\"regiao\", \"taxa\", \"tipo\")\ng_barra1&lt;-rbind(g_b2, g_b3)\n\n\nbarplot(taxa ~ tipo + regiao, data = g_barra1, \n        beside = T,\n        #legend.text = TRUE,\n        ylim = c(0,8),\n        ylab = \"Taxa (100 mil mulheres)\",\n        xlab = \"Região\",\n        col = c(\"lightsalmon3\", \"lightskyblue3\"))\n\n# Adicionando a legenda\nlegend(\"topright\", title = \"\", legend = c(\"Feminicídio \", \"Tentativa Feminicídio\"), pch = 15 , box.lwd = 0,box.col = \"white\",bg = \"white\", col = c(\"lightsalmon3\", \"lightskyblue3\")\n)\n\n# Incluindo o eixo x\nabline(h=0)\n\n\n\n\nGráfico de Linha\nO gráfico de linha ou pontos é muito utilizado para visualização da evolução de séries. É um gráfico que nos permite ver a evolução dos salários entre homens e mulheres, evolução dos preços dos alimentos, evolução do número de casos de feminicídio, evolução dos processos em determinada Vara.\nNosso banco é uma fotografia e não uma evolução, o que torna esse tipo de visualização menos útil. Vejamos a participação de feminicídio por estado\n\nfinal_fem_22&lt;- final_fem_22[order(-final_fem_22$total_abs),]\n\nplot(x=final_fem_22$total_abs, y=final_fem_22$t_feminic_tx,\n     type=\"b\" , bty=\"l\" , \n     ylim=c(0,12),\n     col=rgb(0.2,0.4,0.1,0.7) , lwd=2 , pch=17,\n     main=\"Tentativa eFeminídio Taxa\", \n     xlab = \"Total de Homicídios\", ylab=\"Taxa / 100 mil \"\n      )\n# Adicionando nova variável\nlines(x=final_fem_22$total_abs, y=final_fem_22$feminic_tx, col=rgb(0.8,0.4,0.1,0.7) , lwd=2 , pch=19 , type=\"b\" )\n\n# Inserindo a Legenda\n\nlegend(\"topright\", \n  legend = c(\"Tentativa\", \"Feminicídio\"), \n  col = c(rgb(0.2,0.4,0.1,0.7), \n  rgb(0.8,0.4,0.1,0.7)), \n  pch = c(17,19), \n  bty = \"n\", \n  pt.cex = 1, \n  cex = 0.8, \n  text.col = \"black\", \n  horiz = F , \n  inset = c(0.1, 0.1))\n\n\n\n\nPERCENTIL:\nO p-esimo percentil é um valor tal que ao menos p por cento das observações são menores ou iguais à ele e pelo menos (100-p) por cento das observações são maiores ou iguais a esse valor.\nEtapas para calcular o p-ésimo percentil\nEtapa 1: Organize os dados em ordem crescente.\nEtapa 2: Calcule um indice, \\(i\\) tal que \\[i = \\frac{p}{100} \\times n\\] onde \\(p\\) é o percentil procurado\nEtapa 3:\n\nSe \\(i\\) não for um número inteiro, arredondeo-o para cima. O próximo número inteiro maior que \\(i\\) denota a posição do p-esimo percentil.\nSe \\(i\\) for um número inteiro o p-esimo percentil será a média dos valores que o ocupam as posições \\(i\\) e \\(i + 1\\).\n\n\nquantile(final_fem_22$feminic_tx, probs = c(0.10,0.30,0.60,0.85), na.rm=T)\n\n 10%  30%  60%  85% \n0.96 1.30 1.66 2.24 \n\n\nQUARTIS:\nOs quartis são medidas estatísticas que dividem um conjunto de dados ordenados em quatro partes iguais.\nO três quartis são:\nPrimeiro Quartil (Q1): Representa o valor abaixo do qual está situada a primeira quarta parte (ou 25% inferiores) dos dados quando eles estão ordenados em ordem crescente. O primeiro quartil é o valor que divide os dados em 25% (ou 0.25) abaixo e 75% (ou 0.75) acima desse ponto.\nSegundo Quartil (Q2): Corresponde à mediana dos dados, dividindo o conjunto em duas metades iguais. É o valor que separa os 50% inferiores dos 50% superiores dos dados.\nTerceiro Quartil (Q3): Indica o valor acima do qual está situada a terceira quarta parte (ou 25% superiores) dos dados quando eles estão ordenados. Assim como o primeiro quartil, o terceiro quartil divide os dados em 75% (ou 0.75) abaixo e 25% (ou 0.25) acima desse ponto\n\nquantile(final_fem_22$feminic_tx, na.rm=T)\n\n  0%  25%  50%  75% 100% \n0.60 1.30 1.50 1.95 3.10 \n\n\nAMPLITUDE:\nAmplitude é a diferença entre o valor mínimo e máximo de uma série de dados.\n\\[\\text{Amplitude} = \\text{Maior Valor} - \\text{Menor Valor}\\]\n\nmin_max&lt;-range(final_fem_22$feminic_tx)\namp&lt;-min_max[2]-min_max[1]\namp\n\n[1] 2.5\n\n\nAMPLITUDE INTERQUANTIL:\nA amplitude interquartil é dada pela diferenca entre o terceiro (\\(Q_3\\)) e o primeiro quartil (\\(Q_1\\)).\n\\[IQR = Q_3 - Q_1\\]\n\nqs&lt;-quantile(final_fem_22$feminic_tx, na.rm=T)\niq&lt;-qs[4]-qs[2]\nIQR(final_fem_22$feminic_tx)\n\n[1] 0.65\n\niq\n\n 75% \n0.65 \n\n\n\n\n4.6.1.2 Visualizando a Distribuição dos Dados\nBoxplot\nO boxplot é um gráfico que traz muitas informações e pode ser visto como a distribuição de probabilidade dos dados. O box contém 50% dos dados. O limite superior indica o percentil de 75% (Q3) e o limite inferior indica o percentil de 25% (Q1). A linha que corta o box indica a mediana, ou seja, Q2. Os bigodes são calculados com base na distância interquantílica, ou seja,\nLimite inferior: Q1-1,5(Q3-Q1)\nLimite superior:Q3+1,5(Q3-Q1)\nDados fora desses limites são classificados como suspeitos de serem outlier. Podemos observar a assimetria dos dados quando a mediana não está no meio da caixa, indicando maior densidade na menor distância entre os quartis Q1 ou Q3 e a mediana Q2. Vejamos agora o boxplot da taxa de feminicídio e da taxa de feminicídio por região.\n\nboxplot(final_fem_22$feminic_tx,data=final_fem_22, main=\"Boxplot da taxa de feminicídio no Brasil, 2022\", horizontal=TRUE,\n  xlab=\"\", ylab=\"Tx de Feminicídio/100mil\", col=\"steelblue\")\n\n\n\n\n\nboxplot(final_fem_22$feminic_tx~final_fem_22$regiao,data=final_fem_22, main=\"Boxplot da taxa de feminicídio no Brasil, 2022\", horizontal=TRUE,\n  xlab=\"\", ylab=\"Tx de Feminicídio/100mil\", col=\"steelblue\")\n\n\n\n\nO Violin Plot é muito parecido com o BoxPlot mas com a densidade de kernel rotacionada em cada um dos lados. Assim, indica a distribuição dos dados em cada ponto e vem anotado a mediana na forma de um ponto ou marca e um pequeno boxplot no centro do violin plot.\n\n#Binária para nordeste e centro oeste 1 e demais regiões 0\nfinal_fem_22$N_NE_CO&lt;-0\nfinal_fem_22$N_NE_CO[final_fem_22$regiao == \"N\" | final_fem_22$regiao == \"NE\" | final_fem_22$regiao == \"CO\"] &lt;- 1\n\ntable(final_fem_22$N_NE_CO, final_fem_22$regiao)\n\n   \n    CO N NE S SD\n  0  0 0  0 3  4\n  1  4 7  9 0  0\n\n\n\nlibrary(vioplot) \nx1 &lt;- final_fem_22$feminic_tx[final_fem_22$N_NE_CO==1]\nx2 &lt;- final_fem_22$feminic_tx[final_fem_22$N_NE_CO==0]\nvioplot(x1, x2, names=c(\"Norte, Nord. e C.Oeste\", \"Sul e Sudeste\"), col=c(\"steelblue\", \"lightblue\"), border=\"white\" )\ntitle(\"Violin Plots da taxa de feminicídio por região do Brasil\")\n\n\n\n\nAqui segue uma sugestão de plotar o histograma juntamente com o boxplot, possibilitando em um mesmo gráfico uma maior quantidade de observação. Veja abaixo:\n\npar(fig=c(0,0.6,0,0.6), new=TRUE)\nhist(final_fem_22$feminic_tx, main=\"\", xlab=\"Taxa Feminicídio\", ylab=\"Frequência\", col=\"lightblue2\")\npar(fig=c(0,0.6,0.15,0.9), new=TRUE)\nboxplot(final_fem_22$feminic_tx, horizontal=TRUE, axes=FALSE, col=\"navajowhite2\")\n\n\n\n\nGráfico de Densidade\nVisualizar a distribuição empírica dos dados fornece uma grande quantidade de informação. Um gráfico básico em análise descritiva é o histograma, o qual fornece a distribuição de probabilidade empírica dos dados em um formato de barras. A área do histograma é igual a 1 e altura da sua barra da a densidade de observações em cada classe.\n\n  hist(final_fem_22$feminic_tx, \n       breaks=8,  # número de barras do histograma\n       col=\"steelblue\",  #cor do preenchimento\n       xlab=\"Taxa de Feminicídio\",  # Títulos de eixos e gráfico\n       ylab=\"Frequência\", \n       main=\"Histograma da Taxa de Feminicídio\")\n\n\n\n\nPodemos plotar o histograma conjuntamente com um modelo de distribuição de probabilidade. Utilizaremos a distribuição normal com mesma esperança e desvio padrão.\n\nx &lt;- final_fem_22$feminic_tx \nh&lt;-hist(x, breaks=8, col=\"steelblue\",xlab=\"Taxa de Feminicídio\", ylab=\"Frequência\",\n        main=\"Histograma da taxa de feminicídio e a aproximação pela normal\") \n\nxfit&lt;-seq(0,max(x),length=40) \nyfit&lt;-dnorm(xfit,mean=mean(x),sd=sd(x)) \nyfit &lt;- yfit*diff(h$mids[1:2])*length(x) \nlines(xfit, yfit, col=\"lightsalmon\", lwd=2)\n\n\n\n\nUma outra maneira de visualizar os dados é utilizando uma distribuição continua e não mais a discreta. Para isso, utiliza-se a densidade de Kernel para visualização da distribuição de probabilidade da taxa de feminicídio. Vejamos\n\n  k &lt;- density(final_fem_22$feminic_tx)\n  plot(k, xlab=\"Taxa de Feminicídio\",main=\"Densidade de Kernel para a taxa de feminicídio\")\n  polygon(k, col=\"burlywood3\", border=\"burlywood4\")\n\n\n\n\nOutra forma útil de visualizar os dados a é distribuição por classe, por exemplo distribuição de salários entre homens e mulheres, tempo do processo por vara, distribuição da taxa de feminicídio por regiaão. Vamos utilizar a densidade de Kernel para analisar a distribuição dos valores da taxa de feminicídio por região. Para isso precisa instalar o pacote sm.\n\n#install.packages(\"sm\")\nlibrary(sm)\nsm.density.compare(final_fem_22$feminic_tx, final_fem_22$N_NE_CO, xlab=\"Taxa de Feminicídio\", lwd=c(3, 3),col=c('darkgreen', 'darkblue'))\ntitle(main=\"Comparação da taxa de feminicídio entre regiôes\")\n\nlegend(\"topright\", c(\"S SD\", \"N NE CO\"), xpd = TRUE, horiz = FALSE , bty = \"n\",  col=c('darkgreen', 'darkblue'), lwd=c(4, 4), cex = 0.6)\n\n\n\n\n\n\n\n4.6.2 Medidas de Variabilidade\nA variância amostral é uma medida estatística que indica o quão dispersos estão os dados em relação à média amostral. Em outras palavras, ela quantifica a extensão das diferenças individuais entre os valores observados e a média da amostra.\nA variância populacional é semelhante à variância amostral, mas é calculada utilizando todos os dados de uma população em vez de uma amostra. Ela descreve a dispersão dos dados em relação à média populacional.\nVARIÂNCIA E DESVIO PADRÃO AMOSTRAL:\nDefinimos a vriância amostral como:\n\\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\] onde \\(\\bar{x}\\) é a média amostral.\nVejamos a variância da taxa de feminicídio e do femnicídio absoluto:\n\nvar(final_fem_22$feminic_tx, na.rm=T)\n\n[1] 0.3818234\n\nvar(final_fem_22$feminic_abs, na.rm=T)\n\n[1] 2364.718\n\n\nO Desvio padrão amostral é derivado da variância. Podemos qualcular essa estatistica da seguinte maneira:\n\\[s = \\sqrt{s^2} = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}}\\]\nPara os nossos dados anteriores:\n\n###Calculo do Desvio padrão\n\n#DP taxa de feminicidio\nsd(final_fem_22$feminic_tx, na.rm=T)\n\n[1] 0.6179186\n\n#DP  Feminicidio absoluto\nsd(final_fem_22$feminic_abs, na.rm=T)\n\n[1] 48.62837\n\n\nVamos consolidar agora nossas estatísticas descritivas\n\nfun1 &lt;- function(x, na.rm = TRUE) c(media=mean(x, na.rm = TRUE), med=median(x, na.rm = TRUE), var=var(x, na.rm = TRUE), dp=sd(x, na.rm = TRUE))\n\nest_descrit &lt;- (sapply(final_fem_22[4:17], fun1))\n\nt(est_descrit) %&gt;% \n  kbl(digits = 2) %&gt;%\n     kable_styling()\n\n\n\n\n\nmedia\nmed\nvar\ndp\n\n\n\n\nhomic_abs\n145.33\n95.00\n13985.00\n118.26\n\n\nhomic_tx\n4.77\n4.50\n4.39\n2.10\n\n\nfeminic_abs\n53.22\n33.00\n2364.72\n48.63\n\n\nfeminic_tx\n1.65\n1.50\n0.38\n0.62\n\n\npart_feminic\n37.76\n38.90\n175.84\n13.26\n\n\nrendapc\n1447.15\n1267.00\n243910.59\n493.87\n\n\ntotal_abs\n198.56\n128.00\n26451.33\n162.64\n\n\nmais_50\n0.26\n0.00\n0.20\n0.45\n\n\nt_homic_abs\n283.70\n264.00\n25685.83\n160.27\n\n\nt_homic_tx\n13.79\n10.00\n286.92\n16.94\n\n\nt_feminic_abs\n102.52\n88.00\n5692.09\n75.45\n\n\nt_feminic_tx\n4.14\n3.60\n5.94\n2.44\n\n\npart_t_feminic\n26.88\n29.73\n83.27\n9.13\n\n\nt_total_abs\n383.00\n377.00\n51470.00\n226.87\n\n\n\n\n\n\n\nCOEFICIENTE DE VARIAÇÃO:\nO coeficiente de variação (CV) é uma medida de dispersão relativa que expressa a variabilidade dos dados como uma porcentagem da média.\n\\[\\text{CV} = \\left( \\frac{\\text{Desvio padrão}}{\\text{Média}} \\right) \\times 100\\%\\]\n\n# Vamos calcular o coeficiente de variacao\n\n# O R nao tem nehuma funçao para isso, mas podemos fazer isso rapidamente\n\n# Acessando os dados da variável\nfeminic_abs &lt;- final_fem_22$feminic_abs\n\n# Calcular a média da variável\nmedia_variavel &lt;- mean(feminic_abs, na.rm = TRUE)\n\n# Calcular o desvio padrão da variável\ndesvio_padrao_variavel &lt;- sd(feminic_abs, na.rm = TRUE)\n\n# Calcular o coeficiente de variação\ncoeficiente_variacao &lt;- (desvio_padrao_variavel / media_variavel) * 100\n\n# Exibindo o coeficiente de variação\nprint(coeficiente_variacao)\n\n[1] 91.36854\n\n\n\n\n4.6.3 Medidas de Associação\nCOVARIÂNCIA AMOSTRAL\nCovariância entre duas variáveis: A covariância entre duas variáveis X e Y é uma medida estatística que descreve como essas variáveis variam juntas. Em outras palavras, a covariância indica a tendência de X e Y de se moverem na mesma direção (covariância positiva) ou em direções opostas (covariância negativa).\n\\[\\text{Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})\\]\n\n cov(final_fem_22$feminic_tx, final_fem_22$homic_tx)\n\n[1] 0.4648575\n\n\nCORRELAÇÃO\nO coeficiente de correlação entre duas variáveis X e Y é uma medida estatística que descreve a força e a direção da relação linear entre essas variáveis. O coeficiente de correlação é frequentemente representado pelo coeficiente de correlação de Pearson, \\(r_{XY}\\).\n\\[r_{XY} = \\frac{\\text{Cov}(X, Y)}{s_X s_Y}\\] O coeficiente de correlação de Pearson é uma medida amplamente utilizada para avaliar a relação linear entre variáveis, pois fornece uma interpretação padronizada da força e direção da relação, independentemente das unidades das variáveis.\n\n cor(final_fem_22$feminic_tx, final_fem_22$homic_tx)\n\n[1] 0.3589068\n\n\nScatter plot\nO Scatter plot é conhecido como o gráfico de dispersão. Ele relaciona duas ou três variáveis, ou seja, plota \\(X\\) contra \\(Y\\). Muito utilizado para ver o comportamento conjunto de duas séries. Observe que renda e a taxa de feminicídio não mostram um comportamento conjunto, estão dispersas.\n\n##Dispersão entre renda per capita e a taxa de feminicidio\nplot(final_fem_22$rendapc, final_fem_22$feminic_tx,\n     main = \"Taxa de Feminicídio vs. Renda Per Capita\",\n     xlab = \"Renda Per Capita\",\n     ylab = \"Taxa de Feminicídio\",\n     col = \"steelblue\",          # Cor dos pontos\n     pch = 16,              # Forma dos pontos (círculos sólidos)\n     cex = 1.5              # Tamanho dos pontos\n)\nabline(lm(final_fem_22$feminic_tx~final_fem_22$rendapc), col=\"lightblue4\", lwd=2)\n\n\n\n\nAo observar a taxa de homicídio e a taxa de feminicídio, estados com maior taxa de homicídio tendem a ter maior taxa de feminicídio.\n\n##Dispersão entre renda per capita e a taxa de feminicidio\nplot(final_fem_22$homic_tx, final_fem_22$feminic_tx,\n     main = \"Taxa de Feminicídio vs. Taxa de Homicidios\",\n     xlab = \"Taxa de Homicidio\",\n     ylab = \"Taxa de Feminicídio\",\n     col = \"lightgoldenrod3\",          # Cor dos pontos\n     pch = 16,              # Forma dos pontos (círculos sólidos)\n     cex = 1.5              # Tamanho dos pontos\n)\nabline(lm(final_fem_22$feminic_tx~final_fem_22$homic_tx), col=\"lightblue4\", lwd=2)\n\n\n\n\n\nlibrary(corrgram)\ncorrel&lt;- final_fem_22[c(5,7,8,9,13,15,16)]\ncorrgram(correl, order=TRUE, lower.panel=panel.shade, upper.panel=panel.cor,  main=\"Correlação entre as diversas variáveis\") \n\n\n\n\n\n\n4.6.4 Teste de Hipótese\nVamos testar a hipótese de que as taxas de feminicídio são iguais entre as regiões norte, nordeste e centro oeste e as regiões sul e sudeste. Vamos permitir que as variâncias sejam diferentes entre as duas regiões\n\\[H_0: \\mu_{N-NE-CO} = \\mu_{S-SD}\\] \\[H_1: \\mu_{N-NE-CO} \\neq \\mu_{S-SD}\\]\n\nt.test(feminic_tx~N_NE_CO, data=final_fem_22) \n\n\n    Welch Two Sample t-test\n\ndata:  feminic_tx by N_NE_CO\nt = -1.2049, df = 20.949, p-value = 0.2417\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.6640345  0.1768916\nsample estimates:\nmean in group 0 mean in group 1 \n       1.471429        1.715000 \n\n\nO teste mostra que não rejeitamos a hipótese nula de que as duas regiões possuem a mesma média de taxa de feminicídio.\nVejamos agora a renda per capita:\n\nt.test(rendapc~N_NE_CO, data=final_fem_22) \n\n\n    Welch Two Sample t-test\n\ndata:  rendapc by N_NE_CO\nt = 4.6401, df = 22.301, p-value = 0.0001225\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n 340.6685 890.5172\nsample estimates:\nmean in group 0 mean in group 1 \n       1903.143        1287.550 \n\n\nObserva-se que rejeita-se a hipótese nula, e há evidências de que a média da renda per capita entre as duas regiões são diferentes.\nGRÁFICOS COM GGPLOT2\nO pacote ggplot2 vem se consolidando como um dos pacotes mais usados para geração de gráficos. Ele tem algumas vantagens como:\n\nBastante flexível\nPoderoso\nMuito personalizável\nBonito!\n\nMas algumas coisas não deveriam ser feitas com ggplot, pois existem pacotes mais especializados:\n\nGráficos 3D (pacote rgl)\nGrafos (pacote igraph)\nGráficos interativos (pacote ggvis)\n\nA gramática dos gráficos\nPara criarmos gráficos com ggplot, utilizamos blocos de sintaxe que vão sendo empilhados para criar o gráfico pretendido\nOs blocos com os quais podemos trabalhar são:\n\nDados\nMapeamento estético\nObjetos geométricos\nTransformações estatíticas\nEscalas\nSistema de coordenadas\nAjustes de posição"
  },
  {
    "objectID": "descritiva.html#estatística-e-parâmetro",
    "href": "descritiva.html#estatística-e-parâmetro",
    "title": "4  Análise Descritiva",
    "section": "4.4 Estatística e Parâmetro",
    "text": "4.4 Estatística e Parâmetro\n\n\n\n\nflowchart LR\n  A[PARÂMETRO] --&gt; B[Medida que descreve uma característica da população]\n\n\n\n\n\nOs parâmetros definem as características de uma população. Qual a renda média da população, qual o desemprego médio da população, qual o desempenho médio educacional, qual a expectativa de vida média na população etc. São características que em geral não observamos.\nUma pergunta, qual o tempo médio que demora um processo de feminicídio? Perceba que mesmo características da população que conhecemos são de difíceis de conhecermos. Temos que nos valer de uma parte e tentar estimar o que seriam os valores dessas características.\n\n\n\n\nflowchart LR\n  A[ESTATÍSTICA] --&gt; B[Medida que descreve uma característica da amostra]\n\n\n\n\n\nSejam \\(x_1, x_2,..., x_{n}\\) os valores medidos a cada para cada medição de \\(X\\). Podemos definir uma estatística como:\n\\[ t= H (x_1, x_2, ..., x_{n})\\]\nAlguns exemplos de T:\n\\[ \\text{Média}: \\ \\overline{x}=\\frac{\\sum_{i=1}^{n} x_i}{n}\\]\n\\[ \\text{Variância:} \\ s^{2}= \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\overline{x})^{2} \\]\n\\[ x_{(1)}: Min\\{x_1, ..., x_n\\}\\]\nVejamos a tabela abaixo que já faz uma primeira associação entre estatística e parâmetro:\n\n\n\n\n\n\n\n\n\nParâmetro\n\nEstatística\n\n\n\n\n\nEsperança\n\\(E(X)=\\mu\\)\n\\(\\bar{X}\\)\nMédia\n\n\nVariância Pop.\n\\(Var(X)=\\sigma^2\\)\n\\(S^2;\\sigma^2\\)\nVariância Amostral\n\n\nMediana Pop.\nMd\nmd\nMediana Amostral\n\n\nProporção Pop.\np\n\\(\\hat{p}\\)\nProporção Amostral\n\n\n\nTabela 1 - Parâmetros populacionais e as Estatísticas associadas\nComo regra geral, os parâmetros são representados por letras gregas e as estatística com letras do nosso alfabeto (latino) ou letra grega com com chapéu para indicar que é uma estatística.\nESTIMADORES Um estimador é uma estatística calculada a partir da amostra que é usada para estimar um parâmetro desconhecido da população. Nos permitem fazer inferências sobre os parâmetros com base nos dados amostrais. Por exemplo, a média amostral é um estimador da média populacional, e a proporção amostral é um estimador da proporção populacional."
  },
  {
    "objectID": "descritiva.html#histograma",
    "href": "descritiva.html#histograma",
    "title": "4  Análise Descritiva",
    "section": "4.7 Histograma",
    "text": "4.7 Histograma\n\nlibrary(ggplot2)\n\n\nAnexando pacote: 'ggplot2'\n\n\nOs seguintes objetos são mascarados por 'package:psych':\n\n    %+%, alpha\n\np&lt;-  ggplot(data=final_fem_22, aes(x = feminic_tx, y = after_stat(density))) + \n  geom_histogram(bins=10, col=\"darkblue\",fill=I(\"steelblue\"))+\n  geom_vline(aes(xintercept = mean(feminic_tx)),  color = \"lightsalmon3\", linewidth = 1) +\n  geom_density(color = \"darkgoldenrod\", linewidth = 2)\n\np + labs(title=\"Distrição da taxa de Feminicídio nos Estados\", x=\"Taxa de Feminicídio\", y=\"Densidade\")"
  },
  {
    "objectID": "descritiva.html#teste-de-hipotese-parâmetros.",
    "href": "descritiva.html#teste-de-hipotese-parâmetros.",
    "title": "4  Análise Descritiva",
    "section": "4.5 Teste de Hipotese (Parâmetros).",
    "text": "4.5 Teste de Hipotese (Parâmetros).\n\n4.5.1 Introdução ao Teste de Hipótese de Duas Populações (de Médias)\nO teste de hipótese é uma técnica estatística fundamental usada para tomar decisões baseadas em evidências amostrais. O teste de hipótese de duas populações é aplicado quando queremos comparar as médias de duas populações distintas e determinar se existe uma diferença estatisticamente significativa entre elas. Vamos explorar os principais conceitos deste teste:\nFormulação das Hipóteses\nNo teste de hipótese de duas populações, formulamos duas hipóteses:\n\nHipótese Nula (\\(H_0\\)): Esta é a hipótese inicial que assume que não há diferença entre as médias das duas populações. Geralmente, é representada como\n\n\\[H_0: \\mu_1 = \\mu_2\\],\nonde \\(\\mu_1\\) e \\(\\mu_2\\) são as médias das duas populações.\n\nHipótese Alternativa (\\(H_a\\) ou \\(H_1\\)): Esta é a hipótese que queremos testar, indicando que há uma diferença significativa entre as médias das duas populações. Pode ser definida como: \\[H_a: \\mu_1 &gt; \\mu_2\\] ou \\[H_a: \\mu_1 &lt; \\mu_2\\] ou\n\n\\[H_a: \\mu_1 \\neq \\mu_2\\].\nEstatística do Teste\nO teste de hipótese de duas populações geralmente envolve o cálculo de uma estatística de teste específica para comparar as médias das amostras das duas populações. Uma das estatísticas comuns é o teste t de Student, especialmente quando as variâncias populacionais são desconhecidas e podem ser diferentes entre as populações.\nDecisão do Teste\nApós calcular a estatística de teste, comparamos o valor observado da estatística com um valor crítico ou calculamos um valor p associado. O valor p é a probabilidade de obter uma estatística de teste tão extrema quanto a observada, assumindo que a hipótese nula seja verdadeira. Com base no valor p (geralmente comparado com um nível de significância pré-definido, como 0,05), tomamos uma decisão de rejeitar ou não rejeitar a hipótese nula.\nConclusão do Teste\nA conclusão do teste de hipótese de duas populações nos permite determinar se há evidências estatísticas suficientes para rejeitar a hipótese nula em favor da hipótese alternativa. Essa decisão tem implicações importantes em áreas como pesquisa científica, análise de dados e tomada de decisões em negócios e saúde."
  },
  {
    "objectID": "outrosmodelos.html#outros-modelos",
    "href": "outrosmodelos.html#outros-modelos",
    "title": "6  Modelos Avançados",
    "section": "6.1 Outros Modelos",
    "text": "6.1 Outros Modelos"
  },
  {
    "objectID": "lineares.html#unidade-de-medida-e-forma-funcional",
    "href": "lineares.html#unidade-de-medida-e-forma-funcional",
    "title": "5  Modelos Lineares",
    "section": "5.5 Unidade de Medida e Forma Funcional",
    "text": "5.5 Unidade de Medida e Forma Funcional\nSe a variável dependente é multiplicada por uma constante \\(c\\), então as estimativas do intercepto e da inclinação também serão multiplicadas por \\(c\\)\nSe a variável explicativa é multiplicada por uma contante \\(c\\), então o coeficiente de inclinação será dívido por \\(c\\). Nada acontece com o intercepto.\nSe a variável explicativa é dividida por uma constante \\(c\\), então o coeficiente de inclinação é multiplicado por \\(c\\). Nada acontece com a constante.\nIMPORTANTE: O \\(R^2\\) não depende das unidades de nossas variáveis."
  },
  {
    "objectID": "lineares.html#incorporando-não-linearidades-nas-variáveis",
    "href": "lineares.html#incorporando-não-linearidades-nas-variáveis",
    "title": "5  Modelos Lineares",
    "section": "5.6 Incorporando não linearidades (nas variáveis!)",
    "text": "5.6 Incorporando não linearidades (nas variáveis!)\nMinha primeira tabela\n\n\n\n\n\n\n\n\n\nModelo\nDependente\nExplicativa\nInterpretação de \\(\\beta_1\\)\n\n\n\n\nNivel-nível\n\\(y\\)\n\\(x\\)\n\\(\\beta_1 \\Delta x\\)\n\n\nNível-Log\n\\(y\\)\n\\(ln(x)\\)\n\\((\\beta_1/100)\\%\\) \\(\\Delta x\\)\n\n\nLog-Nível\n\\(ln(y)\\)\n\\(x\\)\n\\(\\% \\Delta y = (100 \\beta_1) \\Delta x\\)\n\n\nLog_log\n\\(ln(y)\\)\n\\(ln(x)\\)\n\\(\\% \\Delta y = \\beta_1\\% \\Delta x\\)\n\n\n\n\n#Criando uma nova coluna para as variaveis em log\ndados$Lnfeminic_tx &lt;- log(dados$feminic_tx)\ndados$Lnhomic_tx &lt;- log(dados$homic_tx)\n\n\nhead(dados)\n\n  sigla  estados regiao homic_abs homic_tx feminic_abs feminic_tx part_feminic\n1    AC     Acre      N        22      5.3          11        2.6         50.0\n2    AL  Alagoas     NE        73      4.5          31        1.9         42.5\n3    AM Amazonas      N        88      4.5          21        1.1         23.9\n4    AP    Amapa      N        22      6.0           8        2.2         36.4\n5    BA    Bahia     NE       406      5.6         107        1.5         26.4\n6    CE    Ceara     NE       264      5.8          28        0.6         10.6\n  rendapc total_abs mais_50 t_homic_abs t_homic_tx t_feminic_abs t_feminic_tx\n1    1038        33       1         388       93.4            16          3.9\n2     935       104       0         160        9.8            54          3.3\n3     965       109       0          83        4.2            45          2.3\n4    1177        30       0          95       25.9            44         12.0\n5    1010       513       0         582        8.0           174          2.4\n6    1050       292       0         324        7.2           102          2.3\n  part_t_feminic t_total_abs Lnfeminic_tx Lnhomic_tx\n1           3.96         404   0.95551145   1.667707\n2          25.23         214   0.64185389   1.504077\n3          35.16         128   0.09531018   1.504077\n4          31.65         139   0.78845736   1.791759\n5          23.02         756   0.40546511   1.722767\n6          23.94         426  -0.51082562   1.757858\n\n\n\nnivel_log &lt;- lm(data=dados, dados$feminic_tx ~ dados$Lnhomic_tx)\nsummary(nivel_log)\n\n\nCall:\nlm(formula = dados$feminic_tx ~ dados$Lnhomic_tx, data = dados)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.22125 -0.30962  0.04254  0.26055  1.12333 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)        0.7246     0.4453   1.627   0.1162  \ndados$Lnhomic_tx   0.6238     0.2901   2.150   0.0414 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5789 on 25 degrees of freedom\nMultiple R-squared:  0.1561,    Adjusted R-squared:  0.1223 \nF-statistic: 4.624 on 1 and 25 DF,  p-value: 0.04138\n\nlog_nivel &lt;- lm(data=dados, dados$Lnfeminic_tx~ dados$homic_tx)\nsummary(log_nivel)\n\n\nCall:\nlm(formula = dados$Lnfeminic_tx ~ dados$homic_tx, data = dados)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.99152 -0.15045  0.06957  0.23432  0.60212 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)     0.21824    0.18283   1.194    0.244\ndados$homic_tx  0.04525    0.03517   1.287    0.210\n\nResidual standard error: 0.3759 on 25 degrees of freedom\nMultiple R-squared:  0.0621,    Adjusted R-squared:  0.02458 \nF-statistic: 1.655 on 1 and 25 DF,  p-value: 0.21\n\nlog_log &lt;- lm(data=dados, dados$Lnfeminic_tx~ dados$Lnhomic_tx)\nsummary(log_log)\n\n\nCall:\nlm(formula = dados$Lnfeminic_tx ~ dados$Lnhomic_tx, data = dados)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.02426 -0.16375  0.06636  0.21270  0.57211 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)      0.0009591  0.2848650   0.003    0.997\ndados$Lnhomic_tx 0.2915326  0.1855640   1.571    0.129\n\nResidual standard error: 0.3703 on 25 degrees of freedom\nMultiple R-squared:  0.08986,   Adjusted R-squared:  0.05345 \nF-statistic: 2.468 on 1 and 25 DF,  p-value: 0.1287"
  }
]