---
title: "Aula Pr√°tica: Coleta e An√°lise de Dados sobre Homic√≠dio Qualificado"
author:
- Jos√© de Jesus Filho e Alexandre Nicolella
format: html
---



## Introdu√ß√£o √† Aula Pr√°tica: Coleta de Dados no DataJud

Nesta aula pr√°tica, vamos aprender como coletar dados processuais utilizando a Base Nacional de Dados do Poder Judici√°rio (**DataJud**), mantida pelo Conselho Nacional de Justi√ßa (CNJ). O DataJud √© o sistema respons√°vel pelo armazenamento centralizado de dados e metadados de todos os processos judiciais brasileiros, f√≠sicos ou eletr√¥nicos, e ser√° a base que utilizaremos ao longo do curso.

##  Acesso ao DataJud

O DataJud pode ser acessado diretamente no site do CNJ üîó:

[https://www.cnj.jus.br/sistemas/datajud/](https://www.cnj.jus.br/sistemas/datajud/)

A plataforma fornece dados atualizados para diversos os ramos da Justi√ßa brasileira, agrupados e padronizados para permitir an√°lises estat√≠sticas e jurim√©tricas.

##  Autentica√ß√£o e Chave P√∫blica

Para acessar os dados via API, utilizaremos a **API P√∫blica** do DataJud, documentada em:

[https://datajud-wiki.cnj.jus.br/api-publica/](https://datajud-wiki.cnj.jus.br/api-publica/)

A autentica√ß√£o √© feita por meio de uma chave p√∫blica, disponibilizada pelo DPJ/CNJ. A chave  üîë pode ser obtida no seguinte endere√ßo:

[https://datajud-wiki.cnj.jus.br/api-publica/acesso](https://datajud-wiki.cnj.jus.br/api-publica/acesso)

Essa chave ser√° utilizada diretamente no c√≥digo em R (ou Python), permitindo realizar consultas autenticadas aos dados processuais.

##  Endpoints, Rotas e Sele√ß√£o de Tribunais

Para realizar nossas consultas, precisamos escolher os endpoints dispon√≠veis, indicando o tribunal desejado. Os endpoints est√£o detalhados em:

[https://datajud-wiki.cnj.jus.br/api-publica/endpoints](https://datajud-wiki.cnj.jus.br/api-publica/endpoints)

√â poss√≠vel consultar processos de de diversos ramos da Justi√ßa brasileira:

- **Tribunais Superiores**
- **Justi√ßa Federal**
- **Justi√ßa Estadual**
- **Justi√ßa do Trabalho**
- **Justi√ßa Eleitoral**
- **Justi√ßa Militar**

No nosso estudo, utilizaremos os dados do **Tribunal de Justi√ßa do Tocantins (TJTO)**.


##  Tipos de Consultas Poss√≠veis

A API permite diferentes modalidades de consulta üîç, como:

- Pesquisa por n√∫mero do processo
- Pesquisa paginada
- Pesquisa por classe
- Pesquisa por assunto
- ...

O DataJud tamb√©m disponibiliza exemplos de c√≥digo em Python e R, acess√≠veis na aba de exemplos:

[https://datajud-wiki.cnj.jus.br/api-publica/exemplos/](https://datajud-wiki.cnj.jus.br/api-publica/exemplos/)


##  Gloss√°rio de Vari√°veis

O DataJud define nomes espec√≠ficos para cada uma das vari√°veis retornadas pela API. O significado de cada termo pode ser consultado no gloss√°rio oficial:

[https://datajud-wiki.cnj.jus.br/api-publica/glossario](https://datajud-wiki.cnj.jus.br/api-publica/glossario)

Esse gloss√°rio √© essencial para interpretar corretamente os dados coletados.


## Sele√ß√£o do Assunto de Interesse

Em geral, ao iniciar uma pesquisa emp√≠rica, precisamos definir o assunto processual a ser analisado. Para isso, utilizamos o Sistema de Gest√£o de Tabelas Processuais Unificadas:

[https://www.cnj.jus.br/sgt/consulta_publica_assuntos.php](https://www.cnj.jus.br/sgt/consulta_publica_assuntos.php)

No nosso caso, o foco inicial seria **Direito Penal/Crimes Contra a Vida**, que inclui subcategorias como:

- **10915 ‚Äî Aborto**
- **12091 ‚Äî Feminic√≠dio**
- **12130 ‚Äî Homic√≠dio Agravado pela Pr√°tica de Exterm√≠nio de Seres Humanos**
- **3371 ‚Äî Homic√≠dio Privilegiado**
- **3372 ‚Äî Homic√≠dio Qualificado**
- **15177 ‚Äî Homic√≠dio Qualificado Contra Menor de 14 Anos (Lei Henry Borel)**
- **3370 ‚Äî Homic√≠dio Simples**
- **3373 ‚Äî Induzimento, Instiga√ß√£o ou Aux√≠lio a Suic√≠dio**
- **3375 ‚Äî Infantic√≠dio**

Poder√≠amos escolher todas ou algumas dessas categorias para nossa an√°lise.

## Escolha Alternativa: Pesquisa por Classe

Nesta aula, por√©m, seguiremos um caminho alternativo: em vez de selecionar um assunto espec√≠fico, trabalharemos com a **classe processual**.

Selecionamos o seguinte ramo:

**Processo Criminal ‚Üí Procedimento Comum ‚Üí A√ß√£o Penal de Compet√™ncia do J√∫ri**

**C√≥digo: 282**

Essa classe captura processos de crimes dolosos contra a vida julgados pelo Tribunal do J√∫ri, alinhados ao nosso objetivo anal√≠tico. Entretanto, muitos dos assuntos acima listados estar√£o presentes. Al√°m disso,  limitamos os nossos processos √† **Inst√¢ncia de 1¬∫ Grau (G1)**.


## Fase Muito Importante

A etapa que descrevemos at√© aqui √© fundamental em qualquer pesquisa emp√≠rica que utilize o DataJud ou outras bases de dados judiciais. As **escolhas feitas nesta fase**, como a defini√ß√£o do assunto, da classe processual e dos crit√©rios de filtragem, **influenciam diretamente o desenho amostral** que construiremos.

Uma **boa sele√ß√£o inicial** garante **maior precis√£o, consist√™ncia e relev√¢ncia dos resultados**. Por isso, √© essencial conduzir essa etapa com aten√ß√£o, calma e organiza√ß√£o. Quanto mais cuidadosa for a defini√ß√£o desses par√¢metros, melhor ser√° a qualidade da extra√ß√£o dos dados e, consequentemente, das an√°lises que realizaremos nas pr√≥ximas fases do curso.

## Colocando a M√£o na Massa: Coleta de Dados no DataJud

### Extra√≠ndo os Dados Processuais

O c√≥digo abaixo extrair√° os dados da **classe 282 do grau G1** do **Tribunal de Justi√ßa do Tocantins** e salvar√° todas essas informa√ß√µes em um dataframe chamado *juri.json*.


```{r eval = FALSE, message=FALSE, warning=FALSE}
# Bibloitecas Necess√°rias
library(tidyverse)
library(httr)
library(jsonlite)

# Definindo a Chave de Acesso
headers = c(
  'Authorization' = 'APIKey cDZHYzlZa0JadVREZDJCendQbXY6SkJlTzNjLV9TRENyQk1RdnFKZGRQdw==',
  'Content-Type' = 'application/json'
)

# Extraindo os dados do DataJud
## Classe 282 e grau G1 (1¬∫ Grau)
body = '{
  "size": 8930,
  "query": {
        "bool": {
            "must": [
                {"match": {"classe.codigo": 282}},
                {"match": {"grau": "G1"}}

            ]
        }
   }
}'

## Do Tribunal de Justi√ßa do Tocantins
POST(url = "https://api-publica.datajud.cnj.jus.br/api_publica_tjto/_search", body = body, add_headers(headers),
write_disk("juri.json"))

## Importanto o dado
juri <- fromJSON("juri.json")
save(juri, file = "juri.rds")
```



Agora vamos analisar a **estrutura do arquivo *juri.json*** para identificar onde cada informa√ß√£o relevante est√° **localizada**. Esse mapeamento √© essencial porque nos permite compreender exatamente como os **dados est√£o organizados** e, assim, definir qual tipo de **extra√ß√£o precisamos realizar** para trabalhar com informa√ß√µes de movimenta√ß√£o, √≥rg√£os julgadores, assuntos e outras caracter√≠sticas presentes no arquivo.

```{r eval = TRUE, message=FALSE, warning=FALSE}
#| results: "hide"

# Pacotes Necess√°rios
library(tidyverse)
library(httr)
library(jsonlite)

## Importanto o dado
load("juri.rds")

# 1. Verifica a classe do objeto (ex.: list, data.frame)
class(juri)  

# 2. ver nomes/elementos de topo
names(juri)          # se for lista ou data.frame, mostra colunas/elementos
length(juri)         # n√∫mero de elementos/top-level items

# 3. Exibe a estrutura do objeto; max.level evita sa√≠da muito grande
str(juri, max.level = 4) 

# 4.Extrai os dados principais: hits -> hits -> _source - Aqui est√£o os dados de interesse
## Cada n√≠vel corresponde a um ramo interno do JSON
dados_basicos <- juri |>
  pluck("hits","hits","_source")
```

### Analisando as Informa√ß√µes Extra√≠das 

**√ìrg√£o Julgador dos Processos**

Vamos criar um banco que contenha o n√∫mero do processo e o √≥rg√£o julgador respons√°vel por cada caso. Em seguida, analisaremos a frequ√™ncia de processos por √≥rg√£o julgador, tanto considerando apenas processos √∫nicos quanto incluindo processos duplicados.


```{r eval = TRUE, message=FALSE, warning=FALSE}

# Pacote que padroniza os nomes das vari√°veis
library(janitor)
library(dplyr)
library(tidyr)

# Criar um dataframe com n√∫mero do processo e √≥rg√£o julgador
julgador <- dados_basicos  |> 
      select(processo = numeroProcesso, orgaoJulgador) |> # Fa√ßo a sele√ß√£o e renomeio a coluna
      unnest(orgaoJulgador) |>  # Como orgaoJulgador √© um dataframe, preciso "desempacotar" os dados
      janitor::clean_names()    # Deixo os nomes padronizados
nrow(julgador) # n√∫mero total de processos
```

Observa-se um **total de 8432 processos**, mas alguns podem estar **duplicados**. Vamos investigar essa quest√£o. Abaixo est√° o c√≥digo para identificar e analisar processos √∫nicos e duplicados.


```{r eval = TRUE, message=FALSE, warning=FALSE}
# Vamos verificar se existem processos duplicados. 
julgador_uni <- julgador %>% 
  distinct(processo, .keep_all = TRUE)
nrow(julgador_uni) # numero total de processos √∫nicos
nrow(julgador) - nrow(julgador_uni) # n√∫mero de processos duplicados

# Vamos analisar os processos duplicados 
julgador_dup <- julgador %>% 
  filter(duplicated(processo) | duplicated(processo, fromLast = TRUE)) 
## Esse comando pega todas as linhas ap√≥s a primeira ocorr√™ncia ou 
## Pega todas as linhas antes da √∫ltima ocorr√™ncia e verifica duplica√ß√£o

## Vamos ver quantos processos duplicados temos:
nrow(julgador_dup) # n√∫mero de processos duplicados
unique(julgador_dup$processo) |> length() # n√∫mero de processos √∫nicos que est√£o duplicados

```

O total de **processos √∫nicos** foi de **8.287**, e identificamos **144 processos duplicados**. Agora, vamos verificar se essas duplica√ß√µes ocorreram em raz√£o de alguma mudan√ßa de √≥rg√£o julgador. Para isso, vamos pivotar os dados e criar uma vari√°vel que indique se houve altera√ß√£o no √≥rg√£o julgador para cada processo duplicado.

```{r eval = TRUE, message=FALSE, warning=FALSE}
## Analisando se houve troca de orga√µ julgador e por isso √© duplicado
# 1. Criar ordem dentro de cada processo 1, para primeira vez e 2 para a segunda vez....
julgador_dup_ord <- julgador_dup %>%
  group_by(processo) %>%
  mutate(orgao_id = row_number()) %>% 
  ungroup()

# 2. Pivotar para formato wide, selciono e indico o nome que ser√° dado
julgador_wide <- julgador_dup_ord %>%
  select(processo, orgao_id, nome) %>%
  pivot_wider(
    names_from = orgao_id,
    values_from = nome,
    names_prefix = "julgador"
  )
# 3. Vari√°vel indicando mudan√ßa
julgador_wide <- julgador_wide %>%
  rowwise() %>%
  mutate(
    mudou_orgao = n_distinct(c_across(starts_with("julgador")), na.rm = TRUE) > 1
  ) %>%
  ungroup()
# - > pega todas as colunas cujo nome come√ßa com "julgador", transforma em vetores e verifica se √© distinto

julgador_wide %>% 
  count(mudou_orgao, sort = TRUE) %>% 
  mutate(
    mudou_orgao = ifelse(mudou_orgao, "Sim", "N√£o")
  ) %>% 
  knitr::kable(
    caption = "Frequ√™ncia de processos que mudaram de √≥rg√£o julgador"
  )
```


Observamos que **93 processos n√£o mudaram de √≥rg√£o julgador** e **51 passaram por altera√ß√£o**. Agora precisamos definir como trataremos esses casos: se consideraremos apenas o *√≥rg√£o julgador final*, se adotaremos o *√≥rg√£o julgador inicial* como refer√™ncia ou *exclu√≠mos*. Mas ainda precisamos observar que h√° **93 processos** que aparecem duplicados, mesmo **sem mudan√ßa de √≥rg√£o julgador**. O que pode estar acontecendo nesses casos?


*LIMPEZA DOS DADOS*

::: {.callout-note title="Escolha e Justificativa" appearance="simple" collapse="true"}

**Motivos Poss√≠veis**: Recursos, mudan√ßas para varas expecializadas, desclassifica√ß√£o, desforamento, entre outros.

**Escolha**: Vamos excluir os processos que mudaram de √≥rg√£o julgador, mantendo apenas aqueles que permaneceram no mesmo √≥rg√£o. Depois analisaremos os processos duplicados restantes.

**Justificativa**: A mudan√ßa de √≥rg√£o julgador pode indicar transfer√™ncias ou redistribui√ß√µes que podem afetar a an√°lise do tempo do processo. Para garantir a consist√™ncia dos dados e evitar vieses, mantemos somente aqueles permaneceram no mesmo √≥rg√£o julgador ao longo do tempo.

:::

```{r eval = TRUE, message=FALSE, warning=FALSE}
# Vamos retirar os processos que mudaram de org√£o julgador 

db_limpo <- dados_basicos %>%
  anti_join(julgador_wide %>% filter(mudou_orgao == TRUE),
            by = c("numeroProcesso" = "processo"))
          
```



Vamos focar nos processos √∫nicos para analisar a frequ√™ncia de √≥rg√£os julgadores e descrever os resultados graficamente e em tabelas.

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(gt)

freq_j_u <- julgador_uni %>% 
  count(nome) %>% 
  arrange(desc(n)) %>% 
  mutate(perc = round(100 * n / sum(n), 1))

ggplot(freq_j_u, aes(x = reorder(nome, n), y = n)) +
  geom_col(fill = "#7185cc", color = "white", alpha = 0.7) +
  coord_flip() +
  labs(
    title = "Frequ√™ncia por √ìrg√£o Julgador (Processos √önicos)",
    x = "√ìrg√£o Julgador",
    y = "Frequ√™ncia"
  ) +
  theme_classic()+
  theme(
    axis.text.y = element_text(size = 4)   # tamanho da letra das categorias
  )


freq_j_u |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia por √ìrg√£o Julgador (Processos √önicos)"
  ) |>
  cols_label(
    nome = "√ìrg√£o Julgador",
    n = "Frequ√™ncia",
    perc = "Percentual"
  )
``` 


*Quest√£o*

Como podemos fazer a nossa an√°lise de movimento considerando que comarcas distintas possuem diferentes volumes de processos? Devemos agrupar as comarcas maiores e as menores? Quais crit√©rios utilizar para isso? Deixamos varas criminais separada de especializadas? 


**Sistema dos Processos**

Aqui avaliamos se os processos pertencem ao sistema **sistema eletr√¥nico de processos judiciais** EPROC ou a outro sistema.

```{r eval = TRUE, message=FALSE, warning=FALSE}
sistema <- db_limpo  |> 
      select(processo = numeroProcesso, sistema) |> 
      unnest(sistema) |>
      janitor::clean_names()

freq_sistema <- sistema %>% 
  count(nome) %>% 
  arrange(desc(n))

freq_sistema |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia por Sistema (Processos √önicos)"
  ) |>
  cols_label(
    nome = "Sistema",
    n = "Frequ√™ncia",
  )
```

Com base na tabela acima, podemos observar a distribui√ß√£o dos processos entre os sistemas Eletr√¥nico e F√≠sico. Observa-se a exist√™ncia somente de processos eletr√¥nicos, mas 4 foram declaros inv√°lidos e 2 Outros. O que fazer com esses casos? Devemos exclu√≠-los da an√°lise ou mant√™-los? 


*LIMPEZA DOS DADOS*


::: {.callout-note title="Escolha e Justificativa" appearance="simple" collapse="true"}

**Motivos Poss√≠veis**: Cita√ß√£o em outros estados, entre outros.

**Escolha**: Vamos excluir todos os processos que n√£o s√£o EPROC.

**Justificativa**: N√£o sabemos ao certo os motivos que levaram a um processo ser classificado como inv√°lido ou outros. Al√©m disso, n√£o sabemos como essa classifica√ß√£o afeta a movimenta√ß√£o. Portanton, vamos excluir todos que n√£o foram EPROC e deixar nossa amostra mais homog√™nea.

:::

```{r eval = TRUE, message=FALSE, warning=FALSE}
# Vamos retirar os processos que mudaram de org√£o julgador 

db_limpo <- db_limpo %>%
  anti_join(sistema %>% filter(!nome == "EPROC"),
            by = c("numeroProcesso" = "processo"))
          
```

**Formato do Processo**

Aqui avaliamos se os processos s√£o do tipo **Eletr√¥nico** ou **F√≠sico**.

```{r eval = TRUE, message=FALSE, warning=FALSE}
formato <- db_limpo  |> 
      select(processo = numeroProcesso, formato) |> 
      unnest(formato) |>
      janitor::clean_names()

freq_formato <- formato %>% 
  count(nome) %>% 
  arrange(desc(n))

freq_formato |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia por Formato (Processos √önicos)"
  ) |>
  cols_label(
    nome = "Formato",
    n = "Frequ√™ncia",
  )
```

Observa-se que 100% dos processos est√£o no formato Eletr√¥nico. Dessa forma, n√£o h√° necessidade de excluir nenhum processo com base nesse crit√©rio.


**Classe Processual** 

Como fizemos nossa busca por classe processual, 282, dever√≠amos ter somente essa classe. Vamos verificar se h√° outras classes presentes nos dados.

```{r eval = TRUE, message=FALSE, warning=FALSE}

classe <- db_limpo  |> 
      select(processo = numeroProcesso, classe) |> 
      unnest(classe) |>
      janitor::clean_names()

freq_classe <- classe %>% 
  count(nome) %>% 
  arrange(desc(n))

freq_classe |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia por Classe (Processos √önicos)"
  ) |>
  cols_label(
    nome = "Classe",
    n = "Frequ√™ncia",
  )
```

Conforme esperado pela nossa consulta inicial, todos os processos pertencem √† classe **A√ß√£o Penal de Compet√™ncia do J√∫ri (282)**. Portanto, n√£o h√° necessidade de excluir nenhum processo com base nesse crit√©rio.



**Assuntos Processuais**

Vamos extrair e analisar os **assuntos processuais** associados a cada processo. Vamos fazer a extra√ß√£o e veja que o resultado √© uma coluna com processo e a outra com o assunto. Se tivermos mais assuntos por processo, esse ser√° duplicado. 

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(purrr)
library(janitor)
library(ggplot2)
library(gt)

 # manter s√≥ linhas em que 'assuntos' √© um data.frame
assuntos <- db_limpo |> 
  filter(map_lgl(assuntos, is.data.frame)) |>
  select(processo = numeroProcesso, assuntos) |>
  unnest(assuntos) |>
  clean_names()

# Processos √∫nicos
nrow(assuntos %>% 
  distinct(processo, .keep_all = TRUE)) # n√∫mero total de processos √∫nicos

freq_assunto <- assuntos |> 
  count(nome) |> 
  arrange(desc(n)) |> 
  mutate(perc_assunto = round(100 * n / sum(n), 1)) |> 
  mutate(perc_processo = round(100 * n / 8228, 1))  # considerando processos √∫nicos


ggplot(freq_assunto, aes(x = reorder(nome, n), y = n)) +
  geom_col(fill = "#7185cc", color = "white", alpha = 0.7) +
  coord_flip() +
  labs(
    title = "Frequ√™ncia por Assunto (Processos √önicos)",
    x = "Assunto",
    y = "Frequ√™ncia"
  ) +
  theme_classic()+
  theme(
    axis.text.y = element_text(size = 4))   # tamanho da letra das categorias
    

freq_assunto |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia dos Assuntos"
  ) |>
  cols_label(
    nome = "Assunto",
    n = "Frequ√™ncia",
    perc_assunto = "% Assuntos",
    perc_processo = "% Processos"
  )

```

**Assuntos** tem um total de **11302 processos**, sendo que o n√∫mero de **processos √∫nicos √© 8228**. Isso indica que muitos processos t√™m mais de um assunto associado. Ent√£o a leitura da tabela acima deve considerar esses n√∫meros. Podemos dizer que **5933** processos tiveram **Homic√≠dio Qualificado** como assunto, **2733** tiveram **Crime Tentado**, e assim por diante. **Existe sobreposi√ß√£o** entre os assuntos. 

Fizemos duas colunas, uma com percentual com base no total de assuntos (11302), **% Assuntos**, e outra com base no total de processos √∫nicos (8228), **% Processos**. A segunda coluna √© mais interessante, pois indica a propor√ß√£o de processos que tiveram cada assunto.

Agora vamos olhar o assunto por processo, para ver quantos assuntos cada processo tem associado.


```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
assuntos_wide <- assuntos %>% 
  group_by(processo, nome) %>%   # garante uma linha por processo-assunto
  summarise(valor = 1, .groups = "drop") %>%
  pivot_wider(
    names_from = nome,
    values_from = valor,
    values_fill = list(valor = 0)   # preenche com 0 se n√£o ocorreu
  )

assuntos_wide %>% 
  slice_head(n = 10) %>% 
  select(1:8) %>%
  gt() %>% 
  tab_header(
    title = "Assuntos por Processo (Exemplo)"
  )
```

Agora cada linha √© um processo √∫nico com todos os assuntos listados. Tivemos um total de 8228. Para o tribunal do Juri tem-se **5 tipos penais**: **Homic√≠dio Qualificado, Homic√≠dio Simples, Infantic√≠dio, Aborto, Induzimento ao Suic√≠dio** e a partir de outubro de 24 o **Feminic√≠dio**. 

**Quest√£o**: 

Devemos incluir todos os assuntos ou focar apenas em alguns? Quais crit√©rios utilizar para essa sele√ß√£o?


*LIMPEZA DOS DADOS*


::: {.callout-note title="Escolha e Justificativa" appearance="simple" collapse="true"}

**Escolha**: Vamos trabalhar somente com homic√≠dio Qualificado, Simples e Feminic√≠dio.

**Justificativa**: Acreditamos que esse esses processos possuem um perfil semelhante entre si, e diferente do infantic√≠dio, aborto e induzimento ao suic√≠dio.

:::

```{r eval = TRUE, message=FALSE, warning=FALSE}
# Vamos retirar os processos que mudaram de org√£o julgador 

assuntos_wide_limpo <- assuntos_wide %>%
  mutate(
    homic_bin = if_any(
      c(
        "Homic√≠dio Qualificado",
        "Homic√≠dio Simples",
        "Feminic√≠dio",
        "Homicidio qualificado",
        "Homic√≠dio",
        "Homic√≠dio Privilegiado",
        "Crimes contra a vida"
      ),
      ~ .x == 1
    ) * 1
  )

db_limpo <- db_limpo %>%
  anti_join(assuntos_wide_limpo %>% filter(homic_bin == 0),
            by = c("numeroProcesso" = "processo"))

nrow(db_limpo) # n√∫mero total de processos ap√≥s limpeza
nrow(db_limpo %>% 
  distinct(numeroProcesso, .keep_all = TRUE)) # n√∫mero total de processos √∫nicos

```

Ao final do procedimento, observamos que o banco de dados **original** continha **8.432 processos**. Ap√≥s as etapas de limpeza e organiza√ß√£o, chegamos a **7.867 registros**. No entanto, ainda identificamos a exist√™ncia de processos duplicados. O total de **processos √∫nicos** √© de **7.775**, o que significa que permanecem **92 processos duplicados** para os quais ainda precisamos definir um tratamento adequado.


*LIMPEZA DOS DADOS*

::: {.callout-note title="Escolha e Justificativa" appearance="simple" collapse="true"}

**Escolha**: Excluir os processos duplicados.

**Justificativa**: Como n√£o est√° claro o motivo dessa duplica√ß√£o e quais seus impactos sobre a movimenta√ß√£o, vamos optar pela exclus√£o desses processos.Note que poderiamos identificar esses processos e fazermos uma an√°lise mais detalhada sobre eles.

**Motivos**: Insidente de insanidade mental, por exemplo. Processo separado mas com mesmo n√∫mero. 

:::


```{r eval = TRUE, message=FALSE, warning=FALSE}
# Vamos retirar os processos que mudaram de org√£o julgador 
db_limpo <- db_limpo %>%
  anti_join(julgador_dup,
            by = c("numeroProcesso" = "processo"))

```

Conclu√≠mos a limpeza com **7.683 processos**, que ser√£o a base da an√°lise de movimenta√ß√£o. Antes de prosseguir, vamos reorganizar as tabelas anteriores  de julgador, assunto e demais vari√°veis, usando agora apenas esse banco de dados limpo.


**TABELAS FINAIS AP√ìS LIMPEZA DOS DADOS**

Com os dados limpos vamos criar uma *data.frame* de julgados final. Nesse vamos deixar o **processo**, o **√≥rg√£o julgador**, e criar vari√°veis que indiquem se o **√≥rg√£o √© especializado** ou n√£o, e se est√° entre os **5 com maior volume de processos**. 

```{r eval = TRUE, message=FALSE, warning=FALSE}

# Pacote que padroniza os nomes das vari√°veis
library(janitor)
library(dplyr)
library(tidyr)

# JULGADOR
julgador_final <- db_limpo  |> 
      select(processo = numeroProcesso, orgaoJulgador) |> 
      unnest(orgaoJulgador) |>   
      janitor::clean_names() 

# Alterando o nome para facilitar a leitura e excluindo o cod do IBGE
julgador_final <- julgador_final %>%
  rename(orgao_julgador = nome) %>%
  select(-codigo_municipio_ibge)  


# Construindo a tabela final do org√£o julgador
freq_j_f <- julgador_final %>% 
  count(orgao_julgador) %>% 
  arrange(desc(n)) %>% 
  mutate(perc = round(100 * n / sum(n), 1))

freq_j_f |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia por √ìrg√£o Julgador (Processos √önicos)"
  ) |>
  cols_label(
    orgao_julgador = "√ìrg√£o Julgador",
    n = "Frequ√™ncia",
    perc = "Percentual"
  )
```

**Identificando a Varas Especializadas e as Varas com Maior Volume de Processos**

```{r eval = TRUE, message=FALSE, warning=FALSE}
# Identificando as Varas Especializadas
julgador_final <- julgador_final %>%
  mutate(
        vara_espec = ifelse(
      orgao_julgador %in% c(
        "Juizo da Especializada no Combate √† Viol√™ncia Contra a Mulher e Crimes Dolosos Contra a Vida de Guru",
        "Ju√≠zo da Vara Criminal, de Viol√™ncia Dom√©stica e Juizado Especial Criminal de Dian√≥polis",
        "Ju√≠zo da Vara Criminal, de Viol√™ncia Dom√©stica e Juizado Especial Criminal de Araguatins"
      ),
      1, 0
    )
  )

# Identificando as varas com maior volume de processos (top 5)

julgador_final <- julgador_final %>%
  mutate(
    volume_top5 = ifelse(
      orgao_julgador %in% c(
        "Ju√≠zo da 1¬™ Vara Criminal de Aragua√≠na",
        "Juizo da 1¬™ Vara Criminal de Palmas",
        "Ju√≠zo da 1¬™ Vara Criminal de Porto Nacional",
        "Ju√≠zo da 1¬™ Vara Criminal de Colinas do Tocantins",
        "Ju√≠zo da 1¬™ Vara Criminal de Para√≠so do Tocantins"
      ),
      1, 0
    )
  )
```


Agora come√ßaremos a montar o **banco de dados final**, agregando todos os bancos que j√° organizamos. Vamos unir as informa√ß√µes de √≥rg√£o julgador, sistema, formato, classe e assunto al√©m das vari√°veis bin√°rias que criamos anteriormente.

```{r eval = TRUE, message=FALSE, warning=FALSE}
sistema_final <- db_limpo  |> 
      select(processo = numeroProcesso, sistema) |> 
      unnest(sistema) |>
      janitor::clean_names()

sistema_final <- sistema_final %>%
  rename(sistema = nome)

bd_final <- julgador_final |> 
  left_join(sistema_final, by = c("processo" = "processo")) |>
  left_join(formato, by = c("processo" = "processo")) |>
  left_join(classe, by = c("processo" = "processo"))

bd_final <- bd_final %>%
  rename(
    cod_julgador = codigo.x,
    cod_sistema = codigo.y,
    cod_formato = codigo.x.x,
    cod_classe = codigo.y.y,
    formato = nome.x,
    classe = nome.y
  )

```

Agora vamos organizar o banco de dados de assuntos. Vamos utilizar o nosso *assunto_wide* para trazer para o nosso banco de dados final e crarmos vari√°veis bin√°rias. 

Primeiro vamos ver se todos os assuntos est√£o presentes e depois vamos deixar somente aqueles que possuem soma maior que zero. 

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)

bd_final <- bd_final |> 
  left_join(assuntos_wide_limpo, by = c("processo" = "processo"))

tabela_somas <- bd_final %>%
  summarise(across(where(is.numeric), ~ sum(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(),
               names_to = "variavel",
               values_to = "soma")


# Mant√©m todas as n√£o num√©ricas 
# Identifica colunas num√©ricas com soma > 0
# Mant√©m apenas num√©ricas cuja soma > 0
bd_final <- bd_final |> 
  select(
    where(~ !is.numeric(.x)),
    where(~ is.numeric(.x) && sum(.x, na.rm = TRUE) > 0)
  ) |> 
  janitor::clean_names()

# Essa vari√°vel criada anteriormente era apenas para apoio
table(bd_final$homic_bin)

# Vamos retirar 
bd_final <- bd_final %>%
  select(-homic_bin)

# Vari√°veis que identificam tipos de homic√≠dio
bd_final <- bd_final %>%
  mutate(
    hq  = ifelse(homicidio_qualificado == 1 | homicidio_qualificado_2 == 1, 1, 0),
    hs  = ifelse(homicidio_simples == 1, 1, 0),
    fem = ifelse(feminicidio == 1, 1, 0)
  )
 
```

Trouxemos a tabela `assuntos_wide_limpo` e identificamos que algumas colunas estavam completamente zeradas. Isso ficou claro a partir da tabela de somas. Assim, removemos apenas as vari√°veis num√©ricas com soma igual a zero, mantendo todas as vari√°veis n√£o num√©ricas.

Tamb√©m exclu√≠mos a vari√°vel `homic_bin`, usada apenas como apoio na etapa anterior.

Por fim, criamos **vari√°veis bin√°rias** para identificar tr√™s categorias principais de homic√≠dio: **homic√≠dio qualificado**, **homic√≠dio simples** e **feminic√≠dio**. √â importante notar que essas categorias podem se sobrepor em alguns processos.



### An√°lise da Movimenta√ß√£o Processual


Agora vamos analisar a movimenta√ß√£o processual. Para isso, precisamos extrair e organizar os dados de movimenta√ß√£o de cada processo. Vamos calcular o tempo decorrido entre cada movimenta√ß√£o e, em seguida, focar na an√°lise do tempo at√© a baixa definitiva do processo.


```{r eval = TRUE, message=FALSE, warning=FALSE}
# Instalando Pacotes necess√°rios
#install.packages("devtools") 
library(janitor)
devtools::install_github("courtsbr/JurisMiner")

movimento <- db_limpo  |> 
      select(processo = numeroProcesso, movimentos) |>
      unnest(movimentos) |> 
      janitor::clean_names() |> 
      select(-complementos_tabelados) |> 
      mutate(data_hora = parse_datetime(data_hora))

movimento  <- movimento |> 
     arrange(processo, desc(data_hora)) |> 
     JurisMiner::tempo_movimentacao(data = data_hora)

movimento  <- movimento |> 
 rename(movimento = nome,
        cod_movimento = codigo
        ) 


```


#### Tempo at√© a Baixa Definitiva

Vamos selecionar todos os processos para os quais conseguimos extrair a baixa definitiva. No c√≥digo abaixo, buscamos manter apenas a primeira baixa de cada processo. Note que alguns processos apresentaram m√∫ltiplas baixas definitivas. Portanto, vamos considerar a √∫ltima baixa definitiva que o processo teve. 

```{r eval = TRUE, message=FALSE, warning=FALSE}
# Tempo at√© a baixa definitiva
tempo_baixa <- movimento |> 
  filter(movimento == "Baixa Definitiva")

# n√∫mero total de processos √∫nicos
nrow(tempo_baixa %>% 
  distinct(processo, .keep_all = TRUE)) 

# Vamos analisar os processos duplicados
# Esse comando pega todas as linhas ap√≥s a primeira ocorr√™ncia ou 
# Pega todas as linhas antes da √∫ltima ocorr√™ncia e verifica duplica√ß√£o 
t_baixa_dup <- tempo_baixa %>% 
  filter(duplicated(processo) | duplicated(processo, fromLast = TRUE)) 


## Vamos ver quantos processos duplicados temos:
# n√∫mero de processos √∫nicos que est√£o duplicados
unique(julgador_dup$processo) |> length() 

## Deixamossomente o que tem a maior decorr√™ncia acumulada
tempo_baixa_unico <- tempo_baixa |> 
  group_by(processo) |> 
  slice_min(decorrencia_acumulada, n = 1) |> 
  ungroup()

```

Observe que agora temos um total de **4595 processos** com baixa definitiva. Iniciamos com **8432 processos**, e ap√≥s a limpeza dos dados, restaram **7683 processos**. Desses, conseguimos identificar a baixa definitiva em 4595 processos. Note uma redu√ß√£o significativa, representando um grupo espec√≠fico de processos que chegaram √† baixa definitiva. 


:::{.callout-note title="Reflex√£o"}

**Quest√£o:**

Os 4.595 representam bem a realidade dos processos de j√∫ri? Ao considerar esses processos estamos selecionando um grupo espec√≠fico? 
:::


** Juntando os Dados de Baixa com o Banco Final**

Agora, vamos juntar com o nosso banco de dados, que criamos na parte anterior, e que cont√©m assunto, classe e as demais vari√°veis bin√°rias que geramos.

```{r eval = TRUE, message=FALSE, warning=FALSE}
baixa_uni_comp <- tempo_baixa_unico |> 
  left_join(bd_final, by = c("processo" = "processo"))

# Verificar se criou uma coluna NA
sum(is.na(baixa_uni_comp$fem))
```

A jun√ß√£o n√£o criou nenhuma coluna com valores **NA**, indicando que todos os processos com baixa definitiva foram **corretamente integrados** ao banco de dados final.


**An√°lise Descritiva Geral**

Primeiramente, vamos descrever ou realizar a an√°lise descritiva do tempo at√© a baixa definitiva do processo. Neste momento, estamos considerando todos os 4.595 processos.


```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(gt)

# Estat√≠sticas descritivas para a vari√°vel decorrencia_acumulada
tempo_stats <- baixa_uni_comp %>%
  summarise(
    media     = mean(decorrencia_acumulada, na.rm = TRUE),
    mediana   = median(decorrencia_acumulada, na.rm = TRUE),
    desvio  = sd(decorrencia_acumulada, na.rm = TRUE),
    variancia = var(decorrencia_acumulada, na.rm = TRUE),
    q1        = quantile(decorrencia_acumulada, 0.25, na.rm = TRUE),
    q3        = quantile(decorrencia_acumulada, 0.75, na.rm = TRUE),
    minimo    = min(decorrencia_acumulada, na.rm = TRUE),
    maximo    = max(decorrencia_acumulada, na.rm = TRUE)
  ) |> 
  pivot_longer(
    cols = everything(),
    names_to = "Estat√≠stica",
    values_to = "Valor"
  ) 

# Tabela GT
tempo_stats %>%
  gt() %>%
  tab_header(
    title = "Estat√≠sticas Descritivas ‚Äî Tempo do Processo at√© Baixa Definitiva",
    subtitle = "Vari√°vel: decorrencia_acumulada"
  ) %>%
  fmt_number(
    columns = Valor,
    decimals = 2
  )
```


A **m√©dia** do tempo do processo at√© a baixa definitiva √© de **1.280 dias**, com **desvio-padr√£o** de **950 dias**, mostrando grande varia√ß√£o nos tempos processuais.   A **mediana** √© de **1.030 dias**, indicando que metade dos processos dura menos do que isso.

*Distribui√ß√£o dos tempos*

- **25%** dos processos s√£o conclu√≠dos em **at√© 554 dias**.  
- **50%** (intervalo interquartil) est√£o entre **554** e **1.762 dias**.  
- **25%** dos processos duram **mais de 1.762 dias**.


**Visualmente**

Vamos analisar tamb√©m o tempo de forma gr√°fica, utilizando diferentes tipos de gr√°ficos. Primeiro, apresentamos o gr√°fico conhecido como BoxPlot; em seguida, o gr√°fico chamado ViolinPlot. Depois, constru√≠mos os gr√°ficos de densidade: inicialmente o histograma e, em seguida, a densidade cont√≠nua. Eles est√£o apresentados abaixo.


**O Box Plot**

O boxplot √© um gr√°fico que traz muitas informa√ß√µes e pode ser visto como a distribui√ß√£o de probabilidade dos dados. 

Como visto acima, o gr√°fico representa a distribui√ß√£o do tempo at√© a baixa definitiva e a sua concentra√ß√£o.  
A **caixa** do boxplot mostra o intervalo interquartil: a parte inferior est√° em **554 dias**, a **mediana** aparece ao redor de **1.030 dias** e o **terceiro quartil** est√° em **1.761 dias**. Esses valores comp√µem o interior da caixa, indicando onde se concentra 50% dos processos.

Observa-se tamb√©m um n√∫mero significativo de **outliers**, representados por pontos acima de aproximadamente **3.600 dias**. Esses processos podem ser classificados como **at√≠picos**, pois apresentam tempos de dura√ß√£o muito superiores ao padr√£o da distribui√ß√£o.



```{r eval = TRUE, message=FALSE, warning=FALSE}
ggplot(baixa_uni_comp, aes(y = decorrencia_acumulada)) +
  geom_boxplot(fill = "#7185cc", color = "#c2986f", alpha=0.7,  # Linhas tracejadas no boxplot
    outlier.shape = 16, outlier.color = "red", outlier.size = 3) + # Boxplot com preenchimento azul e bordas pretas
  labs(
    title = "Boxplot do Tempo do Processo at√© Baixa Definitiva", # T√≠tulo do gr√°fico
    x = "",                                                   # Sem r√≥tulo no eixo x
    y = "Tempo"                        # R√≥tulo do eixo y
  ) +
  coord_flip() + # Inverte os eixos para horizontalidade
  theme_bw() + # Tema limpo e moderno
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"), # Centraliza e estiliza o t√≠tulo
    axis.text.y = element_text(size = 10), # Ajusta o tamanho do texto no eixo y
    axis.title.y = element_text(size = 12) # Ajusta o tamanho do r√≥tulo do eixo y
  )
```


::: {.callout-note title="O BOXPLOT" appearance="simple" collapse="true"}
O box ou caixa cont√©m 50% dos dados. O limite superior indica o percentil de 75% (*Q3*) e o limite inferior indica o percentil de 25% (*Q1*). A linha que corta o box indica a mediana, ou seja, *Q2*. Os bigodes s√£o calculados com base na dist√¢ncia interquant√≠lica, ou seja,

*Limite inferior: Q1-1,5(Q3-Q1)*

*Limite superior:Q3+1,5(Q3-Q1)*

Dados fora desses limites s√£o classificados como suspeitos de serem outliers. Podemos observar a assimetria dos dados quando a mediana n√£o est√° no meio da caixa, indicando maior densidade na menor dist√¢ncia entre os quartis Q1 ou Q3 e a mediana Q2.
:::



**Gr√°fico de Densidade**

Visualizar a distribui√ß√£o emp√≠rica dos dados fornece uma grande quantidade de informa√ß√£o. Um gr√°fico b√°sico em an√°lise descritiva √© o histograma, o qual fornece a distribui√ß√£o de probabilidade emp√≠rica dos dados em um formato de barras. 
O histograma mostra a **frequ√™ncia** de processos em cada faixa de dura√ß√£o at√© a baixa definitiva. A altura de cada barra indica quantos processos est√£o naquela faixa de dias.



```{r eval = TRUE, message=FALSE, warning=FALSE}

ggplot(baixa_uni_comp, aes(x = decorrencia_acumulada)) +
  geom_histogram(bins = 30, fill = "#7185cc", color = "white", alpha = 0.7) +    
  geom_vline(aes(xintercept = mean(decorrencia_acumulada)), color = "#c2986f", size = 1, alpha = 0.7,linetype = "dashed") +
  annotate("text", x = 1400, y = 300, vjust = -0.5, label = "M√©dia", color = "#c2986f", fontface = "bold", size = 4) +
  geom_vline(aes(xintercept = median(decorrencia_acumulada)), color = "#c77878ff", size = 1, alpha = 0.7,linetype = "dashed") + 
  annotate("text", x = 900, y = 400, vjust = -0.5, label = "Mediana", color = "#c77878ff", fontface = "bold", size = 4) + 
  labs(
    x = "Tempo do Processo",                                                 
    y = "Frequ√™ncia",  
    title = "Histograma do Tempo do Processo at√© Baixa Definitiva"   
  ) +
  theme_minimal() + 
 theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),              
    axis.text.x = element_text(size = 12),                                         
    axis.text.y = element_text(size = 10))
```


Observa-se que h√° um n√∫mero relevante de processos com **poucos dias** at√© a baixa definitiva. Pfecisamos decidir o que fazer com esses processos. **Devemos exclu√≠-los?**

A distribui√ß√£o √© **assim√©trica √† direita**, com uma **cauda longa**, o que significa que existe um grupo menor de processos que dura muito mais tempo, esses valores elevados **puxam a m√©dia para cima**.

A maior concentra√ß√£o de processos ocorre entre **800 e 900 dias**, e aproximadamente **metade dos processos** √© conclu√≠da em at√© **1.000 dias**. A partir desse ponto, a frequ√™ncia diminui gradualmente, at√© alcan√ßar valores pr√≥ximos de **4.000 dias**, onde a cauda longa se torna evidente.


Uma outra maneira de visualizar os dados √© utilizando uma **distribui√ß√£o continua** e n√£o mais a discreta. Para isso, utiliza-se a densidade de Kernel para visualiza√ß√£o da distribui√ß√£o de probabilidade da taxa de feminic√≠dio. Vejamos:

```{r eval = TRUE, message=FALSE, warning=FALSE}
 
 ggplot(baixa_uni_comp, aes(x = decorrencia_acumulada)) +
  geom_density(fill = "#7185cc", alpha = 0.4, color = "#7185cc", linewidth = 1) +    
  geom_vline(aes(xintercept = mean(decorrencia_acumulada)), color = "#c2986f", size = 1, alpha = 0.7,linetype = "dashed") +
  annotate("text", x = 1400, y = 0.00005, vjust = -0.5, label = "M√©dia", color = "#c2986f", fontface = "bold", size = 4) +
  geom_vline(aes(xintercept = median(decorrencia_acumulada)), color = "#c77878ff", size = 1, alpha = 0.7,linetype = "dashed") + 
  annotate("text", x = 900, y = 0.00005, vjust = -0.5, label = "Mediana", color = "#c77878ff", fontface = "bold", size = 4) + 
  labs(
    x = "Tempo do Processo",                                                 
    y = "Frequ√™ncia",  
    title = "Histograma do Tempo do Processo at√© Baixa Definitiva"   
  ) +
  theme_minimal() + 
 theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),              
    axis.text.x = element_text(size = 12),                                         
    axis.text.y = element_text(size = 10))
 
```



**An√°lise por √ìrg√£o Julgador**

Vamos analisar agora por √≥rg√£o julgador, os 5 maiores em rela√ß√£o aos demais.

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(gt)

# Estat√≠sticas descritivas estratificadas por volume_top5
tempo_stats_grupo <- baixa_uni_comp %>%
  group_by(volume_top5) %>% 
  summarise(
    media     = mean(decorrencia_acumulada, na.rm = TRUE),
    mediana   = median(decorrencia_acumulada, na.rm = TRUE),
    desvio    = sd(decorrencia_acumulada, na.rm = TRUE),
    variancia = var(decorrencia_acumulada, na.rm = TRUE),
    q1        = quantile(decorrencia_acumulada, 0.25, na.rm = TRUE),
    q3        = quantile(decorrencia_acumulada, 0.75, na.rm = TRUE),
    minimo    = min(decorrencia_acumulada, na.rm = TRUE),
    maximo    = max(decorrencia_acumulada, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -volume_top5,
    names_to = "Estat√≠stica",
    values_to = "Valor"
  )%>%
  pivot_wider(
    names_from = volume_top5,
    values_from = Valor
  )

# Tabela GT
tempo_stats_grupo %>%
  gt(groupname_col = "volume_top5") %>%
  tab_header(
    title = "Estat√≠sticas Descritivas ‚Äî Tempo do Processo at√© Baixa Definitiva",
    subtitle = "Estratificadas 5 maiores √≥rg√£os julgadores )"
  ) %>%
  fmt_number(
    columns = where(is.numeric),
    decimals = 2
  ) %>%
  cols_label(
    Estat√≠stica = "Estat√≠stica",
    `0` = "Demais",
    `1` = "Top 5"
  )
```

Observamos que as **cinco maiores varas** apresentam uma m√©dia de **1.194 dias** at√© a baixa definitiva, enquanto as **demais varas** possuem uma m√©dia de **1.325 dias**. H√°, portanto, uma diferen√ßa entre as m√©dias dos dois grupos.

Tamb√©m se verifica diferen√ßa na **dispers√£o**: nas cinco maiores varas, o desvio-padr√£o √© de **802 dias**, ao passo que nas demais varas ele chega a **1.015 dias**. Isso indica que, al√©m de terem um tempo m√©dio menor, as cinco maiores varas apresentam uma dura√ß√£o dos processos **mais concentrada** e com **menor variabilidade** em compara√ß√£o √†s demais comarcas.

Vejamos a distribui√ß√£o graficamente:


```{r eval = TRUE, message=FALSE, warning=FALSE}
 
library(ggplot2)

# Garantir que seja fator
baixa_uni_comp$volume_top5_factor <- factor(baixa_uni_comp$volume_top5, levels = c(1, 0), labels = c("Top5", "Demais"))

ggplot(baixa_uni_comp, aes(x = decorrencia_acumulada, fill = volume_top5_factor, group = volume_top5_factor)) +
  geom_density(alpha = 0.4, linewidth = 1) +    
  labs(
    x = "Tempo do Processo",                                                 
    y = "Densidade",  
    title = "Distribui√ß√£o do Tempo do Processo at√© Baixa Definitiva"   
  ) +
  scale_fill_manual(
    name = "Grupo de Volume", 
    values = c("Top5" = "#7185cc", "Demais" = "#c77878ff")  # cores espec√≠ficas
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),              
    axis.text.x = element_text(size = 12),                                         
    axis.text.y = element_text(size = 10)
  )

 
```

Para avaliar se a diferen√ßa entre as m√©dias dos dois grupos √© estatisticamente significativa, realizamos um **teste t de diferen√ßa de m√©dias**. O resultado foi **significativo**, indicando que as m√©dias dos dois grupos s√£o, de fato, diferentes.

Em termos pr√°ticos, isso significa que, **em m√©dia**, as cinco varas com maior volume de processos apresentam um **tempo m√©dio de tramita√ß√£o menor** do que o observado nas demais varas.



```{r eval = TRUE, message=FALSE, warning=FALSE}
t.test(
  decorrencia_acumulada ~ volume_top5,
  data = baixa_uni_comp,
  var.equal = FALSE) # teste de Welch (padr√£o e mais seguro)
  
```

Vamos agora analisar por vara especializada versus n√£o especializada.

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(gt)

# Estat√≠sticas descritivas estratificadas por vara especializada
tempo_stats_grupo_espec <- baixa_uni_comp %>%
  group_by(vara_espec) %>% 
  summarise(
    media     = mean(decorrencia_acumulada, na.rm = TRUE),
    mediana   = median(decorrencia_acumulada, na.rm = TRUE),
    desvio    = sd(decorrencia_acumulada, na.rm = TRUE),
    variancia = var(decorrencia_acumulada, na.rm = TRUE),
    q1        = quantile(decorrencia_acumulada, 0.25, na.rm = TRUE),
    q3        = quantile(decorrencia_acumulada, 0.75, na.rm = TRUE),
    minimo    = min(decorrencia_acumulada, na.rm = TRUE),
    maximo    = max(decorrencia_acumulada, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -vara_espec,
    names_to = "Estat√≠stica",
    values_to = "Valor"
  )%>%
  pivot_wider(
    names_from = vara_espec,
    values_from = Valor
  )

# Tabela GT
tempo_stats_grupo_espec %>%
  gt(groupname_col = "volume_top5") %>%
  tab_header(
    title = "Estat√≠sticas Descritivas ‚Äî Tempo do Processo at√© Baixa Definitiva",
    subtitle = "Estratificadas Especializada (1) e Demais (0)"
  ) %>%
  fmt_number(
    columns = where(is.numeric),
    decimals = 2
  ) %>%
  cols_label(
    Estat√≠stica = "Estat√≠stica",
    `0` = "Demais",
    `1` = "Especializada"
  )
```

Neste caso, observamos uma diferen√ßa ainda maior entre os grupos: enquanto as **demais varas** apresentam tempo m√©dio de **1.302 dias**, as **varas especializadas** t√™m m√©dia de **1.138 dias**. 

 
```{r eval = TRUE, message=FALSE, warning=FALSE}
 t.test(
  decorrencia_acumulada ~ vara_espec,
  data = baixa_uni_comp,
  var.equal = FALSE) # teste de Welch (padr√£o e mais seguro)
```

O teste de diferen√ßa de m√©dia mostra que os processos tramitam **mais rapidamente** nas varas especializadas em rela√ß√£o as demais e √© estatisticamente significativo a 1%.



Vamos agora repetir a mesma an√°lise, mas classificando os processos por **assunto**.   Come√ßaremos examinando os casos de **homic√≠dio qualificado**, comparando-os com os demais processos.

O objetivo √© verificar se os processos de homic√≠dio qualificado apresentam um **padr√£o distinto de dura√ß√£o**. 


```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(gt)

# Estat√≠sticas descritivas estratificadas por Homic√≠dio Qualificado
tempo_stats_grupo1 <- baixa_uni_comp %>%
  group_by(hq) %>% 
  summarise(
    media     = mean(decorrencia_acumulada, na.rm = TRUE),
    mediana   = median(decorrencia_acumulada, na.rm = TRUE),
    desvio    = sd(decorrencia_acumulada, na.rm = TRUE),
    variancia = var(decorrencia_acumulada, na.rm = TRUE),
    q1        = quantile(decorrencia_acumulada, 0.25, na.rm = TRUE),
    q3        = quantile(decorrencia_acumulada, 0.75, na.rm = TRUE),
    minimo    = min(decorrencia_acumulada, na.rm = TRUE),
    maximo    = max(decorrencia_acumulada, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -hq,
    names_to = "Estat√≠stica",
    values_to = "Valor"
  )%>%
  pivot_wider(
    names_from = hq,
    values_from = Valor
  )

# Tabela GT
tempo_stats_grupo1 %>%
  gt(groupname_col = "volume_top5") %>%
  tab_header(
    title = "Estat√≠sticas Descritivas ‚Äî Tempo do Processo at√© Baixa Definitiva",
    subtitle = "Estratificadas Homic√≠dio Qualificado (1) e Demais (0)"
  ) %>%
  fmt_number(
    columns = where(is.numeric),
    decimals = 2
  ) %>%
  cols_label(
    Estat√≠stica = "Estat√≠stica",
    `0` = "Demais",
    `1` = "Homic Qualificado"
  )
```

Observamos agora que as m√©dias dos dois grupos s√£o **mais pr√≥ximas**: os processos de **homic√≠dio qualificado** apresentam tempo m√©dio de **1.264 dias**, enquanto os demais processos t√™m m√©dia de **1.319 dias**. Da mesma forma, os **desvios-padr√£o** tamb√©m s√£o semelhantes: cerca de **921 dias** para homic√≠dio qualificado e **1.017 dias** para os demais assuntos. 

Portanto, ao contr√°rio do que vimos no caso das varas, **n√£o h√° uma diferen√ßa t√£o acentuada**.

```{r eval = TRUE, message=FALSE, warning=FALSE}
t.test(
  decorrencia_acumulada ~ hq,
  data = baixa_uni_comp,
  var.equal = FALSE) # teste de Welch (padr√£o e mais seguro)
```

O teste de m√©dia s indicou que a diferen√ßa entre os dois grupos **n√£o √© estatisticamente significativa a 5%**. Isso sugere que, em termos pr√°ticos, o tempo m√©dio de tramita√ß√£o dos processos de homic√≠dio qualificado n√£o difere significativamente dos demais processos.

Vejamos agora os processos de feminic√≠dio, comparando-os com os demais processos. O objetivo √© verificar se os **processos de feminic√≠dio** apresentam um **padr√£o distinto** de dura√ß√£o em rela√ß√£o aos **outros tipos de homic√≠dio**.

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(gt)

# Estat√≠sticas descritivas estratificadas por Feminic√≠dio
tempo_stats_grupo2 <- baixa_uni_comp %>%
  group_by(fem) %>% 
  summarise(
    media     = mean(decorrencia_acumulada, na.rm = TRUE),
    mediana   = median(decorrencia_acumulada, na.rm = TRUE),
    desvio    = sd(decorrencia_acumulada, na.rm = TRUE),
    variancia = var(decorrencia_acumulada, na.rm = TRUE),
    q1        = quantile(decorrencia_acumulada, 0.25, na.rm = TRUE),
    q3        = quantile(decorrencia_acumulada, 0.75, na.rm = TRUE),
    minimo    = min(decorrencia_acumulada, na.rm = TRUE),
    maximo    = max(decorrencia_acumulada, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -fem,
    names_to = "Estat√≠stica",
    values_to = "Valor"
  )%>%
  pivot_wider(
    names_from = fem,
    values_from = Valor
  )

# Tabela GT
tempo_stats_grupo2 %>%
  gt(groupname_col = "volume_top5") %>%
  tab_header(
    title = "Estat√≠sticas Descritivas ‚Äî Tempo do Processo at√© Baixa Definitiva",
    subtitle = "Estratificadas Feminic√≠dio (1) e Demais (0)"
  ) %>%
  fmt_number(
    columns = where(is.numeric),
    decimals = 2
  ) %>%
  cols_label(
    Estat√≠stica = "Estat√≠stica",
    `0` = "Demais",
    `1` = "Feminic√≠dio"
  )
```

```{r eval = TRUE, message=FALSE, warning=FALSE}

 t.test(
  decorrencia_acumulada ~ fem,
  data = baixa_uni_comp,
  var.equal = FALSE) # teste de Welch (padr√£o e mais seguro)
```

Observamos que os processos classificados como **feminic√≠dio** apresentam uma **m√©dia de dura√ß√£o menor** do que aqueles n√£o classificados dessa forma. A diferen√ßa entre as m√©dias √© de aproximadamente **150 dias**, e √© estatisticamente significativa a 5%

Vamos tentar analisar por meio de um modelo linear multivariado, que considera todas as vari√°veis anteriores. 

```{r eval = TRUE, message=FALSE, warning=FALSE}
#install.packages("modelsummary")
library(modelsummary)

lm_model <- lm(decorrencia_acumulada ~ volume_top5 + vara_espec + hq + fem, data = baixa_uni_comp)

modelsummary(
  lm_model,
  output = "gt",
  statistic = c("std.error", "p.value"),
  shape = term ~ statistic,
  fmt=2,
  gof_map = tribble(
    ~raw,           ~clean,              ~fmt,
    "adj.r.squared","R¬≤ ajustado",       3,
    "nobs",         "N. de observa√ß√µes", 0,
    "fstatistic",   "Estat√≠stica F",     3
  ),
  stars = TRUE,
  title = "Modelo de Regress√£o Linear",
  notes = "S.E.: Erro padr√£o."
)

```

Observe-se que o intercepto do nosso modelo √© de **1.418 dias**. Esse valor representa o tempo m√©dio dos processos que **n√£o** est√£o entre as cinco varas de maior volume, **n√£o** tramitam em varas especializadas e **n√£o** s√£o classificados como homic√≠dio qualificado ou feminic√≠dio. Ou seja, √© o valor esperado quando **todas as demais vari√°veis do modelo s√£o iguais a zero**. Esta √© a interpreta√ß√£o b√°sica do intercepto.

Em rela√ß√£o a esse grupo de refer√™ncia, observamos redu√ß√µes importantes no tempo m√©dio do processo:

- Nas **cinco varas de maior volume**, o tempo m√©dio √© cerca de **171 dias menor** do que o valor do intercepto (1.418 dias).
- Nas **varas especializadas**, a redu√ß√£o √© ainda maior, aproximadamente **238 dias** a menos em rela√ß√£o ao intercepto.
- Para os processos classificados como **feminic√≠dio**, h√° tamb√©m uma diminui√ß√£o m√©dia de **164 dias**.

Esses valores indicam quanto cada caracter√≠stica reduz o tempo esperado em compara√ß√£o com o grupo base definido pelo intercepto.


#### Analisando as Fases do Processo de J√∫ri
A estrat√©gia de an√°lise ser√° a seguinte: 

```{mermaid}
flowchart LR
  A[Distribui√ß√£o] --> B[Recebimento da Den√∫ncia]
  B --> C[Aud. Instru√ß√£o e Julgamento]
  C --> D[Dec. Pron√∫ncia]
  D --> E[Se√ß. Trib. do J√∫ri]
```

* Distribui√ß√£o: 
* Recebimento da Den√∫ncia: **391**
* Audi√™ncia de Instru√ß√£o e Julgamento: **12750**
* Decis√£o de Pron√∫ncia: **10953**
* Se√ß√£o do Tribunal do J√∫ri: **313**



**Montando os bancos de dados para cada fase do processo**

Vamos montar os bancos e organizar um banco √∫nico para cada fase do processo de j√∫ri.

```{r eval = FALSE, message=FALSE, warning=FALSE}

# Montar as bases e selecionar apenas as vari√°veis desejadas em cada base

# Tempo at√© a denuncia
t_denuncia <- movimento |> 
  filter(cod_movimento == "391")

## Deixamos somente a primeira denuncia
t_denuncia_unico <- t_denuncia |> 
  group_by(processo) |> 
  slice_min(decorrencia_acumulada, n = 1) |> 
  ungroup()

t_denuncia_unico <- t_denuncia_unico |>
  select(processo, cod_movimento, decorrencia_acumulada, data_hora) |>
  rename(cod_denuncia=cod_movimento,
         deco_denuncia = decorrencia_acumulada,
         data_denuncia  = data_hora)

# Tempo at√© a Instru√ß√£o e Julgamento
t_int_julg <- movimento |> 
  filter(cod_movimento == "12750")

## Deixamos somente a primeira instru√ß√£o e julgamento
t_int_julg_unico <- t_int_julg |> 
  group_by(processo) |>
  slice_min(decorrencia_acumulada, n = 1) |> 
  ungroup()

t_int_julg_unico <- t_int_julg_unico |>
  select(processo, cod_movimento, decorrencia_acumulada, data_hora) |>
  rename(cod_instr=cod_movimento,
          deco_intjulg = decorrencia_acumulada,
         data_intjulg  = data_hora)


# Tempo at√© a pronuncia
t_pronun <- movimento |> 
  filter(cod_movimento == "10953")

## Deixamos somente a primeira denuncia
t_pronun_unico <- t_pronun |> 
  group_by(processo) |> 
  slice_min(decorrencia_acumulada, n = 1) |> 
  ungroup()
t_pronun_unico <- t_pronun_unico |>
  select(processo, cod_movimento, decorrencia_acumulada, data_hora) |>
  rename(cod_pronun=cod_movimento,
         deco_pronun = decorrencia_acumulada,
         data_pronun  = data_hora)

# Tempo at√© a juri
t_juri <- movimento |> 
  filter(cod_movimento == "313")

## Deixamos somente a primeira denuncia
t_juri_unico <- t_juri |> 
  group_by(processo) |> 
  slice_min(decorrencia_acumulada, n = 1) |> 
  ungroup()

t_juri_unico <- t_juri_unico %>% 
  distinct(processo, .keep_all = TRUE)


t_juri_unico <- t_juri_unico |>
  select(processo, cod_movimento, decorrencia_acumulada, data_hora) |>
  rename(cod_juri=cod_movimento,
         deco_juri = decorrencia_acumulada,
         data_juri  = data_hora)



tempo_baixa_unico <- tempo_baixa_unico |>
  select(processo, cod_movimento, decorrencia_acumulada, data_hora) |>
  rename(cod_baixa=cod_movimento,
         deco_baixa = decorrencia_acumulada,
         data_baixa  = data_hora)

mov_final <- bd_final |> 
  left_join(t_denuncia_unico, by ="processo")|> 
  left_join(t_int_julg_unico, by = "processo") |>
  left_join(t_pronun_unico,   by = "processo") |>
  left_join(t_juri_unico,     by = "processo") |> 
  left_join(tempo_baixa_unico, by ="processo")


mov_final <- mov_final |>
  drop_na(deco_intjulg, deco_baixa, deco_juri, deco_pronun, deco_denuncia)



```


Agora que juntamos todas as movimenta√ß√µes e eliminamos os casos com valores ausentes e chegamos a um total de **1.034 processos**. 

Partimos originalmente de **8.432 processos** no banco b√°sico. Portanto, houve uma redu√ß√£o substancial da base anal√≠tica, com a exclus√£o de aproximadamente **7.400 processos**.

Essa redu√ß√£o levanta uma quest√£o central para a an√°lise:  
**os 1.034 processos restantes s√£o representativos do conjunto original ou formam um grupo com caracter√≠sticas muito diferentes?**  


Para evitar vi√©s de sele√ß√£o, vamos seguir olhando cada vari√°vel individualmente e comparando as estat√≠sticas descritivas de cada fase do processo.
  
```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(purrr)
library(gt)

# 1. Fun√ß√£o para gerar estat√≠sticas descritivas
make_stats <- function(x) {
  tibble::tibble(
    Estat√≠stica = c(
      "media", "mediana", "desvio", "variancia",
      "q1", "q3", "minimo", "maximo"
    ),
    Valor = c(
      mean(x, na.rm = TRUE),
      median(x, na.rm = TRUE),
      sd(x, na.rm = TRUE),
      var(x, na.rm = TRUE),
      quantile(x, 0.25, na.rm = TRUE),
      quantile(x, 0.75, na.rm = TRUE),
      min(x, na.rm = TRUE),
      max(x, na.rm = TRUE)
    )
  )
}



# Tempo at√© a denuncia
t_denuncia <- movimento |> 
  filter(cod_movimento == "391")
t_denuncia_unico <- t_denuncia |> 
  group_by(processo) |> 
  slice_min(decorrencia_acumulada, n = 1) |> 
  ungroup()
t_denuncia_unico <- t_denuncia_unico |>
  select(processo, cod_movimento, decorrencia_acumulada, data_hora) |>
  rename(cod_denuncia=cod_movimento,
         deco_denuncia = decorrencia_acumulada,
         data_denuncia  = data_hora)
# Tempo at√© a Instru√ß√£o e Julgamento
t_int_julg <- movimento |> 
  filter(cod_movimento == "12750")
t_int_julg_unico <- t_int_julg |> 
  group_by(processo) |>
  slice_min(decorrencia_acumulada, n = 1) |> 
  ungroup()
t_int_julg_unico <- t_int_julg_unico |>
  select(processo, cod_movimento, decorrencia_acumulada, data_hora) |>
  rename(cod_instr=cod_movimento,
          deco_intjulg = decorrencia_acumulada,
         data_intjulg  = data_hora)

# Tempo at√© a pronuncia
t_pronun <- movimento |> 
  filter(cod_movimento == "10953")
t_pronun_unico <- t_pronun |> 
  group_by(processo) |> 
  slice_min(decorrencia_acumulada, n = 1) |> 
  ungroup()
t_pronun_unico <- t_pronun_unico |>
  select(processo, cod_movimento, decorrencia_acumulada, data_hora) |>
  rename(cod_pronun=cod_movimento,
         deco_pronun = decorrencia_acumulada,
         data_pronun  = data_hora)

# Tempo at√© a juri
t_juri <- movimento |> 
  filter(cod_movimento == "313")
t_juri_unico <- t_juri |> 
  group_by(processo) |> 
  slice_min(decorrencia_acumulada, n = 1) |> 
  ungroup()
t_juri_unico <- t_juri_unico %>% 
  distinct(processo, .keep_all = TRUE)
t_juri_unico <- t_juri_unico |>
  select(processo, cod_movimento, decorrencia_acumulada, data_hora) |>
  rename(cod_juri=cod_movimento,
         deco_juri = decorrencia_acumulada,
         data_juri  = data_hora)

tempo_baixa_unico <- tempo_baixa_unico |>
  select(processo, cod_movimento, decorrencia_acumulada, data_hora) |>
  rename(cod_baixa=cod_movimento,
         deco_baixa = decorrencia_acumulada,
         data_baixa  = data_hora)

# 2. Gerar estat√≠sticas para cada banco

stats_denuncia <- make_stats(t_denuncia_unico$deco_denuncia)
stats_intjulg <- make_stats(t_int_julg_unico$deco_intjulg)
stats_pronun <- make_stats(t_pronun_unico$deco_pronun)
stats_juri <- make_stats( t_juri_unico$deco_juri)
stats_baixa <- make_stats(tempo_baixa_unico$deco_baixa)

# 3. Juntar tudo em uma √∫nica tabela
stats_baixa    <- stats_baixa    %>% rename(Baixa = Valor)
stats_intjulg  <- stats_intjulg  %>% rename(Instr_Julg = Valor)
stats_pronun   <- stats_pronun   %>% rename(Pronuncia = Valor)
stats_juri     <- stats_juri     %>% rename(Juri = Valor)
stats_denuncia <- stats_denuncia %>% rename(Denuncia = Valor)

all_stats <- stats_denuncia %>%
  left_join(stats_intjulg,  by = "Estat√≠stica") %>%
  left_join(stats_pronun,   by = "Estat√≠stica") %>%
  left_join(stats_juri,     by = "Estat√≠stica") %>%
  left_join(stats_baixa, by = "Estat√≠stica")

# 4. Gerar tabela final
all_stats %>%
  gt() %>%
  fmt_number(
    columns = where(is.numeric),  # aplica a todas as colunas num√©ricas
    decimals = 2
  ) %>%
  tab_header(
    title = "Estat√≠sticas Descritivas ‚Äî Todas as Fases do Processo"
  )
```


Nessa tabela tem-se uma vis√£o geral das estat√≠sticas descritivas para cada fase do processo. Observa-se que o tempo m√©dio da distribui√ß√£o at√© o Recebimento da Den√∫ncia √© de **32,51 dias**. J√° o tempo m√©dio da distribui√ß√£o at√© a Audi√™ncia de Instru√ß√£o e Julgamento √© de **490,23 dias**.


#### Da distribui√ß√£o at√© o Recebimento da Den√∫ncia


Primeiro vamos analisar o tempo entre a distribui√ß√£o do processo e o recebimento da den√∫ncia. Graficamente tem-se: 

```{r eval = TRUE, message=FALSE, warning=FALSE}
t_denuncia_unico <- t_denuncia_unico

ggplot(t_denuncia_unico, aes(x = deco_denuncia)) +
  geom_histogram(bins = 3000, fill = "#7185cc", color = "white", alpha = 0.7) +    
  geom_vline(aes(xintercept = mean(deco_denuncia)), color = "#c2986f", size = 1, alpha = 0.7,linetype = "dashed") +
  annotate("text", x = 37, y = 500, vjust = -0.5, label = "M√©dia", color = "#c2986f", fontface = "bold", size = 4) +
  geom_vline(aes(xintercept = median(deco_denuncia)), color = "#c77878ff", size = 1, alpha = 0.7,linetype = "dashed") + 
  annotate("text", x = 7, y = 500, vjust = -0.5, label = "Mediana", color = "#c77878ff", fontface = "bold", size = 4) + 
  labs(
    x = "Tempo em dias (at√© 50 dias)",                                                 
    y = "Frequ√™ncia",  
    title = "Histograma do Tempo da Distribui√ß√£o at√© a Den√∫ncia"   
  ) +
  coord_cartesian(xlim = c(0, 50)) +
  theme_minimal() + 
 theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),              
    axis.text.x = element_text(size = 12),                                         
    axis.text.y = element_text(size = 10))
 
```


Observa-se que **50% dos processos duram menos de 3 dias** entre a **distribui√ß√£o** e o **recebimento da den√∫ncia**. Entretanto, a **m√©dia √© bem maior**, em torno de **32 dias**.

Essa diferen√ßa indica que existem **processos com dura√ß√£o muito longa**, alguns com mais de 100 dias, que **puxam a m√©dia para cima**. Ou seja, a distribui√ß√£o √© assim√©trica, com uma **cauda longa √† direita**.

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)

# Contar quantos processos t√™m soma maior que 30 dias
t_denuncia_unico %>%
  filter(deco_denuncia > 30) %>%
  summarise(n = n(),
            percentual = n() / nrow(t_denuncia_unico) * 100,
            media= mean(deco_denuncia))

```

Observa-se que aproximadamente **12% dos processos** levam mais de **30 dias** entre a distribui√ß√£o e o recebimento da den√∫ncia e possuem m√©dia de **245 dias** nesse grupo.

Para entender melhor essa diferen√ßa, iremos **investigar os atos ordinat√≥rios** e outros atos, pois eles podem estar **contribuindo significativamente para o aumento do tempo entre distribui√ß√£o e den√∫ncia**.

**Movimenta√ß√£o at√© Recebimento da Den√∫ncia**

Vamos analisar a movimenta√ß√£o do processo desde a distribui√ß√£o at√© o recebimento da den√∫ncia. Vamos criar um banco espec√≠fico para essa an√°lise.


```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)

# 1. Identificar o tempo da den√∫ncia para cada processo
tempo_denuncia <- movimento |> 
  filter(cod_movimento == "391") |> 
  group_by(processo) |> 
  slice_min(decorrencia_acumulada, n = 1)  |> 
  select(processo, deco_denuncia=decorrencia_acumulada)

# 2. Selecionar todos os atos at√© a den√∫ncia
atos_ate_denuncia <- movimento %>%
  left_join(tempo_denuncia, by = "processo") %>%
  filter(decorrencia_acumulada <= deco_denuncia) 
```

Criamos um banco que possui todos os movimentos processuais desde a distribui√ß√£o at√© o recebimento da den√∫ncia. Agora, vamos analisar a frequ√™ncia dos movimentos processuais.

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(gt)

freq_movimento <- atos_ate_denuncia %>%
  count(movimento, sort = TRUE)  # conta por descri√ß√£o do movimento

freq_movimento %>%
  gt() %>%
  tab_header(
    title = "Frequ√™ncia de Movimentos at√© a Den√∫ncia"
  ) %>%
  fmt_number(
    columns = "n",
    decimals = 0
  ) %>%
  cols_label(
    movimento = "Movimento",
    n = "Frequ√™ncia"
  )



```


E abaixo vamos **somar o tempo** de cada **ato ordinat√≥rio** por processo. 



```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
# Filtra somente atos ordinat√≥rios e soma por processo
soma_ordinatorios <- atos_ate_denuncia %>%
  filter(cod_movimento == 11383) %>%   # filtra apenas atos ordinat√≥rios
  group_by(processo) %>%                       # agrupa por processo
  summarise(soma_decorrencia = sum(decorrencia, na.rm = TRUE))
```	

Agora temos um banco com a soma do tempo dos atos ordinat√≥rios para cada processo, desde a distribui√ß√£o at√© o recebimento da den√∫ncia. Vamos **analisar as estat√≠sticas** descritivas dessa vari√°vel.


```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(gt)

# Estat√≠sticas descritivas para a vari√°vel decorrencia_acumulada
tempo_stats <- soma_ordinatorios %>%
  summarise(
    media     = mean(soma_decorrencia, na.rm = TRUE),
    mediana   = median(soma_decorrencia, na.rm = TRUE),
    desvio  = sd(soma_decorrencia, na.rm = TRUE),
    variancia = var(soma_decorrencia, na.rm = TRUE),
    q1        = quantile(soma_decorrencia, 0.25, na.rm = TRUE),
    q3        = quantile(soma_decorrencia, 0.75, na.rm = TRUE),
    minimo    = min(soma_decorrencia, na.rm = TRUE),
    maximo    = max(soma_decorrencia, na.rm = TRUE)
  ) |> 
  pivot_longer(
    cols = everything(),
    names_to = "Estat√≠stica",
    values_to = "Valor"
  ) 

# Tabela GT
tempo_stats %>%
  gt() %>%
  tab_header(
    title = "Estat√≠sticas Descritivas ‚Äî Tempo m√©dios dos Atos Ordinat√≥rios at√© a Den√∫ncia",
    subtitle = "Vari√°vel: decorrencia"
  ) %>%
  fmt_number(
    columns = Valor,
    decimals = 2
  )
```

Observa-se que a **mediana** do tempo dos **atos ordinat√≥rios** √© muito baixa, cerca de **0,12 dias** (aproximadamente **3 horas**).

Entretanto, a **m√©dia** √© significativamente maior, em torno de **3,5 dias**, indicando que existem **processos com atos ordinat√≥rios muito longos**, que elevam o valor m√©dio. O **desvio-padr√£o** tamb√©m √© alto, refor√ßando que h√° grande **varia√ß√£o entre os processos**.

Esses resultados sugerem que √© importante analisar mais detalhadamente os **atos ordinat√≥rios**, especialmente nos processos que apresentam **tempos excepcionalmente longos**, para entender o que est√° causando essa discrep√¢ncia.


Graficamente, a distribui√ß√£o do tempo dos atos ordinat√≥rios at√© a den√∫ncia pode ser visualizada da seguinte forma:

```{r eval = TRUE, message=FALSE, warning=FALSE}
 
ggplot(soma_ordinatorios, aes(x = soma_decorrencia)) +
  geom_histogram(bins = 3000, fill = "#7185cc", color = "white", alpha = 0.7) +    
  geom_vline(aes(xintercept = mean(soma_decorrencia)), color = "#c2986f", size = 1, alpha = 0.7,linetype = "dashed") +
  annotate("text", x = 5, y = 750, vjust = -0.5, label = "M√©dia", color = "#c2986f", fontface = "bold", size = 4) +
  geom_vline(aes(xintercept = median(soma_decorrencia)), color = "#c77878ff", size = 1, alpha = 0.7,linetype = "dashed") + 
  annotate("text", x = 2, y = 1000, vjust = -0.5, label = "Mediana", color = "#c77878ff", fontface = "bold", size = 4) + 
  labs(
    x = "Tempo do Atos Ordinat√≥rios",                                                 
    y = "Frequ√™ncia",  
    title = "Histograma do Tempo Atos Ordinat√≥rios at√© a Den√∫ncia"   
  ) +
  coord_cartesian(xlim = c(0, 25)) +
  theme_minimal() + 
 theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),              
    axis.text.x = element_text(size = 12),                                         
    axis.text.y = element_text(size = 10))
 
```


Como j√° visto a **mediana** da participa√ß√£o dos atos ordinat√≥rios √© **0,12 dias** (aproximadamente **3 horas**), enquanto a **m√©dia** √© de **3,5 dias**. A distribui√ß√£o apresenta uma **cauda longa √† direita**, evidenciando a presen√ßa de processos com **atos ordinat√≥rios excepcionalmente longos**, que merecem an√°lise detalhada.


Passamos a estudar a **participa√ß√£o dos atos ordinat√≥rios** no **tempo total entre distribui√ß√£o e recebimento da den√∫ncia**.

O objetivo √© entender:

* **Quanto maior a participa√ß√£o**, maior o tempo gasto entre a distribui√ß√£o e den√∫ncia?
* Como o tempo dos atos ordinat√≥rios se relaciona com o **tempo at√© a den√∫ncia**?

Para isso, abaixo apresentamos uma **tabela** que mostra, para cada processo, a **participa√ß√£o dos atos ordinat√≥rios** e o **tempo total entre distribui√ß√£o e den√∫ncia**.


```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)

part_atos_ord <-  t_denuncia_unico |> 
  left_join(soma_ordinatorios, by = "processo") |> 
  mutate(
    soma_decorrencia = replace_na(soma_decorrencia, 0), 
    participacao = (soma_decorrencia) / deco_denuncia * 100)
```

Agora temos um banco que mostra a participa√ß√£o dos atos ordinat√≥rios no tempo total entre a distribui√ß√£o e o recebimento da den√∫ncia. Vamos **analisar as estat√≠sticas descritivas** dessa participa√ß√£o.

```{r eval = TRUE, message=FALSE, warning=FALSE}	
library(ggplot2)
library(dplyr)

# Scatterplot: Participa√ß√£o vs Deco_den√∫ncia
ggplot(part_atos_ord, aes(x = soma_decorrencia, y = deco_denuncia)) +
  geom_point(color = "#7185cc", alpha = 0.6, size = 2) +
  geom_smooth(method = "lm", color = "#c2986f", se = FALSE, linetype = "dashed") +  # linha de tend√™ncia
  labs(
    x = "Participa√ß√£o dos Atos Ordinat√≥rios (%)",
    y = "Tempo at√© Den√∫ncia (dias)",
    title = "Rela√ß√£o entre Participa√ß√£o dos Atos Ordinat√≥rios e Tempo at√© a Den√∫ncia"
  ) +
    coord_cartesian(xlim = c(0, 25), ylim = c(0, 100)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 10)
  )

# Correla√ß√£o entre participa√ß√£o e deco_denuncia
correlation <- cor(part_atos_ord$soma_decorrencia, part_atos_ord$deco_denuncia, use = "complete.obs")
correlation
```

Observa-se que h√° uma **rela√ß√£o positiva** entre a participa√ß√£o dos atos ordinat√≥rios e o tempo at√© a den√∫ncia. Ou seja, **quanto maior a participa√ß√£o dos atos ordinat√≥rios, maior tende a ser o tempo at√© a den√∫ncia**. Entretanto a correla√ß√£o n√£o √© alta, cerca de **0,52**, indicando que outros fatores tamb√©m influenciam o tempo at√© a den√∫ncia.

Agora vamos explorar visiualmente se quanto maior a participa√ß√£o dos atos ordinat√≥rios, maior √© o tempo total at√© a den√∫ncia. Primeiramente vamos analisar os processos com soma dos **atos ordinat√≥rios > 3 dias**.

```	{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)

# Filtrar processos com soma dos atos ordinat√≥rios > 30 dias
part_mais_3 <- part_atos_ord %>%
  filter(soma_decorrencia > 3)

# Histograma da participa√ß√£o
ggplot(part_mais_3, aes(x = participacao )) +
  geom_histogram(binwidth = 5, fill = "#7185cc", color = "#7185cc", alpha = 0.4) +
  labs(
    x = "Participa√ß√£o dos Atos Ordinat√≥rios (%)",
    y = "N√∫mero de Processos",
    title = "Distribui√ß√£o da Participa√ß√£o dos Atos Ordinat√≥rios (somente >3 dias)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 10)
  )
```

Observa-se que n√£o h√° nenhum padr√£o claro, mostrando que a participa√ß√£o √© pr√≥xima de **uma distribui√ß√£o uniforme** para os processos com soma dos atos ordinat√≥rios **maior que 3 dias**.

Abaixo mostramos nos processos com soma dos atos ordinat√≥rios entre **1 e 3 dias**.

```	{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)

# Filtrar processos com soma dos atos ordinat√≥rios > 30 dias
part_menos_3 <- part_atos_ord %>%
  filter(soma_decorrencia <= 3 & soma_decorrencia > 1)

# Histograma da participa√ß√£o
ggplot(part_menos_3, aes(x = participacao )) +
  geom_histogram(binwidth = 5, fill = "#7185cc", color = "#7185cc", alpha = 0.4) +
  labs(
    x = "Participa√ß√£o dos Atos Ordinat√≥rios (%)",
    y = "N√∫mero de Processos",
    title = "Distribui√ß√£o da Participa√ß√£o dos Atos Ordinat√≥rios (somente entre 1 e 3 dias)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 10)
  )
```

Novamente, observa-se que n√£o h√° nenhum padr√£o claro para os processos com soma dos atos ordinat√≥rios entre **1 e 3 dias**.




