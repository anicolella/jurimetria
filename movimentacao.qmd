---
title: "Aula Pr√°tica: Coleta e An√°lise de Dados sobre Homic√≠dio Qualificado"
author:
- Jos√© de Jesus Filho e Alexandre Nicolella
format: html
---



## Introdu√ß√£o √† Aula Pr√°tica: Coleta de Dados no DataJud

Nesta aula pr√°tica, vamos aprender como coletar dados processuais utilizando a Base Nacional de Dados do Poder Judici√°rio (**DataJud**), mantida pelo Conselho Nacional de Justi√ßa (CNJ). O DataJud √© o sistema respons√°vel pelo armazenamento centralizado de dados e metadados de todos os processos judiciais brasileiros, f√≠sicos ou eletr√¥nicos, e ser√° a base que utilizaremos ao longo do curso.

##  Acesso ao DataJud

O DataJud pode ser acessado diretamente no site do CNJ üîó:

[https://www.cnj.jus.br/sistemas/datajud/](https://www.cnj.jus.br/sistemas/datajud/)

A plataforma fornece dados atualizados para diversos os ramos da Justi√ßa brasileira, agrupados e padronizados para permitir an√°lises estat√≠sticas e jurim√©tricas.

##  Autentica√ß√£o e Chave P√∫blica

Para acessar os dados via API, utilizaremos a **API P√∫blica** do DataJud, documentada em:

[https://datajud-wiki.cnj.jus.br/api-publica/](https://datajud-wiki.cnj.jus.br/api-publica/)

A autentica√ß√£o √© feita por meio de uma chave p√∫blica, disponibilizada pelo DPJ/CNJ. A chave  üîë pode ser obtida no seguinte endere√ßo:

[https://datajud-wiki.cnj.jus.br/api-publica/acesso](https://datajud-wiki.cnj.jus.br/api-publica/acesso)

Essa chave ser√° utilizada diretamente no c√≥digo em R (ou Python), permitindo realizar consultas autenticadas aos dados processuais.

##  Endpoints, Rotas e Sele√ß√£o de Tribunais

Para realizar nossas consultas, precisamos escolher os endpoints dispon√≠veis, indicando o tribunal desejado. Os endpoints est√£o detalhados em:

[https://datajud-wiki.cnj.jus.br/api-publica/endpoints](https://datajud-wiki.cnj.jus.br/api-publica/endpoints)

√â poss√≠vel consultar processos de de diversos ramos da Justi√ßa brasileira:

- **Tribunais Superiores**
- **Justi√ßa Federal**
- **Justi√ßa Estadual**
- **Justi√ßa do Trabalho**
- **Justi√ßa Eleitoral**
- **Justi√ßa Militar**

No nosso estudo, utilizaremos os dados do **Tribunal de Justi√ßa do Tocantins (TJTO)**.


##  Tipos de Consultas Poss√≠veis

A API permite diferentes modalidades de consulta üîç, como:

- Pesquisa por n√∫mero do processo
- Pesquisa paginada
- Pesquisa por classe
- Pesquisa por assunto
- ...

O DataJud tamb√©m disponibiliza exemplos de c√≥digo em Python e R, acess√≠veis na aba de exemplos:

[https://datajud-wiki.cnj.jus.br/api-publica/exemplos/](https://datajud-wiki.cnj.jus.br/api-publica/exemplos/)


##  Gloss√°rio de Vari√°veis

O DataJud define nomes espec√≠ficos para cada uma das vari√°veis retornadas pela API. O significado de cada termo pode ser consultado no gloss√°rio oficial:

[https://datajud-wiki.cnj.jus.br/api-publica/glossario](https://datajud-wiki.cnj.jus.br/api-publica/glossario)

Esse gloss√°rio √© essencial para interpretar corretamente os dados coletados.


## Sele√ß√£o do Assunto de Interesse

Em geral, ao iniciar uma pesquisa emp√≠rica, precisamos definir o assunto processual a ser analisado. Para isso, utilizamos o Sistema de Gest√£o de Tabelas Processuais Unificadas:

[https://www.cnj.jus.br/sgt/consulta_publica_assuntos.php](https://www.cnj.jus.br/sgt/consulta_publica_assuntos.php)

No nosso caso, o foco inicial seria **Direito Penal/Crimes Contra a Vida**, que inclui subcategorias como:

- **10915 ‚Äî Aborto**
- **12091 ‚Äî Feminic√≠dio**
- **12130 ‚Äî Homic√≠dio Agravado pela Pr√°tica de Exterm√≠nio de Seres Humanos**
- **3371 ‚Äî Homic√≠dio Privilegiado**
- **3372 ‚Äî Homic√≠dio Qualificado**
- **15177 ‚Äî Homic√≠dio Qualificado Contra Menor de 14 Anos (Lei Henry Borel)**
- **3370 ‚Äî Homic√≠dio Simples**
- **3373 ‚Äî Induzimento, Instiga√ß√£o ou Aux√≠lio a Suic√≠dio**
- **3375 ‚Äî Infantic√≠dio**

Poder√≠amos escolher todas ou algumas dessas categorias para nossa an√°lise.

## Escolha Alternativa: Pesquisa por Classe

Nesta aula, por√©m, seguiremos um caminho alternativo: em vez de selecionar um assunto espec√≠fico, trabalharemos com a **classe processual**.

Selecionamos o seguinte ramo:

**Processo Criminal ‚Üí Procedimento Comum ‚Üí A√ß√£o Penal de Compet√™ncia do J√∫ri**

**C√≥digo: 282**

Essa classe captura processos de crimes dolosos contra a vida julgados pelo Tribunal do J√∫ri, alinhados ao nosso objetivo anal√≠tico. Entretanto, muitos dos assuntos acima listados estar√£o presentes. Al√°m disso,  limitamos os nossos processos √† **Inst√¢ncia de 1¬∫ Grau (G1)**.


## Fase Muito Importante

A etapa que descrevemos at√© aqui √© fundamental em qualquer pesquisa emp√≠rica que utilize o DataJud ou outras bases de dados judiciais. As **escolhas feitas nesta fase**, como a defini√ß√£o do assunto, da classe processual e dos crit√©rios de filtragem, **influenciam diretamente o desenho amostral** que construiremos.

Uma **boa sele√ß√£o inicial** garante **maior precis√£o, consist√™ncia e relev√¢ncia dos resultados**. Por isso, √© essencial conduzir essa etapa com aten√ß√£o, calma e organiza√ß√£o. Quanto mais cuidadosa for a defini√ß√£o desses par√¢metros, melhor ser√° a qualidade da extra√ß√£o dos dados e, consequentemente, das an√°lises que realizaremos nas pr√≥ximas fases do curso.

## Colocando a M√£o na Massa: Coleta de Dados no DataJud

### Extra√≠ndo os Dados Processuais

O c√≥digo abaixo extrair√° os dados da **classe 282 do grau G1** do **Tribunal de Justi√ßa do Tocantins** e salvar√° todas essas informa√ß√µes em um dataframe chamado *juri.json*.


```{r eval = FALSE, message=FALSE, warning=FALSE}
# Bibloitecas Necess√°rias
library(tidyverse)
library(httr)
library(jsonlite)

# Definindo a Chave de Acesso
headers = c(
  'Authorization' = 'APIKey cDZHYzlZa0JadVREZDJCendQbXY6SkJlTzNjLV9TRENyQk1RdnFKZGRQdw==',
  'Content-Type' = 'application/json'
)

# Extraindo os dados do DataJud
## Classe 282 e grau G1 (1¬∫ Grau)
body = '{
  "size": 8930,
  "query": {
        "bool": {
            "must": [
                {"match": {"classe.codigo": 282}},
                {"match": {"grau": "G1"}}

            ]
        }
   }
}'

## Do Tribunal de Justi√ßa do Tocantins
POST(url = "https://api-publica.datajud.cnj.jus.br/api_publica_tjto/_search", body = body, add_headers(headers),
write_disk("juri.json"))

## Importanto o dado
juri <- fromJSON("juri.json")
save(juri, file = "juri.rds")
```



Agora vamos analisar a **estrutura do arquivo *juri.json*** para identificar onde cada informa√ß√£o relevante est√° **localizada**. Esse mapeamento √© essencial porque nos permite compreender exatamente como os **dados est√£o organizados** e, assim, definir qual tipo de **extra√ß√£o precisamos realizar** para trabalhar com informa√ß√µes de movimenta√ß√£o, √≥rg√£os julgadores, assuntos e outras caracter√≠sticas presentes no arquivo.

```{r eval = TRUE, message=FALSE, warning=FALSE}
#| results: "hide"

# Pacotes Necess√°rios
library(tidyverse)
library(httr)
library(jsonlite)

## Importanto o dado
load("juri.rds")

# 1. Verifica a classe do objeto (ex.: list, data.frame)
class(juri)  

# 2. ver nomes/elementos de topo
names(juri)          # se for lista ou data.frame, mostra colunas/elementos
length(juri)         # n√∫mero de elementos/top-level items

# 3. Exibe a estrutura do objeto; max.level evita sa√≠da muito grande
str(juri, max.level = 4) 

# 4.Extrai os dados principais: hits -> hits -> _source - Aqui est√£o os dados de interesse
## Cada n√≠vel corresponde a um ramo interno do JSON
dados_basicos <- juri |>
  pluck("hits","hits","_source")
```

### Analisando as Informa√ß√µes Extra√≠das 

**√ìrg√£o Julgador dos Processos**

Vamos criar um banco que contenha o n√∫mero do processo e o √≥rg√£o julgador respons√°vel por cada caso. Em seguida, analisaremos a frequ√™ncia de processos por √≥rg√£o julgador, tanto considerando apenas processos √∫nicos quanto incluindo processos duplicados.


```{r eval = TRUE, message=FALSE, warning=FALSE}

# Pacote que padroniza os nomes das vari√°veis
library(janitor)
library(dplyr)
library(tidyr)

# Criar um dataframe com n√∫mero do processo e √≥rg√£o julgador
julgador <- dados_basicos  |> 
      select(processo = numeroProcesso, orgaoJulgador) |> # Fa√ßo a sele√ß√£o e renomeio a coluna
      unnest(orgaoJulgador) |>  # Como orgaoJulgador √© um dataframe, preciso "desempacotar" os dados
      janitor::clean_names()    # Deixo os nomes padronizados
nrow(julgador) # n√∫mero total de processos
```

Observa-se um **total de 8432 processos**, mas alguns podem estar **duplicados**. Vamos investigar essa quest√£o. Abaixo est√° o c√≥digo para identificar e analisar processos √∫nicos e duplicados.


```{r eval = TRUE, message=FALSE, warning=FALSE}
# Vamos verificar se existem processos duplicados. 
julgador_uni <- julgador %>% 
  distinct(processo, .keep_all = TRUE)
nrow(julgador_uni) # numero total de processos √∫nicos
nrow(julgador) - nrow(julgador_uni) # n√∫mero de processos duplicados

# Vamos analisar os processos duplicados 
julgador_dup <- julgador %>% 
  filter(duplicated(processo) | duplicated(processo, fromLast = TRUE)) 
## Esse comando pega todas as linhas ap√≥s a primeira ocorr√™ncia ou 
## Pega todas as linhas antes da √∫ltima ocorr√™ncia e verifica duplica√ß√£o

## Vamos ver quantos processos duplicados temos:
nrow(julgador_dup) # n√∫mero de processos duplicados
unique(julgador_dup$processo) |> length() # n√∫mero de processos √∫nicos que est√£o duplicados

```

O total de **processos √∫nicos** foi de **8.287**, e identificamos **144 processos duplicados**. Agora, vamos verificar se essas duplica√ß√µes ocorreram em raz√£o de alguma mudan√ßa de √≥rg√£o julgador. Para isso, vamos pivotar os dados e criar uma vari√°vel que indique se houve altera√ß√£o no √≥rg√£o julgador para cada processo duplicado.

```{r eval = TRUE, message=FALSE, warning=FALSE}
## Analisando se houve troca de orga√µ julgador e por isso √© duplicado
# 1. Criar ordem dentro de cada processo 1, para primeira vez e 2 para a segunda vez....
julgador_dup_ord <- julgador_dup %>%
  group_by(processo) %>%
  mutate(orgao_id = row_number()) %>% 
  ungroup()

# 2. Pivotar para formato wide, selciono e indico o nome que ser√° dado
julgador_wide <- julgador_dup_ord %>%
  select(processo, orgao_id, nome) %>%
  pivot_wider(
    names_from = orgao_id,
    values_from = nome,
    names_prefix = "julgador"
  )
# 3. Vari√°vel indicando mudan√ßa
julgador_wide <- julgador_wide %>%
  rowwise() %>%
  mutate(
    mudou_orgao = n_distinct(c_across(starts_with("julgador")), na.rm = TRUE) > 1
  ) %>%
  ungroup()
# - > pega todas as colunas cujo nome come√ßa com "julgador", transforma em vetores e verifica se √© distinto

julgador_wide %>% 
  count(mudou_orgao, sort = TRUE) %>% 
  mutate(
    mudou_orgao = ifelse(mudou_orgao, "Sim", "N√£o")
  ) %>% 
  knitr::kable(
    caption = "Frequ√™ncia de processos que mudaram de √≥rg√£o julgador"
  )
```


Observamos que **93 processos n√£o mudaram de √≥rg√£o julgador** e **51 passaram por altera√ß√£o**. Agora precisamos definir como trataremos esses casos: se consideraremos apenas o *√≥rg√£o julgador final*, se adotaremos o *√≥rg√£o julgador inicial* como refer√™ncia ou *exclu√≠mos*. Mas ainda precisamos observar que h√° **93 processos** que aparecem duplicados, mesmo **sem mudan√ßa de √≥rg√£o julgador**. O que pode estar acontecendo nesses casos?


*LIMPEZA DOS DADOS*

::: {.callout-note title="Escolha e Justificativa" appearance="simple" collapse="true"}

**Motivos Poss√≠veis**: Recursos, mudan√ßas para varas expecializadas, desclassifica√ß√£o, desforamento, entre outros.

**Escolha**: Vamos excluir os processos que mudaram de √≥rg√£o julgador, mantendo apenas aqueles que permaneceram no mesmo √≥rg√£o. Depois analisaremos os processos duplicados restantes.

**Justificativa**: A mudan√ßa de √≥rg√£o julgador pode indicar transfer√™ncias ou redistribui√ß√µes que podem afetar a an√°lise do tempo do processo. Para garantir a consist√™ncia dos dados e evitar vieses, mantemos somente aqueles permaneceram no mesmo √≥rg√£o julgador ao longo do tempo.

:::

```{r eval = TRUE, message=FALSE, warning=FALSE}
# Vamos retirar os processos que mudaram de org√£o julgador 

db_limpo <- dados_basicos %>%
  anti_join(julgador_wide %>% filter(mudou_orgao == TRUE),
            by = c("numeroProcesso" = "processo"))
          
```



Vamos focar nos processos √∫nicos para analisar a frequ√™ncia de √≥rg√£os julgadores e descrever os resultados graficamente e em tabelas.

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(gt)

freq_j_u <- julgador_uni %>% 
  count(nome) %>% 
  arrange(desc(n)) %>% 
  mutate(perc = round(100 * n / sum(n), 1))

ggplot(freq_j_u, aes(x = reorder(nome, n), y = n)) +
  geom_col(fill = "#7185cc", color = "white", alpha = 0.7) +
  coord_flip() +
  labs(
    title = "Frequ√™ncia por √ìrg√£o Julgador (Processos √önicos)",
    x = "√ìrg√£o Julgador",
    y = "Frequ√™ncia"
  ) +
  theme_classic()+
  theme(
    axis.text.y = element_text(size = 4)   # tamanho da letra das categorias
  )


freq_j_u |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia por √ìrg√£o Julgador (Processos √önicos)"
  ) |>
  cols_label(
    nome = "√ìrg√£o Julgador",
    n = "Frequ√™ncia",
    perc = "Percentual"
  )
``` 


*Quest√£o*

Como podemos fazer a nossa an√°lise de movimento considerando que comarcas distintas possuem diferentes volumes de processos? Devemos agrupar as comarcas maiores e as menores? Quais crit√©rios utilizar para isso? Deixamos varas criminais separada de especializadas? 


**Sistema dos Processos**

Aqui avaliamos se os processos pertencem ao sistema **sistema eletr√¥nico de processos judiciais** EPROC ou a outro sistema.

```{r eval = TRUE, message=FALSE, warning=FALSE}
sistema <- db_limpo  |> 
      select(processo = numeroProcesso, sistema) |> 
      unnest(sistema) |>
      janitor::clean_names()

freq_sistema <- sistema %>% 
  count(nome) %>% 
  arrange(desc(n))

freq_sistema |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia por Sistema (Processos √önicos)"
  ) |>
  cols_label(
    nome = "Sistema",
    n = "Frequ√™ncia",
  )
```

Com base na tabela acima, podemos observar a distribui√ß√£o dos processos entre os sistemas Eletr√¥nico e F√≠sico. Observa-se a exist√™ncia somente de processos eletr√¥nicos, mas 4 foram declaros inv√°lidos e 2 Outros. O que fazer com esses casos? Devemos exclu√≠-los da an√°lise ou mant√™-los? 


*LIMPEZA DOS DADOS*


::: {.callout-note title="Escolha e Justificativa" appearance="simple" collapse="true"}

**Motivos Poss√≠veis**: Cita√ß√£o em outros estados, entre outros.

**Escolha**: Vamos excluir todos os processos que n√£o s√£o EPROC.

**Justificativa**: N√£o sabemos ao certo os motivos que levaram a um processo ser classificado como inv√°lido ou outros. Al√©m disso, n√£o sabemos como essa classifica√ß√£o afeta a movimenta√ß√£o. Portanton, vamos excluir todos que n√£o foram EPROC e deixar nossa amostra mais homog√™nea.

:::

```{r eval = TRUE, message=FALSE, warning=FALSE}
# Vamos retirar os processos que mudaram de org√£o julgador 

db_limpo <- db_limpo %>%
  anti_join(sistema %>% filter(!nome == "EPROC"),
            by = c("numeroProcesso" = "processo"))
          
```

**Formato do Processo**

Aqui avaliamos se os processos s√£o do tipo **Eletr√¥nico** ou **F√≠sico**.

```{r eval = TRUE, message=FALSE, warning=FALSE}
formato <- db_limpo  |> 
      select(processo = numeroProcesso, formato) |> 
      unnest(formato) |>
      janitor::clean_names()

freq_formato <- formato %>% 
  count(nome) %>% 
  arrange(desc(n))

freq_formato |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia por Formato (Processos √önicos)"
  ) |>
  cols_label(
    nome = "Formato",
    n = "Frequ√™ncia",
  )
```

Observa-se que 100% dos processos est√£o no formato Eletr√¥nico. Dessa forma, n√£o h√° necessidade de excluir nenhum processo com base nesse crit√©rio.


**Classe Processual** 

Como fizemos nossa busca por classe processual, 282, dever√≠amos ter somente essa classe. Vamos verificar se h√° outras classes presentes nos dados.

```{r eval = TRUE, message=FALSE, warning=FALSE}

classe <- db_limpo  |> 
      select(processo = numeroProcesso, classe) |> 
      unnest(classe) |>
      janitor::clean_names()

freq_classe <- classe %>% 
  count(nome) %>% 
  arrange(desc(n))

freq_classe |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia por Classe (Processos √önicos)"
  ) |>
  cols_label(
    nome = "Classe",
    n = "Frequ√™ncia",
  )
```

Conforme esperado pela nossa consulta inicial, todos os processos pertencem √† classe **A√ß√£o Penal de Compet√™ncia do J√∫ri (282)**. Portanto, n√£o h√° necessidade de excluir nenhum processo com base nesse crit√©rio.



**Assuntos Processuais**

Vamos extrair e analisar os **assuntos processuais** associados a cada processo. Vamos fazer a extra√ß√£o e veja que o resultado √© uma coluna com processo e a outra com o assunto. Se tivermos mais assuntos por processo, esse ser√° duplicado. 

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(purrr)
library(janitor)
library(ggplot2)
library(gt)

 # manter s√≥ linhas em que 'assuntos' √© um data.frame
assuntos <- db_limpo |> 
  filter(map_lgl(assuntos, is.data.frame)) |>
  select(processo = numeroProcesso, assuntos) |>
  unnest(assuntos) |>
  clean_names()

# Processos √∫nicos
nrow(assuntos %>% 
  distinct(processo, .keep_all = TRUE)) # n√∫mero total de processos √∫nicos

freq_assunto <- assuntos |> 
  count(nome) |> 
  arrange(desc(n)) |> 
  mutate(perc_assunto = round(100 * n / sum(n), 1)) |> 
  mutate(perc_processo = round(100 * n / 8228, 1))  # considerando processos √∫nicos


ggplot(freq_assunto, aes(x = reorder(nome, n), y = n)) +
  geom_col(fill = "#7185cc", color = "white", alpha = 0.7) +
  coord_flip() +
  labs(
    title = "Frequ√™ncia por Assunto (Processos √önicos)",
    x = "Assunto",
    y = "Frequ√™ncia"
  ) +
  theme_classic()+
  theme(
    axis.text.y = element_text(size = 4))   # tamanho da letra das categorias
    

freq_assunto |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia dos Assuntos"
  ) |>
  cols_label(
    nome = "Assunto",
    n = "Frequ√™ncia",
    perc_assunto = "% Assuntos",
    perc_processo = "% Processos"
  )

```

**Assuntos** tem um total de **11302 processos**, sendo que o n√∫mero de **processos √∫nicos √© 8228**. Isso indica que muitos processos t√™m mais de um assunto associado. Ent√£o a leitura da tabela acima deve considerar esses n√∫meros. Podemos dizer que **5933** processos tiveram **Homic√≠dio Qualificado** como assunto, **2733** tiveram **Crime Tentado**, e assim por diante. **Existe sobreposi√ß√£o** entre os assuntos. 

Fizemos duas colunas, uma com percentual com base no total de assuntos (11302), **% Assuntos**, e outra com base no total de processos √∫nicos (8228), **% Processos**. A segunda coluna √© mais interessante, pois indica a propor√ß√£o de processos que tiveram cada assunto.

Agora vamos olhar o assunto por processo, para ver quantos assuntos cada processo tem associado.


```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
assuntos_wide <- assuntos %>% 
  group_by(processo, nome) %>%   # garante uma linha por processo-assunto
  summarise(valor = 1, .groups = "drop") %>%
  pivot_wider(
    names_from = nome,
    values_from = valor,
    values_fill = list(valor = 0)   # preenche com 0 se n√£o ocorreu
  )

assuntos_wide %>% 
  slice_head(n = 10) %>% 
  select(1:8) %>%
  gt() %>% 
  tab_header(
    title = "Assuntos por Processo (Exemplo)"
  )
```

Agora cada linha √© um processo √∫nico com todos os assuntos listados. Tivemos um total de 8228. Para o tribunal do Juri tem-se **5 tipos penais**: **Homic√≠dio Qualificado, Homic√≠dio Simples, Infantic√≠dio, Aborto, Induzimento ao Suic√≠dio** e a partir de outubro de 24 o **Feminic√≠dio**. 

**Quest√£o**: 

Devemos incluir todos os assuntos ou focar apenas em alguns? Quais crit√©rios utilizar para essa sele√ß√£o?


*LIMPEZA DOS DADOS*


::: {.callout-note title="Escolha e Justificativa" appearance="simple" collapse="true"}

**Escolha**: Vamos trabalhar somente com homic√≠dio Qualificado, Simples e Feminic√≠dio.

**Justificativa**: Acreditamos que esse esses processos possuem um perfil semelhante entre si, e diferente do infantic√≠dio, aborto e induzimento ao suic√≠dio.

:::

```{r eval = TRUE, message=FALSE, warning=FALSE}
# Vamos retirar os processos que mudaram de org√£o julgador 

assuntos_wide_limpo <- assuntos_wide %>%
  mutate(
    homic_bin = if_any(
      c(
        "Homic√≠dio Qualificado",
        "Homic√≠dio Simples",
        "Feminic√≠dio",
        "Homicidio qualificado",
        "Homic√≠dio"
      ),
      ~ .x == 1
    ) * 1
  )

db_limpo <- db_limpo %>%
  anti_join(assuntos_wide_limpo %>% filter(homic_bin == 0),
            by = c("numeroProcesso" = "processo"))

nrow(db_limpo) # n√∫mero total de processos ap√≥s limpeza
nrow(db_limpo %>% 
  distinct(numeroProcesso, .keep_all = TRUE)) # n√∫mero total de processos √∫nicos

```

Ao final do procedimento, observamos que o banco de dados **original** continha **8.432 processos**. Ap√≥s as etapas de limpeza e organiza√ß√£o, chegamos a **7.867 registros**. No entanto, ainda identificamos a exist√™ncia de processos duplicados. O total de **processos √∫nicos** √© de **7.775**, o que significa que permanecem **92 processos duplicados** para os quais ainda precisamos definir um tratamento adequado.


*LIMPEZA DOS DADOS*

::: {.callout-note title="Escolha e Justificativa" appearance="simple" collapse="true"}

**Escolha**: Excuir os processos duplicados.

**Justificativa**: Como n√£o est√° claro o motivo dessa duplica√ß√£o e quais seus impactos sobre a movimenta√ß√£o, vamos optar pela exclus√£o desses processos.Note que poderiamos identificar esses processos e fazermos uma an√°lise mais detalhada sobre eles.

**Motivos**: Insidente de insanidade mental, por exemplo. Processo separado mas com mesmo n√∫mero. 

:::


```{r eval = TRUE, message=FALSE, warning=FALSE}
# Vamos retirar os processos que mudaram de org√£o julgador 
db_limpo <- db_limpo %>%
  anti_join(julgador_dup,
            by = c("numeroProcesso" = "processo"))

```

Conclu√≠mos a limpeza com **7.683 processos**, que ser√£o a base da an√°lise de movimenta√ß√£o. Antes de prosseguir, vamos reorganizar as tabelas anteriores  de julgador, assunto e demais vari√°veis, usando agora apenas esse banco de dados limpo.


**TABELAS FINAIS AP√ìS LIMPEZA DOS DADOS**

Com os dados limpos vamos criar uma *data.frame* de julgados final. Nesse vamos deixar o **processo**, o **√≥rg√£o julgador**, e criar vari√°veis que indiquem se o **√≥rg√£o √© especializado** ou n√£o, e se est√° entre os **5 com maior volume de processos**. 

```{r eval = TRUE, message=FALSE, warning=FALSE}

# Pacote que padroniza os nomes das vari√°veis
library(janitor)
library(dplyr)
library(tidyr)

# JULGADOR
julgador_final <- db_limpo  |> 
      select(processo = numeroProcesso, orgaoJulgador) |> 
      unnest(orgaoJulgador) |>   
      janitor::clean_names() 

# Alterando o nome para facilitar a leitura e excluindo o cod do IBGE
julgador_final <- julgador_final %>%
  rename(orgao_julgador = nome) %>%
  select(-codigo_municipio_ibge)  


# Construindo a tabela final do org√£o julgador
freq_j_f <- julgador_final %>% 
  count(orgao_julgador) %>% 
  arrange(desc(n)) %>% 
  mutate(perc = round(100 * n / sum(n), 1))

freq_j_f |> 
  gt() |>
  tab_header(
    title = "Frequ√™ncia por √ìrg√£o Julgador (Processos √önicos)"
  ) |>
  cols_label(
    orgao_julgador = "√ìrg√£o Julgador",
    n = "Frequ√™ncia",
    perc = "Percentual"
  )
```

**Identificando a Varas Especializadas e as Varas com Maior Volume de Processos**

```{r eval = TRUE, message=FALSE, warning=FALSE}
# Identificando as Varas Especializadas
julgador_final <- julgador_final %>%
  mutate(
        vara_espec = ifelse(
      orgao_julgador %in% c(
        "Juizo da Especializada no Combate √† Viol√™ncia Contra a Mulher e Crimes Dolosos Contra a Vida de Guru",
        "Ju√≠zo da Vara Criminal, de Viol√™ncia Dom√©stica e Juizado Especial Criminal de Dian√≥polis",
        "Ju√≠zo da Vara Criminal, de Viol√™ncia Dom√©stica e Juizado Especial Criminal de Araguatins"
      ),
      1, 0
    )
  )

# Identificando as varas com maior volume de processos (top 5)

julgador_final <- julgador_final %>%
  mutate(
    volume_top5 = ifelse(
      orgao_julgador %in% c(
        "Ju√≠zo da 1¬™ Vara Criminal de Aragua√≠na",
        "Juizo da 1¬™ Vara Criminal de Palmas",
        "Ju√≠zo da 1¬™ Vara Criminal de Porto Nacional",
        "Ju√≠zo da 1¬™ Vara Criminal de Colinas do Tocantins",
        "Ju√≠zo da 1¬™ Vara Criminal de Para√≠so do Tocantins"
      ),
      1, 0
    )
  )
```


Agora come√ßaremos a montar o **banco de dados final**, agregando todos os bancos que j√° organizamos. Vamos unir as informa√ß√µes de √≥rg√£o julgador, sistema, formato, classe e assunto al√©m das vari√°veis bin√°rias que criamos anteriormente.

```{r eval = TRUE, message=FALSE, warning=FALSE}
sistema_final <- db_limpo  |> 
      select(processo = numeroProcesso, sistema) |> 
      unnest(sistema) |>
      janitor::clean_names()

sistema_final <- sistema_final %>%
  rename(sistema = nome)

bd_final <- julgador_final |> 
  left_join(sistema_final, by = c("processo" = "processo")) |>
  left_join(formato, by = c("processo" = "processo")) |>
  left_join(classe, by = c("processo" = "processo"))

bd_final <- bd_final %>%
  rename(
    cod_julgador = codigo.x,
    cod_sistema = codigo.y,
    cod_formato = codigo.x.x,
    cod_classe = codigo.y.y,
    formato = nome.x,
    classe = nome.y
  )

```

Agora vamos organizar o banco de dados de assuntos. Vamos utilizar o nosso *assunto_wide* para trazer para o nosso banco de dados final e crarmos vari√°veis bin√°rias. 

Primeiro vamos ver se todos os assuntos est√£o presentes e depois vamos deixar somente aqueles que possuem soma maior que zero. 

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)

bd_final <- bd_final |> 
  left_join(assuntos_wide_limpo, by = c("processo" = "processo"))

tabela_somas <- bd_final %>%
  summarise(across(where(is.numeric), ~ sum(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(),
               names_to = "variavel",
               values_to = "soma")


# Mant√©m todas as n√£o num√©ricas 
# Identifica colunas num√©ricas com soma > 0
# Mant√©m apenas num√©ricas cuja soma > 0
bd_final <- bd_final |> 
  select(
    where(~ !is.numeric(.x)),
    where(~ is.numeric(.x) && sum(.x, na.rm = TRUE) > 0)
  ) |> 
  janitor::clean_names()

# Essa vari√°vel criada anteriormente era apenas para apoio
table(bd_final$homic_bin)

# Vamos retirar 
bd_final <- bd_final %>%
  select(-homic_bin)

# Vari√°veis que identificam tipos de homic√≠dio
bd_final <- bd_final %>%
  mutate(
    hq  = ifelse(homicidio_qualificado == 1 | homicidio_qualificado_2 == 1, 1, 0),
    hs  = ifelse(homicidio_simples == 1, 1, 0),
    fem = ifelse(feminicidio == 1, 1, 0)
  )
 
```

Trouxemos a tabela `assuntos_wide_limpo` e identificamos que algumas colunas estavam completamente zeradas. Isso ficou claro a partir da tabela de somas. Assim, removemos apenas as vari√°veis num√©ricas com soma igual a zero, mantendo todas as vari√°veis n√£o num√©ricas.

Tamb√©m exclu√≠mos a vari√°vel `homic_bin`, usada apenas como apoio na etapa anterior.

Por fim, criamos **vari√°veis bin√°rias** para identificar tr√™s categorias principais de homic√≠dio: **homic√≠dio qualificado**, **homic√≠dio simples** e **feminic√≠dio**. √â importante notar que essas categorias podem se sobrepor em alguns processos.



### An√°lise da Movimenta√ß√£o Processual


Agora vamos analisar a movimenta√ß√£o processual. Para isso, precisamos extrair e organizar os dados de movimenta√ß√£o de cada processo. Vamos calcular o tempo decorrido entre cada movimenta√ß√£o e, em seguida, focar na an√°lise do tempo at√© a baixa definitiva do processo.


```{r eval = TRUE, message=FALSE, warning=FALSE}
# Instalando Pacotes necess√°rios
#install.packages("devtools") 
library(janitor)
devtools::install_github("courtsbr/JurisMiner")

movimento <- db_limpo  |> 
      select(processo = numeroProcesso, movimentos) |>
      unnest(movimentos) |> 
      janitor::clean_names() |> 
      select(-complementos_tabelados) |> 
      mutate(data_hora = parse_datetime(data_hora))

movimento  <- movimento |> 
     arrange(processo, desc(data_hora)) |> 
     JurisMiner::tempo_movimentacao(data = data_hora)

movimento  <- movimento |> 
 rename(movimento = nome,
        cod_movimento = codigo
        ) 


```


### Tempo at√© a Baixa Definitiva

Vamos selecionar todos os processos para os quais conseguimos extrair a baixa definitiva. No c√≥digo abaixo, buscamos manter apenas a √∫ltima baixa de cada processo. Note que alguns processos apresentaram m√∫ltiplas baixas definitivas.

```{r eval = TRUE, message=FALSE, warning=FALSE}
# Tempo at√© a baixa definitiva

tempo_baixa <- movimento |> 
  filter(movimento == "Baixa Definitiva")

nrow(tempo_baixa %>% 
  distinct(processo, .keep_all = TRUE)) # n√∫mero total de processos √∫nicos

# Vamos analisar os processos duplicados 
t_baixa_dup <- tempo_baixa %>% 
  filter(duplicated(processo) | duplicated(processo, fromLast = TRUE)) 
## Esse comando pega todas as linhas ap√≥s a primeira ocorr√™ncia ou 
## Pega todas as linhas antes da √∫ltima ocorr√™ncia e verifica duplica√ß√£o

## Vamos ver quantos processos duplicados temos:
unique(julgador_dup$processo) |> length() # n√∫mero de processos √∫nicos que est√£o duplicados

tempo_baixa_unico <- tempo_baixa |> 
  group_by(processo) |> 
  slice_max(decorrencia_acumulada, n = 1) |> 
  ungroup()

```


Agora, vamos juntar com o nosso banco de dados, que criamos na outra parte, e que cont√©m assunto, classe e as demais vari√°veis bin√°rias que geramos.

```{r eval = TRUE, message=FALSE, warning=FALSE}
baixa_uni_comp <- tempo_baixa_unico |> 
  left_join(bd_final, by = c("processo" = "processo"))

# Verificar se criou uma coluna NA
sum(is.na(baixa_uni_comp$fem))
```


**Analise Descritiva Geral**

Primeiramente, vamos descrever ou realizar a an√°lise descritiva do tempo at√© a baixa, ou seja, do tempo at√© a baixa definitiva do processo. Neste momento, estamos considerando todos os processos.


```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(gt)

# Estat√≠sticas descritivas para a vari√°vel decorrencia_acumulada
tempo_stats <- baixa_uni_comp %>%
  summarise(
    media     = mean(decorrencia_acumulada, na.rm = TRUE),
    mediana   = median(decorrencia_acumulada, na.rm = TRUE),
    desvio  = sd(decorrencia_acumulada, na.rm = TRUE),
    variancia = var(decorrencia_acumulada, na.rm = TRUE),
    q1        = quantile(decorrencia_acumulada, 0.25, na.rm = TRUE),
    q3        = quantile(decorrencia_acumulada, 0.75, na.rm = TRUE),
    minimo    = min(decorrencia_acumulada, na.rm = TRUE),
    maximo    = max(decorrencia_acumulada, na.rm = TRUE)
  ) |> 
  pivot_longer(
    cols = everything(),
    names_to = "Estat√≠stica",
    values_to = "Valor"
  ) 

# Tabela GT
tempo_stats %>%
  gt() %>%
  tab_header(
    title = "Estat√≠sticas Descritivas ‚Äî Tempo do Processo at√© Baixa Definitiva",
    subtitle = "Vari√°vel: decorrencia_acumulada"
  ) %>%
  fmt_number(
    columns = Valor,
    decimals = 2
  )
```


Vamos analisar tamb√©m o tempo de forma gr√°fica, utilizando diferentes tipos de gr√°ficos. Primeiro, apresentamos o gr√°fico conhecido como BoxPlot; em seguida, o gr√°fico chamado ViolinPlot. Depois, constru√≠mos os gr√°ficos de densidade: inicialmente o histograma e, em seguida, a densidade cont√≠nua. Eles est√£o apresentados abaixo.


**O Box Plot**

O boxplot √© um gr√°fico que traz muitas informa√ß√µes e pode ser visto como a distribui√ß√£o de probabilidade dos dados. O box ou caixa cont√©m 50% dos dados. O limite superior indica o percentil de 75% (*Q3*) e o limite inferior indica o percentil de 25% (*Q1*). A linha que corta o box indica a mediana, ou seja, *Q2*. Os bigodes s√£o calculados com base na dist√¢ncia interquant√≠lica, ou seja,

*Limite inferior: Q1-1,5(Q3-Q1)*

*Limite superior:Q3+1,5(Q3-Q1)*

Dados fora desses limites s√£o classificados como suspeitos de serem outliers. Podemos observar a assimetria dos dados quando a mediana n√£o est√° no meio da caixa, indicando maior densidade na menor dist√¢ncia entre os quartis Q1 ou Q3 e a mediana Q2.


```{r eval = TRUE, message=FALSE, warning=FALSE}
ggplot(baixa_uni_comp, aes(y = decorrencia_acumulada)) +
  geom_boxplot(fill = "#7185cc", color = "#c2986f", alpha=0.7,  # Linhas tracejadas no boxplot
    outlier.shape = 16, outlier.color = "red", outlier.size = 3) + # Boxplot com preenchimento azul e bordas pretas
  labs(
    title = "Boxplot do Tempo do Processo at√© Baixa Definitiva", # T√≠tulo do gr√°fico
    x = "",                                                   # Sem r√≥tulo no eixo x
    y = "Tempo"                        # R√≥tulo do eixo y
  ) +
  coord_flip() + # Inverte os eixos para horizontalidade
  theme_bw() + # Tema limpo e moderno
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"), # Centraliza e estiliza o t√≠tulo
    axis.text.y = element_text(size = 10), # Ajusta o tamanho do texto no eixo y
    axis.title.y = element_text(size = 12) # Ajusta o tamanho do r√≥tulo do eixo y
  )
```


**O Violin Plot**

O Violin Plot √© muito parecido com o BoxPlot mas com a densidade de kernel rotacionada em cada um dos lados. Assim, indica a distribui√ß√£o dos dados em cada ponto e vem anotado a mediana na forma de um ponto ou marca e um pequeno boxplot no centro do violin plot.


```{r eval = TRUE, message=FALSE, warning=FALSE}
ggplot(baixa_uni_comp, aes( x=0,  y = decorrencia_acumulada))+ 
  geom_violin(trim = FALSE, color = "#c2986f", fill="#7185cc") +                                                        # Cria o gr√°fico de violino
  stat_summary(fun="median", geom = "point", shape=19, size=3, color="darkorange"  ) +                # Vamos colocar o ponto mediana
  labs(
    title = "Violin Plots do Tempo do Processo at√© Baixa Definitiva",
    x = "Processos",
    y = "Tempo at√© Baixa Definitiva"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),              # Centraliza o t√≠tulo
    axis.text.x = element_text(size = 12),                                         # Ajusta o tamanho dos r√≥tulos no eixo X
    axis.text.y = element_text(size = 10),                                         # Ajusta o tamanho dos r√≥tulos no eixo Y
    legend.position = "none"  )
```



**Gr√°fico de Densidade**

Visualizar a distribui√ß√£o emp√≠rica dos dados fornece uma grande quantidade de informa√ß√£o. Um gr√°fico b√°sico em an√°lise descritiva √© o histograma, o qual fornece a distribui√ß√£o de probabilidade emp√≠rica dos dados em um formato de barras. A √°rea do histograma √© igual a 1 e altura da sua barra da a densidade de observa√ß√µes em cada classe.


```{r eval = TRUE, message=FALSE, warning=FALSE}

ggplot(baixa_uni_comp, aes(x = decorrencia_acumulada)) +
  geom_histogram(bins = 30, fill = "#7185cc", color = "white", alpha = 0.7) +    
  geom_vline(aes(xintercept = mean(decorrencia_acumulada)), color = "#c2986f", size = 1, alpha = 0.7,linetype = "dashed") +
  annotate("text", x = 1400, y = 300, vjust = -0.5, label = "M√©dia", color = "#c2986f", fontface = "bold", size = 4) +
  geom_vline(aes(xintercept = median(decorrencia_acumulada)), color = "#c77878ff", size = 1, alpha = 0.7,linetype = "dashed") + 
  annotate("text", x = 900, y = 400, vjust = -0.5, label = "Mediana", color = "#c77878ff", fontface = "bold", size = 4) + 
  labs(
    x = "Tempo do Processo",                                                 
    y = "Frequ√™ncia",  
    title = "Histograma do Tempo do Processo at√© Baixa Definitiva"   
  ) +
  theme_minimal() + 
 theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),              
    axis.text.x = element_text(size = 12),                                         
    axis.text.y = element_text(size = 10))
```


Uma outra maneira de visualizar os dados √© utilizando uma distribui√ß√£o continua e n√£o mais a discreta. Para isso, utiliza-se a densidade de Kernel para visualiza√ß√£o da distribui√ß√£o de probabilidade da taxa de feminic√≠dio. Vejamos

```{r eval = TRUE, message=FALSE, warning=FALSE}
 
 ggplot(baixa_uni_comp, aes(x = decorrencia_acumulada)) +
  geom_density(fill = "#7185cc", alpha = 0.4, color = "#7185cc", linewidth = 1) +    
  geom_vline(aes(xintercept = mean(decorrencia_acumulada)), color = "#c2986f", size = 1, alpha = 0.7,linetype = "dashed") +
  annotate("text", x = 1400, y = 0.00005, vjust = -0.5, label = "M√©dia", color = "#c2986f", fontface = "bold", size = 4) +
  geom_vline(aes(xintercept = median(decorrencia_acumulada)), color = "#c77878ff", size = 1, alpha = 0.7,linetype = "dashed") + 
  annotate("text", x = 900, y = 0.00005, vjust = -0.5, label = "Mediana", color = "#c77878ff", fontface = "bold", size = 4) + 
  labs(
    x = "Tempo do Processo",                                                 
    y = "Frequ√™ncia",  
    title = "Histograma do Tempo do Processo at√© Baixa Definitiva"   
  ) +
  theme_minimal() + 
 theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),              
    axis.text.x = element_text(size = 12),                                         
    axis.text.y = element_text(size = 10))
 
```


**An√°lise por √ìrg√£o Julgador**

Vamos analisar agora por √≥rg√£o julgador, os 5 maiores em rela√ß√£o aos demais.

```{r eval = TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(gt)

# Estat√≠sticas descritivas estratificadas por volume_top5
tempo_stats_grupo <- baixa_uni_comp %>%
  group_by(volume_top5) %>% 
  summarise(
    media     = mean(decorrencia_acumulada, na.rm = TRUE),
    mediana   = median(decorrencia_acumulada, na.rm = TRUE),
    desvio    = sd(decorrencia_acumulada, na.rm = TRUE),
    variancia = var(decorrencia_acumulada, na.rm = TRUE),
    q1        = quantile(decorrencia_acumulada, 0.25, na.rm = TRUE),
    q3        = quantile(decorrencia_acumulada, 0.75, na.rm = TRUE),
    minimo    = min(decorrencia_acumulada, na.rm = TRUE),
    maximo    = max(decorrencia_acumulada, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = -volume_top5,
    names_to = "Estat√≠stica",
    values_to = "Valor"
  )%>%
  pivot_wider(
    names_from = volume_top5,
    values_from = Valor
  )

# Tabela GT
tempo_stats_grupo %>%
  gt(groupname_col = "volume_top5") %>%
  tab_header(
    title = "Estat√≠sticas Descritivas ‚Äî Tempo do Processo at√© Baixa Definitiva",
    subtitle = "Estratificadas 5 maiores √≥rg√£os julgadores )"
  ) %>%
  fmt_number(
    columns = where(is.numeric),
    decimals = 2
  ) %>%
  cols_label(
    Estat√≠stica = "Estat√≠stica",
    `0` = "Top 5",
    `1` = "Demais"
  )
```


```{r eval = TRUE, message=FALSE, warning=FALSE}
 
library(ggplot2)

# Garantir que seja fator
baixa_uni_comp$volume_top5_factor <- factor(baixa_uni_comp$volume_top5, levels = c(1, 0), labels = c("Top5", "Demais"))

ggplot(baixa_uni_comp, aes(x = decorrencia_acumulada, fill = volume_top5_factor, group = volume_top5_factor)) +
  geom_density(alpha = 0.4, linewidth = 1) +    
  labs(
    x = "Tempo do Processo",                                                 
    y = "Densidade",  
    title = "Distribui√ß√£o do Tempo do Processo at√© Baixa Definitiva"   
  ) +
  scale_fill_manual(
    name = "Grupo de Volume", 
    values = c("Top5" = "#7185cc", "Demais" = "#c77878ff")  # cores espec√≠ficas
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),              
    axis.text.x = element_text(size = 12),                                         
    axis.text.y = element_text(size = 10)
  )

 
```